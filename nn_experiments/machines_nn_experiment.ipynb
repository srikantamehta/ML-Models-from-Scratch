{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_preprocessor import DataProcessor\n",
    "from data_configs.configs import *\n",
    "from models.neural_networks import *\n",
    "from src.cross_validation import CrossValidation\n",
    "import numpy as np\n",
    "\n",
    "config = machine_config\n",
    "data_processor = DataProcessor(config=config)\n",
    "cross_validator = CrossValidation(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Srikanta\\Documents\\Intro to Machine Learning\\programming_assignment_1\\src\\data_preprocessor.py:44: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[column].fillna(data[column].mean(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "raw_data = data_processor.load_data()\n",
    "data_1 = raw_data.drop(columns=['vendor_name','model_name','ERP'])\n",
    "data_2 = data_processor.impute_missing_values(data_1)\n",
    "data_3 = data_processor.standardize_data(data_2,data_2,features=['MYCT', 'MMIN', 'MMAX', 'CACH', 'CHMIN', 'CHMAX'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MYCT</th>\n",
       "      <th>MMIN</th>\n",
       "      <th>MMAX</th>\n",
       "      <th>CACH</th>\n",
       "      <th>CHMIN</th>\n",
       "      <th>CHMAX</th>\n",
       "      <th>PRP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.302859</td>\n",
       "      <td>-0.673409</td>\n",
       "      <td>-0.494275</td>\n",
       "      <td>5.680569</td>\n",
       "      <td>1.658008</td>\n",
       "      <td>4.220899</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.671717</td>\n",
       "      <td>1.323114</td>\n",
       "      <td>1.722913</td>\n",
       "      <td>0.167228</td>\n",
       "      <td>0.484346</td>\n",
       "      <td>0.528211</td>\n",
       "      <td>269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.671717</td>\n",
       "      <td>1.323114</td>\n",
       "      <td>1.722913</td>\n",
       "      <td>0.167228</td>\n",
       "      <td>0.484346</td>\n",
       "      <td>0.528211</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.671717</td>\n",
       "      <td>1.323114</td>\n",
       "      <td>1.722913</td>\n",
       "      <td>0.167228</td>\n",
       "      <td>0.484346</td>\n",
       "      <td>0.528211</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.671717</td>\n",
       "      <td>1.323114</td>\n",
       "      <td>0.358489</td>\n",
       "      <td>0.167228</td>\n",
       "      <td>0.484346</td>\n",
       "      <td>-0.087238</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>-0.306701</td>\n",
       "      <td>-0.481594</td>\n",
       "      <td>-0.323723</td>\n",
       "      <td>-0.620392</td>\n",
       "      <td>-0.542608</td>\n",
       "      <td>-0.394962</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>-0.406600</td>\n",
       "      <td>-0.481594</td>\n",
       "      <td>-0.323723</td>\n",
       "      <td>0.167228</td>\n",
       "      <td>-0.395900</td>\n",
       "      <td>-0.394962</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>-0.302859</td>\n",
       "      <td>-0.223779</td>\n",
       "      <td>-0.323723</td>\n",
       "      <td>-0.620392</td>\n",
       "      <td>-0.395900</td>\n",
       "      <td>-0.164169</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>1.061146</td>\n",
       "      <td>-0.607408</td>\n",
       "      <td>-0.323723</td>\n",
       "      <td>0.167228</td>\n",
       "      <td>-0.689316</td>\n",
       "      <td>-0.702686</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>1.061146</td>\n",
       "      <td>-0.481594</td>\n",
       "      <td>-0.664828</td>\n",
       "      <td>-0.620392</td>\n",
       "      <td>-0.689316</td>\n",
       "      <td>-0.702686</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>209 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         MYCT      MMIN      MMAX      CACH     CHMIN     CHMAX  PRP\n",
       "0   -0.302859 -0.673409 -0.494275  5.680569  1.658008  4.220899  198\n",
       "1   -0.671717  1.323114  1.722913  0.167228  0.484346  0.528211  269\n",
       "2   -0.671717  1.323114  1.722913  0.167228  0.484346  0.528211  220\n",
       "3   -0.671717  1.323114  1.722913  0.167228  0.484346  0.528211  172\n",
       "4   -0.671717  1.323114  0.358489  0.167228  0.484346 -0.087238  132\n",
       "..        ...       ...       ...       ...       ...       ...  ...\n",
       "204 -0.306701 -0.481594 -0.323723 -0.620392 -0.542608 -0.394962   42\n",
       "205 -0.406600 -0.481594 -0.323723  0.167228 -0.395900 -0.394962   46\n",
       "206 -0.302859 -0.223779 -0.323723 -0.620392 -0.395900 -0.164169   52\n",
       "207  1.061146 -0.607408 -0.323723  0.167228 -0.689316 -0.702686   67\n",
       "208  1.061146 -0.481594 -0.664828 -0.620392 -0.689316 -0.702686   45\n",
       "\n",
       "[209 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_val = cross_validator.random_partition(data_3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested params: {'lr': 0.01, 'epochs': 3000}, Score: 7970.490785854759\n",
      "Tested params: {'lr': 0.01, 'epochs': 5000}, Score: 7970.475786088262\n",
      "Tested params: {'lr': 0.01, 'epochs': 20000}, Score: 7970.450695079872\n",
      "Tested params: {'lr': 0.001, 'epochs': 5000}, Score: 8017.537044520643\n",
      "Tested params: {'lr': 0.0001, 'epochs': 20000}, Score: 8490.875881480595\n",
      "Tested params: {'lr': 0.001, 'epochs': 1000}, Score: 9890.905015994285\n",
      "Tested params: {'lr': 0.01, 'epochs': 18000}, Score: 7970.524197738162\n",
      "Tested params: {'lr': 0.01, 'epochs': 17000}, Score: 7970.460200168816\n",
      "Tested params: {'lr': 0.001, 'epochs': 12000}, Score: 7974.60848587786\n",
      "Tested params: {'lr': 0.001, 'epochs': 14000}, Score: 7973.364663793899\n",
      "Tested params: {'lr': 0.0001, 'epochs': 20000}, Score: 8490.870895067274\n",
      "Tested params: {'lr': 0.01, 'epochs': 5000}, Score: 7970.492238172022\n",
      "Tested params: {'lr': 0.001, 'epochs': 11000}, Score: 7975.562366765633\n",
      "Tested params: {'lr': 0.001, 'epochs': 8000}, Score: 7981.998455895757\n",
      "Tested params: {'lr': 0.01, 'epochs': 15000}, Score: 7970.470167848475\n",
      "Best parameters: {'lr': 0.01, 'epochs': 20000}, Best score: 7970.450695079872\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "iterations = 15\n",
    "\n",
    "param_space = {\n",
    "    'lr': [0.01,0.001,0.0001],\n",
    "    'epochs': np.linspace(1000, 20000, num=20).astype(int).tolist()\n",
    "}\n",
    "\n",
    "best_score = float('inf')\n",
    "best_params_linear = {}\n",
    "\n",
    "for _ in range(iterations):\n",
    "\n",
    "    # Randomly select parameters\n",
    "    params = {key: random.choice(value) for key, value in param_space.items()}\n",
    "    scores = []\n",
    "\n",
    "    for i, (train_set, _) in enumerate(cross_validator.cross_validation(data_train, n_splits=2, n_repeats=5, random_state=42, stratify=False)):\n",
    "    \n",
    "        train_data = train_set.to_numpy()\n",
    "        X_train = train_data[:,:-1]\n",
    "        y_train = train_data[:,-1:]\n",
    "\n",
    "        data_test = data_val.to_numpy()\n",
    "        X_val = data_test[:,:-1]\n",
    "        y_val = data_test[:,-1:]\n",
    "        \n",
    "        linear = LinearNetwork(config)\n",
    "\n",
    "        _, val_losses = linear.linear_regression(X_train,y_train,X_val,y_val,epochs=params['epochs'],lr=params['lr'],patience=500)\n",
    "\n",
    "        score = np.min(val_losses)\n",
    "        scores.append(score)\n",
    "\n",
    "        # Skip to the next parameter set if score > 0.2\n",
    "        if score > 20000:\n",
    "            print(f\"Skipping params: {params} due to high score: {score}\")\n",
    "            break  # Exit the current for-loop\n",
    "        \n",
    "    avg_score = np.mean(scores)\n",
    "\n",
    "    print(f\"Tested params: {params}, Score: {avg_score}\")\n",
    "    \n",
    "    if avg_score < best_score:\n",
    "        best_score = avg_score\n",
    "        best_params_linear = params\n",
    "        \n",
    "\n",
    "print(f\"Best parameters: {best_params_linear}, Best score: {best_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping params: {'lr': 0.0001, 'epochs': 4000, 'n_hidden': 12} due to high score: 41193.35520669441\n",
      "Tested params: {'lr': 0.0001, 'epochs': 4000, 'n_hidden': 12}, Score: 41193.35520669441\n",
      "Skipping params: {'lr': 1e-06, 'epochs': 14000, 'n_hidden': 42} due to high score: 21477.184125792883\n",
      "Tested params: {'lr': 1e-06, 'epochs': 14000, 'n_hidden': 42}, Score: 21477.184125792883\n",
      "Skipping params: {'lr': 1e-07, 'epochs': 12000, 'n_hidden': 57} due to high score: 43522.2152594878\n",
      "Tested params: {'lr': 1e-07, 'epochs': 12000, 'n_hidden': 57}, Score: 43522.2152594878\n",
      "Skipping params: {'lr': 1e-05, 'epochs': 2000, 'n_hidden': 27} due to high score: 21881.45524677582\n",
      "Tested params: {'lr': 1e-05, 'epochs': 2000, 'n_hidden': 27}, Score: 21881.45524677582\n",
      "Skipping params: {'lr': 1e-05, 'epochs': 2000, 'n_hidden': 42} due to high score: 20141.025311628873\n",
      "Tested params: {'lr': 1e-05, 'epochs': 2000, 'n_hidden': 42}, Score: 20141.025311628873\n",
      "Skipping params: {'lr': 1e-07, 'epochs': 8000, 'n_hidden': 72} due to high score: 47080.35199703692\n",
      "Tested params: {'lr': 1e-07, 'epochs': 8000, 'n_hidden': 72}, Score: 47080.35199703692\n",
      "Skipping params: {'lr': 0.0001, 'epochs': 8000, 'n_hidden': 72} due to high score: 22356.81013203647\n",
      "Tested params: {'lr': 0.0001, 'epochs': 8000, 'n_hidden': 72}, Score: 15783.829767054107\n",
      "Skipping params: {'lr': 1e-05, 'epochs': 6000, 'n_hidden': 27} due to high score: 21987.547162216244\n",
      "Tested params: {'lr': 1e-05, 'epochs': 6000, 'n_hidden': 27}, Score: 21987.547162216244\n",
      "Skipping params: {'lr': 1e-05, 'epochs': 2000, 'n_hidden': 12} due to high score: 26598.30786177903\n",
      "Tested params: {'lr': 1e-05, 'epochs': 2000, 'n_hidden': 12}, Score: 26598.30786177903\n",
      "Skipping params: {'lr': 1e-07, 'epochs': 12000, 'n_hidden': 87} due to high score: 38538.782012657626\n",
      "Tested params: {'lr': 1e-07, 'epochs': 12000, 'n_hidden': 87}, Score: 38538.782012657626\n",
      "Skipping params: {'lr': 1e-07, 'epochs': 16000, 'n_hidden': 87} due to high score: 35020.53477187257\n",
      "Tested params: {'lr': 1e-07, 'epochs': 16000, 'n_hidden': 87}, Score: 35020.53477187257\n",
      "Skipping params: {'lr': 1e-05, 'epochs': 2000, 'n_hidden': 72} due to high score: 23474.278436524666\n",
      "Tested params: {'lr': 1e-05, 'epochs': 2000, 'n_hidden': 72}, Score: 17452.621024363107\n",
      "Skipping params: {'lr': 0.0001, 'epochs': 2000, 'n_hidden': 87} due to high score: 21088.599938361316\n",
      "Tested params: {'lr': 0.0001, 'epochs': 2000, 'n_hidden': 87}, Score: 21088.599938361316\n",
      "Skipping params: {'lr': 1e-06, 'epochs': 16000, 'n_hidden': 42} due to high score: 21013.731091467787\n",
      "Tested params: {'lr': 1e-06, 'epochs': 16000, 'n_hidden': 42}, Score: 21013.731091467787\n",
      "Skipping params: {'lr': 1e-05, 'epochs': 12000, 'n_hidden': 27} due to high score: 21786.2057336963\n",
      "Tested params: {'lr': 1e-05, 'epochs': 12000, 'n_hidden': 27}, Score: 21786.2057336963\n",
      "Best parameters: {'lr': 0.0001, 'epochs': 8000, 'n_hidden': 72}, Best score: 15783.829767054107\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "iterations = 15\n",
    "\n",
    "param_space = {\n",
    "    'lr': [0.0001,0.00001,0.000001,0.0000001],\n",
    "    'epochs': np.arange(2000, 20000, 2000).tolist(),\n",
    "    'n_hidden': np.arange(2*X_val.shape[1], 100, 15)\n",
    "}\n",
    "\n",
    "best_score = float('inf')\n",
    "best_params_ffn = {}\n",
    "\n",
    "for _ in range(iterations):\n",
    "\n",
    "    # Randomly select parameters\n",
    "    params = {key: random.choice(value) for key, value in param_space.items()}\n",
    "    scores = []\n",
    "\n",
    "    for i, (train_set, _) in enumerate(cross_validator.cross_validation(data_train, n_splits=2, n_repeats=5, random_state=42, stratify=False)):\n",
    "           \n",
    "        train_data = train_set.to_numpy()\n",
    "        X_train = train_data[:,:-1]\n",
    "        y_train = train_data[:,-1:]\n",
    "\n",
    "        data_test = data_val.to_numpy()\n",
    "        X_val = data_test[:,:-1]\n",
    "        y_val = data_test[:,-1:]\n",
    "\n",
    "        ffn = FeedForwardNetwork(config,n_input=X_train.shape[1],n_hidden_1=params['n_hidden'],n_hidden_2=params['n_hidden'],n_output=y_train.shape[1])\n",
    "\n",
    "        _, val_losses, _ = ffn.train(X_train,y_train,X_val,y_val,epochs=params['epochs'],lr=params['lr'],patience=500)\n",
    "\n",
    "        score = np.min(val_losses)\n",
    "        scores.append(score)\n",
    "\n",
    "        # Skip to the next parameter set if score > 0.2\n",
    "        if score > 20000:\n",
    "            print(f\"Skipping params: {params} due to high score: {score}\")\n",
    "            break  # Exit the current for-loop\n",
    "\n",
    "    avg_score = np.mean(scores)\n",
    "\n",
    "    print(f\"Tested params: {params}, Score: {avg_score}\")\n",
    "    \n",
    "    if avg_score < best_score:\n",
    "        best_score = avg_score\n",
    "        best_params_ffn = params\n",
    "        \n",
    "\n",
    "print(f\"Best parameters: {best_params_ffn}, Best score: {best_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping params: {'lr': 1e-06, 'epochs': 7000, 'n_encoder': 2} due to high score.\n",
      "Tested params: {'lr': 1e-06, 'epochs': 7000, 'n_encoder': 2}, Score: 0.7451574617985534\n",
      "Tested params: {'lr': 0.001, 'epochs': 5000, 'n_encoder': 4}, Score: 0.07360011892582566\n",
      "Skipping params: {'lr': 1e-07, 'epochs': 17000, 'n_encoder': 3} due to high score.\n",
      "Tested params: {'lr': 1e-07, 'epochs': 17000, 'n_encoder': 3}, Score: 0.7465465252665268\n",
      "Skipping params: {'lr': 0.0001, 'epochs': 9000, 'n_encoder': 4} due to high score.\n",
      "Tested params: {'lr': 0.0001, 'epochs': 9000, 'n_encoder': 4}, Score: 0.2544451637208205\n",
      "Skipping params: {'lr': 1e-07, 'epochs': 13000, 'n_encoder': 4} due to high score.\n",
      "Tested params: {'lr': 1e-07, 'epochs': 13000, 'n_encoder': 4}, Score: 0.746848557376376\n",
      "Skipping params: {'lr': 1e-05, 'epochs': 11000, 'n_encoder': 3} due to high score.\n",
      "Tested params: {'lr': 1e-05, 'epochs': 11000, 'n_encoder': 3}, Score: 0.7284968514102522\n",
      "Skipping params: {'lr': 1e-07, 'epochs': 13000, 'n_encoder': 2} due to high score.\n",
      "Tested params: {'lr': 1e-07, 'epochs': 13000, 'n_encoder': 2}, Score: 0.7467736209150228\n",
      "Tested params: {'lr': 0.0001, 'epochs': 17000, 'n_encoder': 4}, Score: 0.10928614322849155\n",
      "Skipping params: {'lr': 1e-05, 'epochs': 11000, 'n_encoder': 3} due to high score.\n",
      "Tested params: {'lr': 1e-05, 'epochs': 11000, 'n_encoder': 3}, Score: 0.7346081851884697\n",
      "Skipping params: {'lr': 1e-05, 'epochs': 19000, 'n_encoder': 4} due to high score.\n",
      "Tested params: {'lr': 1e-05, 'epochs': 19000, 'n_encoder': 4}, Score: 0.4393350592296657\n",
      "Tested params: {'lr': 0.0001, 'epochs': 13000, 'n_encoder': 4}, Score: 0.14458748627118834\n",
      "Skipping params: {'lr': 1e-05, 'epochs': 9000, 'n_encoder': 2} due to high score.\n",
      "Tested params: {'lr': 1e-05, 'epochs': 9000, 'n_encoder': 2}, Score: 0.7425277182903854\n",
      "Skipping params: {'lr': 1e-07, 'epochs': 17000, 'n_encoder': 4} due to high score.\n",
      "Tested params: {'lr': 1e-07, 'epochs': 17000, 'n_encoder': 4}, Score: 0.7465542968841101\n",
      "Skipping params: {'lr': 1e-05, 'epochs': 15000, 'n_encoder': 4} due to high score.\n",
      "Tested params: {'lr': 1e-05, 'epochs': 15000, 'n_encoder': 4}, Score: 0.4743072574901491\n",
      "Skipping params: {'lr': 1e-05, 'epochs': 9000, 'n_encoder': 3} due to high score.\n",
      "Tested params: {'lr': 1e-05, 'epochs': 9000, 'n_encoder': 3}, Score: 0.7364158543275673\n",
      "Best parameters: {'lr': 0.001, 'epochs': 5000, 'n_encoder': 4}, Best score: 0.07360011892582566\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "iterations = 15\n",
    "\n",
    "param_space = {\n",
    "    'lr': [0.001,0.0001,0.00001,0.000001,0.0000001],\n",
    "    'epochs': np.arange(5000, 20000, 2000).tolist(),\n",
    "    'n_encoder': np.arange(2,X_val.shape[1]-1,1).tolist()\n",
    "}\n",
    "\n",
    "best_score = float('inf')\n",
    "best_params_auto = {}\n",
    "\n",
    "for _ in range(iterations):\n",
    "\n",
    "    # Randomly select parameters\n",
    "    params = {key: random.choice(value) for key, value in param_space.items()}\n",
    "    scores = []\n",
    "\n",
    "    for i, (train_set, _) in enumerate(cross_validator.cross_validation(data_train, n_splits=2, n_repeats=5, random_state=42, stratify=False)):\n",
    "    \n",
    "        train_data = train_set.to_numpy()\n",
    "        X_train = train_data[:,:-1]\n",
    "        y_train = train_data[:,-1:]\n",
    "\n",
    "        data_test = data_val.to_numpy()\n",
    "        X_val = data_test[:,:-1]\n",
    "        y_val = data_test[:,-1:]\n",
    "\n",
    "        # Check if the shapes of X_train and X_val are not equal\n",
    "        if X_train.shape[1] != X_val.shape[1]:\n",
    "            # print(f\"Shape mismatch between training and validation sets, skipping params: {params}\")\n",
    "            continue\n",
    "\n",
    "        autoE = AutoEncoder(config,n_input=X_train.shape[1],n_encoder=params['n_encoder'])\n",
    "\n",
    "        losses = autoE.train(X_train, max_epochs=params['epochs'], lr=params['lr'])\n",
    "\n",
    "        score = np.min(losses)\n",
    "        scores.append(score)\n",
    "\n",
    "        # Skip to the next parameter set if score > 0.2\n",
    "        if score > 0.2:\n",
    "            print(f\"Skipping params: {params} due to high score.\")\n",
    "            break  # Exit the current for-loop\n",
    "\n",
    "    avg_score = np.mean(scores)\n",
    "\n",
    "    print(f\"Tested params: {params}, Score: {avg_score}\")\n",
    "    \n",
    "    if avg_score < best_score:\n",
    "        best_score = avg_score\n",
    "        best_params_auto = params\n",
    "        \n",
    "\n",
    "print(f\"Best parameters: {best_params_auto}, Best score: {best_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0668874747296308"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoE = AutoEncoder(config,n_input=X_train.shape[1],n_encoder=best_params_auto['n_encoder'])\n",
    "losses = autoE.train(X_train, max_epochs=best_params_auto['epochs'], lr=best_params_auto['lr'])\n",
    "losses[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing params: {'lr': 0.0001, 'epochs': 9000, 'n_hidden_2': 21}\n",
      "Skipping params: {'lr': 0.0001, 'epochs': 9000, 'n_hidden_2': 21} due to high score: 22703.182169619064\n",
      "Tested params: {'lr': 0.0001, 'epochs': 9000, 'n_hidden_2': 21}, Score: 22703.182169619064\n",
      "Testing params: {'lr': 1e-07, 'epochs': 17000, 'n_hidden_2': 6}\n",
      "Skipping params: {'lr': 1e-07, 'epochs': 17000, 'n_hidden_2': 6} due to high score: 57173.475358766984\n",
      "Tested params: {'lr': 1e-07, 'epochs': 17000, 'n_hidden_2': 6}, Score: 57173.475358766984\n",
      "Testing params: {'lr': 1e-05, 'epochs': 19000, 'n_hidden_2': 51}\n",
      "Skipping params: {'lr': 1e-05, 'epochs': 19000, 'n_hidden_2': 51} due to high score: 20909.784938357796\n",
      "Tested params: {'lr': 1e-05, 'epochs': 19000, 'n_hidden_2': 51}, Score: 14448.922452916402\n",
      "Testing params: {'lr': 0.001, 'epochs': 11000, 'n_hidden_2': 51}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Srikanta\\Documents\\Intro to Machine Learning\\programming_assignment_1\\.venv\\Lib\\site-packages\\numpy\\core\\_methods.py:118: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "c:\\Users\\Srikanta\\Documents\\Intro to Machine Learning\\programming_assignment_1\\models\\neural_networks.py:459: RuntimeWarning: overflow encountered in square\n",
      "  train_metric = np.mean((y_train - A_output)**2)\n",
      "c:\\Users\\Srikanta\\Documents\\Intro to Machine Learning\\programming_assignment_1\\models\\neural_networks.py:460: RuntimeWarning: overflow encountered in square\n",
      "  val_metric = np.mean((y_val - val_output)**2)\n",
      "c:\\Users\\Srikanta\\Documents\\Intro to Machine Learning\\programming_assignment_1\\models\\neural_networks.py:428: RuntimeWarning: invalid value encountered in multiply\n",
      "  error_hidden_2 = np.dot(error_output, self.W_output.T) * (1 - np.power(A2, 2))  # Derivative of tanh is (1 - tanh^2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested params: {'lr': 0.001, 'epochs': 11000, 'n_hidden_2': 51}, Score: nan\n",
      "Testing params: {'lr': 1e-07, 'epochs': 7000, 'n_hidden_2': 51}\n",
      "Skipping params: {'lr': 1e-07, 'epochs': 7000, 'n_hidden_2': 51} due to high score: 52599.20835970355\n",
      "Tested params: {'lr': 1e-07, 'epochs': 7000, 'n_hidden_2': 51}, Score: 52599.20835970355\n",
      "Testing params: {'lr': 1e-05, 'epochs': 13000, 'n_hidden_2': 6}\n",
      "Skipping params: {'lr': 1e-05, 'epochs': 13000, 'n_hidden_2': 6} due to high score: 20650.487323065456\n",
      "Tested params: {'lr': 1e-05, 'epochs': 13000, 'n_hidden_2': 6}, Score: 20650.487323065456\n",
      "Testing params: {'lr': 0.001, 'epochs': 19000, 'n_hidden_2': 66}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Srikanta\\Documents\\Intro to Machine Learning\\programming_assignment_1\\.venv\\Lib\\site-packages\\numpy\\core\\_methods.py:118: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "c:\\Users\\Srikanta\\Documents\\Intro to Machine Learning\\programming_assignment_1\\models\\neural_networks.py:459: RuntimeWarning: overflow encountered in square\n",
      "  train_metric = np.mean((y_train - A_output)**2)\n",
      "c:\\Users\\Srikanta\\Documents\\Intro to Machine Learning\\programming_assignment_1\\models\\neural_networks.py:460: RuntimeWarning: overflow encountered in square\n",
      "  val_metric = np.mean((y_val - val_output)**2)\n",
      "c:\\Users\\Srikanta\\Documents\\Intro to Machine Learning\\programming_assignment_1\\models\\neural_networks.py:428: RuntimeWarning: invalid value encountered in multiply\n",
      "  error_hidden_2 = np.dot(error_output, self.W_output.T) * (1 - np.power(A2, 2))  # Derivative of tanh is (1 - tanh^2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested params: {'lr': 0.001, 'epochs': 19000, 'n_hidden_2': 66}, Score: nan\n",
      "Testing params: {'lr': 1e-07, 'epochs': 5000, 'n_hidden_2': 6}\n",
      "Skipping params: {'lr': 1e-07, 'epochs': 5000, 'n_hidden_2': 6} due to high score: 65581.39574187237\n",
      "Tested params: {'lr': 1e-07, 'epochs': 5000, 'n_hidden_2': 6}, Score: 65581.39574187237\n",
      "Testing params: {'lr': 1e-07, 'epochs': 11000, 'n_hidden_2': 66}\n",
      "Skipping params: {'lr': 1e-07, 'epochs': 11000, 'n_hidden_2': 66} due to high score: 43337.74593770218\n",
      "Tested params: {'lr': 1e-07, 'epochs': 11000, 'n_hidden_2': 66}, Score: 43337.74593770218\n",
      "Testing params: {'lr': 0.001, 'epochs': 5000, 'n_hidden_2': 6}\n",
      "Skipping params: {'lr': 0.001, 'epochs': 5000, 'n_hidden_2': 6} due to high score: 52358.02782280216\n",
      "Tested params: {'lr': 0.001, 'epochs': 5000, 'n_hidden_2': 6}, Score: 52358.02782280216\n",
      "Testing params: {'lr': 0.001, 'epochs': 5000, 'n_hidden_2': 36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Srikanta\\Documents\\Intro to Machine Learning\\programming_assignment_1\\.venv\\Lib\\site-packages\\numpy\\core\\_methods.py:118: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "c:\\Users\\Srikanta\\Documents\\Intro to Machine Learning\\programming_assignment_1\\models\\neural_networks.py:459: RuntimeWarning: overflow encountered in square\n",
      "  train_metric = np.mean((y_train - A_output)**2)\n",
      "c:\\Users\\Srikanta\\Documents\\Intro to Machine Learning\\programming_assignment_1\\models\\neural_networks.py:460: RuntimeWarning: overflow encountered in square\n",
      "  val_metric = np.mean((y_val - val_output)**2)\n",
      "c:\\Users\\Srikanta\\Documents\\Intro to Machine Learning\\programming_assignment_1\\models\\neural_networks.py:428: RuntimeWarning: invalid value encountered in multiply\n",
      "  error_hidden_2 = np.dot(error_output, self.W_output.T) * (1 - np.power(A2, 2))  # Derivative of tanh is (1 - tanh^2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested params: {'lr': 0.001, 'epochs': 5000, 'n_hidden_2': 36}, Score: nan\n",
      "Testing params: {'lr': 0.0001, 'epochs': 11000, 'n_hidden_2': 6}\n",
      "Skipping params: {'lr': 0.0001, 'epochs': 11000, 'n_hidden_2': 6} due to high score: 26404.83361538519\n",
      "Tested params: {'lr': 0.0001, 'epochs': 11000, 'n_hidden_2': 6}, Score: 26404.83361538519\n",
      "Testing params: {'lr': 1e-07, 'epochs': 5000, 'n_hidden_2': 6}\n",
      "Skipping params: {'lr': 1e-07, 'epochs': 5000, 'n_hidden_2': 6} due to high score: 65467.43810670397\n",
      "Tested params: {'lr': 1e-07, 'epochs': 5000, 'n_hidden_2': 6}, Score: 65467.43810670397\n",
      "Testing params: {'lr': 0.0001, 'epochs': 17000, 'n_hidden_2': 96}\n",
      "Skipping params: {'lr': 0.0001, 'epochs': 17000, 'n_hidden_2': 96} due to high score: 33498.56462901738\n",
      "Tested params: {'lr': 0.0001, 'epochs': 17000, 'n_hidden_2': 96}, Score: 26584.275132495837\n",
      "Testing params: {'lr': 1e-07, 'epochs': 7000, 'n_hidden_2': 81}\n",
      "Skipping params: {'lr': 1e-07, 'epochs': 7000, 'n_hidden_2': 81} due to high score: 49317.95848745318\n",
      "Tested params: {'lr': 1e-07, 'epochs': 7000, 'n_hidden_2': 81}, Score: 49317.95848745318\n",
      "Best parameters: {'lr': 1e-05, 'epochs': 19000, 'n_hidden_2': 51}, Best score: 14448.922452916402\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "iterations = 15\n",
    "\n",
    "param_space = {\n",
    "    'lr': [0.001,0.0001,0.00001,0.000001,0.0000001],\n",
    "    'epochs': np.arange(5000, 20000, 2000).tolist(),\n",
    "    'n_hidden_2': np.arange(X_val.shape[1], 100, 15)\n",
    "}\n",
    "\n",
    "best_score = float('inf')\n",
    "best_params_combined = {}\n",
    "\n",
    "for _ in range(iterations):\n",
    "\n",
    "    # Randomly select parameters\n",
    "    params = {key: random.choice(value) for key, value in param_space.items()}\n",
    "    scores = []\n",
    "    print(f\"Testing params: {params}\")\n",
    "\n",
    "    for i, (train_set, _) in enumerate(cross_validator.cross_validation(data_train, n_splits=2, n_repeats=5, random_state=42, stratify=False)):\n",
    "    \n",
    "        train_data = train_set.to_numpy()\n",
    "        X_train = train_data[:,:-1]\n",
    "        y_train = train_data[:,-1:]\n",
    "\n",
    "        data_test = data_val.to_numpy()\n",
    "        X_val = data_test[:,:-1]\n",
    "        y_val = data_test[:,-1:]\n",
    "\n",
    "        # Check if the shapes of X_train and X_val are not equal\n",
    "        if X_train.shape[1] != X_val.shape[1]:\n",
    "            # print(f\"Shape mismatch between training and validation sets, skipping params: {params}\")\n",
    "            continue\n",
    "        \n",
    "        combined = CombinedModel(autoE,n_hidden_2=params['n_hidden_2'],n_output=y_val.shape[1])\n",
    "\n",
    "        _, val_losses, _ = combined.train(X_train,y_train,X_val,y_val,epochs=params['epochs'], lr=params['lr'],patience=500)\n",
    "\n",
    "\n",
    "        score = np.min(val_losses)\n",
    "        scores.append(score)\n",
    "\n",
    "        # Skip to the next parameter set if score > 0.2\n",
    "        if score > 20000:\n",
    "            print(f\"Skipping params: {params} due to high score: {score}\")\n",
    "            break  # Exit the current for-loop\n",
    "\n",
    "    avg_score = np.mean(scores)\n",
    "\n",
    "    print(f\"Tested params: {params}, Score: {avg_score}\")\n",
    "    \n",
    "    if avg_score < best_score:\n",
    "        best_score = avg_score\n",
    "        best_params_combined = params\n",
    "        \n",
    "\n",
    "print(f\"Best parameters: {best_params_combined}, Best score: {best_score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Model Tested params: {'lr': 0.01, 'epochs': 20000}, Average Score: 5437.229857771791\n",
      "FFN Model Tested params: {'lr': 0.0001, 'epochs': 8000, 'n_hidden': 72}, Average Score: 6413.998034747997\n",
      "Combined Model Tested params: {'lr': 1e-05, 'epochs': 19000, 'n_hidden_2': 51}, Average Score: 5704.171624577029\n",
      "Linear Model Scores: [7393.463525634592, 3361.6506758423907, 3269.280937946132, 7281.165725630679, 7844.847515288771, 3497.5946821491066, 7268.175881200254, 2995.0895737393257, 2599.632841191785, 8861.397219094873]\n",
      "FFN Model Scores: [9526.646182737022, 1692.78491962975, 2151.4437232320215, 8347.852019165213, 8382.195966333851, 6812.029753503698, 15280.45925892775, 2957.0385163995807, 915.8536736890944, 8073.676333861985]\n",
      "Combined Model Scores: [8416.180353810572, 1576.9937208560202, 1804.5479187539943, 10764.231172258087, 8700.837890321956, 1521.5472876242993, 12053.436992100273, 2232.825391797534, 1394.4851877361737, 8576.630330511383]\n"
     ]
    }
   ],
   "source": [
    "linear_scores = []\n",
    "ffn_scores = []\n",
    "combined_scores = []\n",
    "\n",
    "for i, (train_set, test_set) in enumerate(cross_validator.cross_validation(data_train, n_splits=2, n_repeats=5, random_state=42, stratify=False)):\n",
    "\n",
    "    train_data = train_set.to_numpy()\n",
    "    X_train = train_data[:,:-1]\n",
    "    y_train = train_data[:,-1:]\n",
    "\n",
    "    test_data = test_set.to_numpy()\n",
    "    X_test = test_data[:,:-1]\n",
    "    y_test = test_data[:,-1:]\n",
    "\n",
    "    # Check if the shapes of X_train and X_val are not equal\n",
    "    if X_train.shape[1] != X_test.shape[1]:\n",
    "        # print(f\"Shape mismatch between training and validation sets, skipping params: {params}\")\n",
    "        continue\n",
    "    \n",
    "    linear = LinearNetwork(config)\n",
    "    _, linear_val_losses = linear.linear_regression(X_train,y_train,X_test,y_test,epochs=best_params_linear['epochs'],lr=best_params_linear['lr'],patience=np.inf)\n",
    "\n",
    "    ffn = FeedForwardNetwork(config,n_input=X_train.shape[1],n_hidden_1=best_params_ffn['n_hidden'],n_hidden_2=best_params_ffn['n_hidden'],n_output=y_train.shape[1])\n",
    "    _, ffn_val_losses, _ = ffn.train(X_train,y_train,X_test,y_test,epochs=best_params_ffn['epochs'],lr=best_params_ffn['lr'],patience=np.inf)\n",
    "\n",
    "    autoE = AutoEncoder(config,n_input=X_train.shape[1],n_encoder=best_params_auto['n_encoder'])\n",
    "    losses = autoE.train(X_train, max_epochs=best_params_auto['epochs'], lr=best_params_auto['lr'])\n",
    "    combined = CombinedModel(autoE,n_hidden_2=best_params_combined['n_hidden_2'],n_output=y_test.shape[1])\n",
    "    _, combined_val_losses, _ = combined.train(X_train,y_train,X_test,y_test,epochs=best_params_combined['epochs'], lr=best_params_combined['lr'],patience=np.inf)\n",
    "\n",
    "\n",
    "    linear_score = np.min(linear_val_losses)\n",
    "    ffn_score = np.min(ffn_val_losses)\n",
    "    combined_score = np.min(combined_val_losses)\n",
    "    \n",
    "    linear_scores.append(linear_score)\n",
    "    ffn_scores.append(ffn_score)\n",
    "    combined_scores.append(combined_score)\n",
    "\n",
    "avg_score_linear = np.mean(linear_scores)\n",
    "avg_score_ffn = np.mean(ffn_scores)\n",
    "avg_score_combined = np.mean(combined_scores)\n",
    "\n",
    "print(f\"Linear Model Tested params: {best_params_linear}, Average Score: {avg_score_linear}\")\n",
    "print(f\"FFN Model Tested params: {best_params_ffn}, Average Score: {avg_score_ffn}\")\n",
    "print(f\"Combined Model Tested params: {best_params_combined}, Average Score: {avg_score_combined}\")\n",
    "\n",
    "print(f\"Linear Model Scores: {linear_scores}\")\n",
    "print(f\"FFN Model Scores: {ffn_scores}\")\n",
    "print(f\"Combined Model Scores: {combined_scores}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANOVA result: F-statistic = 0.16898436718024284, p-value = 0.8454083687364071\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Combine all scores into a single array, and create an array of labels\n",
    "scores = np.concatenate([linear_scores, ffn_scores, combined_scores])\n",
    "labels = ['Linear'] * len(linear_scores) + ['FFN'] * len(ffn_scores) + ['Combined'] * len(combined_scores)\n",
    "\n",
    "# Conduct ANOVA\n",
    "anova_result = stats.f_oneway(linear_scores, ffn_scores, combined_scores)\n",
    "print(f\"ANOVA result: F-statistic = {anova_result.statistic}, p-value = {anova_result.pvalue}\")\n",
    "\n",
    "# If ANOVA shows significant differences, conduct post-hoc testing with Tukey's HSD\n",
    "if anova_result.pvalue < 0.05:\n",
    "    tukey = pairwise_tukeyhsd(endog=scores, groups=labels, alpha=0.05)\n",
    "    print(tukey)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Model vs. FFN Model: t-statistic = -0.6027395468351565, p-value = 0.55420065904851\n",
      "Linear Model vs. Combined Model: t-statistic = -0.168548444692268, p-value = 0.8680313204668435\n",
      "FFN Model vs. Combined Model: t-statistic = 0.35875517002439733, p-value = 0.7239517104896738\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "t_stat, p_val = stats.ttest_ind(linear_scores, ffn_scores)\n",
    "print(f\"Linear Model vs. FFN Model: t-statistic = {t_stat}, p-value = {p_val}\")\n",
    "\n",
    "# Comparing Linear Model vs. Combined Model\n",
    "t_stat, p_val = stats.ttest_ind(linear_scores, combined_scores)\n",
    "print(f\"Linear Model vs. Combined Model: t-statistic = {t_stat}, p-value = {p_val}\")\n",
    "\n",
    "# Comparing FFN Model vs. Combined Model\n",
    "t_stat, p_val = stats.ttest_ind(ffn_scores, combined_scores)\n",
    "print(f\"FFN Model vs. Combined Model: t-statistic = {t_stat}, p-value = {p_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Archive ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = data_train.to_numpy()\n",
    "# X_train = data[:,:-1]\n",
    "# y_train = data[:,-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_test = data_val.to_numpy()\n",
    "# X_val = data_test[:,:-1]\n",
    "# y_val = data_test[:,-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoE = AutoEncoder(config,n_input=X_train.shape[1],n_encoder=4)\n",
    "\n",
    "# autoE.train(X_train, max_epochs=30000, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined = CombinedModel(autoE,n_hidden_2=100,n_output=1)\n",
    "\n",
    "# MSEs, val_metrics, final_mse = combined.train(X_train,y_train,X_val,y_val,epochs=10000,lr=0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.plot(MSEs)\n",
    "# plt.plot(val_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ffn = FeedForwardNetwork(config,n_input=X_train.shape[1],n_hidden_1=100,n_hidden_2=100,n_output=1)\n",
    "\n",
    "# MSEs, val_metrics, final_mse = ffn.train(X_train,y_train,X_val,y_val,5000,0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.plot(MSEs)\n",
    "# plt.plot(val_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear = LinearNetwork(config)\n",
    "\n",
    "# losses = linear.linear_regression(X_train,y_train,X_val,y_val)\n",
    "# losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
