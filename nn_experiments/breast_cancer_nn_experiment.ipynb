{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_preprocessor import DataProcessor\n",
    "from data_configs.configs import *\n",
    "from models.neural_networks import *\n",
    "from src.cross_validation import CrossValidation\n",
    "import numpy as np\n",
    "\n",
    "config = breast_cancer_config\n",
    "data_processor = DataProcessor(config=config)\n",
    "cross_validator = CrossValidation(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Srikanta\\Documents\\Intro to Machine Learning\\programming_assignment_1\\src\\data_preprocessor.py:47: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[column].fillna(data[column].mode()[0], inplace=True)\n",
      "c:\\Users\\Srikanta\\Documents\\Intro to Machine Learning\\programming_assignment_1\\src\\data_preprocessor.py:44: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[column].fillna(data[column].mean(), inplace=True)\n",
      "c:\\Users\\Srikanta\\Documents\\Intro to Machine Learning\\programming_assignment_1\\src\\data_preprocessor.py:47: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[column].fillna(data[column].mode()[0], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "raw_data = data_processor.load_data()\n",
    "data_1 = data_processor.impute_missing_values(raw_data)\n",
    "data_2 = data_1.drop(columns=['Sample code number'])\n",
    "data_3 = data_processor.encode_ordinal_features(data_2)\n",
    "data_4 = data_processor.standardize_data(data_3,data_3,features=['Clump Thickness', 'Uniformity of Cell Size',\n",
    "       'Uniformity of Cell Shape', 'Marginal Adhesion',\n",
    "       'Single Epithelial Cell Size', 'Bare Nuclei', 'Bland Chromatin',\n",
    "       'Normal Nucleoli', 'Mitoses'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clump Thickness</th>\n",
       "      <th>Uniformity of Cell Size</th>\n",
       "      <th>Uniformity of Cell Shape</th>\n",
       "      <th>Marginal Adhesion</th>\n",
       "      <th>Single Epithelial Cell Size</th>\n",
       "      <th>Bare Nuclei</th>\n",
       "      <th>Bland Chromatin</th>\n",
       "      <th>Normal Nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.206788</td>\n",
       "      <td>-0.699494</td>\n",
       "      <td>-0.742767</td>\n",
       "      <td>-0.632794</td>\n",
       "      <td>-0.549168</td>\n",
       "      <td>-0.706485</td>\n",
       "      <td>-0.179534</td>\n",
       "      <td>-0.611387</td>\n",
       "      <td>-0.343666</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.206788</td>\n",
       "      <td>0.283642</td>\n",
       "      <td>0.266684</td>\n",
       "      <td>0.768071</td>\n",
       "      <td>1.708882</td>\n",
       "      <td>1.792229</td>\n",
       "      <td>-0.179534</td>\n",
       "      <td>-0.283909</td>\n",
       "      <td>-0.343666</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.503505</td>\n",
       "      <td>-0.699494</td>\n",
       "      <td>-0.742767</td>\n",
       "      <td>-0.632794</td>\n",
       "      <td>-0.549168</td>\n",
       "      <td>-0.428851</td>\n",
       "      <td>-0.179534</td>\n",
       "      <td>-0.611387</td>\n",
       "      <td>-0.343666</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.561934</td>\n",
       "      <td>1.594490</td>\n",
       "      <td>1.612618</td>\n",
       "      <td>-0.632794</td>\n",
       "      <td>-0.097558</td>\n",
       "      <td>0.126419</td>\n",
       "      <td>-0.179534</td>\n",
       "      <td>1.353485</td>\n",
       "      <td>-0.343666</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.148359</td>\n",
       "      <td>-0.699494</td>\n",
       "      <td>-0.742767</td>\n",
       "      <td>0.067638</td>\n",
       "      <td>-0.549168</td>\n",
       "      <td>-0.706485</td>\n",
       "      <td>-0.179534</td>\n",
       "      <td>-0.611387</td>\n",
       "      <td>-0.343666</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>-0.503505</td>\n",
       "      <td>-0.699494</td>\n",
       "      <td>-0.742767</td>\n",
       "      <td>-0.632794</td>\n",
       "      <td>-0.097558</td>\n",
       "      <td>-0.428851</td>\n",
       "      <td>-0.999756</td>\n",
       "      <td>-0.611387</td>\n",
       "      <td>-0.343666</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>-0.858651</td>\n",
       "      <td>-0.699494</td>\n",
       "      <td>-0.742767</td>\n",
       "      <td>-0.632794</td>\n",
       "      <td>-0.549168</td>\n",
       "      <td>-0.706485</td>\n",
       "      <td>-0.999756</td>\n",
       "      <td>-0.611387</td>\n",
       "      <td>-0.343666</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>0.206788</td>\n",
       "      <td>2.249915</td>\n",
       "      <td>2.285586</td>\n",
       "      <td>0.067638</td>\n",
       "      <td>1.708882</td>\n",
       "      <td>-0.151216</td>\n",
       "      <td>1.871021</td>\n",
       "      <td>2.335921</td>\n",
       "      <td>0.239398</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>-0.148359</td>\n",
       "      <td>1.594490</td>\n",
       "      <td>0.939651</td>\n",
       "      <td>0.417854</td>\n",
       "      <td>-0.097558</td>\n",
       "      <td>0.126419</td>\n",
       "      <td>2.691243</td>\n",
       "      <td>1.026006</td>\n",
       "      <td>-0.343666</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>-0.148359</td>\n",
       "      <td>1.594490</td>\n",
       "      <td>1.612618</td>\n",
       "      <td>0.768071</td>\n",
       "      <td>0.354052</td>\n",
       "      <td>0.404054</td>\n",
       "      <td>2.691243</td>\n",
       "      <td>0.371049</td>\n",
       "      <td>-0.343666</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>699 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Clump Thickness  Uniformity of Cell Size  Uniformity of Cell Shape  \\\n",
       "0           0.206788                -0.699494                 -0.742767   \n",
       "1           0.206788                 0.283642                  0.266684   \n",
       "2          -0.503505                -0.699494                 -0.742767   \n",
       "3           0.561934                 1.594490                  1.612618   \n",
       "4          -0.148359                -0.699494                 -0.742767   \n",
       "..               ...                      ...                       ...   \n",
       "694        -0.503505                -0.699494                 -0.742767   \n",
       "695        -0.858651                -0.699494                 -0.742767   \n",
       "696         0.206788                 2.249915                  2.285586   \n",
       "697        -0.148359                 1.594490                  0.939651   \n",
       "698        -0.148359                 1.594490                  1.612618   \n",
       "\n",
       "     Marginal Adhesion  Single Epithelial Cell Size  Bare Nuclei  \\\n",
       "0            -0.632794                    -0.549168    -0.706485   \n",
       "1             0.768071                     1.708882     1.792229   \n",
       "2            -0.632794                    -0.549168    -0.428851   \n",
       "3            -0.632794                    -0.097558     0.126419   \n",
       "4             0.067638                    -0.549168    -0.706485   \n",
       "..                 ...                          ...          ...   \n",
       "694          -0.632794                    -0.097558    -0.428851   \n",
       "695          -0.632794                    -0.549168    -0.706485   \n",
       "696           0.067638                     1.708882    -0.151216   \n",
       "697           0.417854                    -0.097558     0.126419   \n",
       "698           0.768071                     0.354052     0.404054   \n",
       "\n",
       "     Bland Chromatin  Normal Nucleoli   Mitoses  Class  \n",
       "0          -0.179534        -0.611387 -0.343666      2  \n",
       "1          -0.179534        -0.283909 -0.343666      2  \n",
       "2          -0.179534        -0.611387 -0.343666      2  \n",
       "3          -0.179534         1.353485 -0.343666      2  \n",
       "4          -0.179534        -0.611387 -0.343666      2  \n",
       "..               ...              ...       ...    ...  \n",
       "694        -0.999756        -0.611387 -0.343666      2  \n",
       "695        -0.999756        -0.611387 -0.343666      2  \n",
       "696         1.871021         2.335921  0.239398      4  \n",
       "697         2.691243         1.026006 -0.343666      4  \n",
       "698         2.691243         0.371049 -0.343666      4  \n",
       "\n",
       "[699 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_val = cross_validator.random_partition(data_4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_val = data_processor.encode_nominal_features(data_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = data_val.to_numpy()\n",
    "X_val = data_test[:,:-2]\n",
    "y_val = data_test[:,-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested params: {'lr': 1e-05, 'epochs': 18000}, Score: 0.07918000111135785\n",
      "Tested params: {'lr': 1e-06, 'epochs': 4000}, Score: 0.18913727945278405\n",
      "Tested params: {'lr': 1e-06, 'epochs': 5000}, Score: 0.16839151626177334\n",
      "Tested params: {'lr': 1e-05, 'epochs': 1000}, Score: 0.12206445143418995\n",
      "Tested params: {'lr': 0.001, 'epochs': 5000}, Score: 0.09679476797677339\n",
      "Tested params: {'lr': 0.0001, 'epochs': 6000}, Score: 0.08121199357103256\n",
      "Tested params: {'lr': 0.001, 'epochs': 18000}, Score: 0.09678505557768542\n",
      "Tested params: {'lr': 0.01, 'epochs': 4000}, Score: 0.1103418767293333\n",
      "Tested params: {'lr': 0.01, 'epochs': 3000}, Score: 0.11033846231402203\n",
      "Tested params: {'lr': 0.0001, 'epochs': 5000}, Score: 0.08119164057885364\n",
      "Tested params: {'lr': 0.01, 'epochs': 17000}, Score: 0.11034082098896121\n",
      "Tested params: {'lr': 0.0001, 'epochs': 1000}, Score: 0.08055305914197848\n",
      "Tested params: {'lr': 1e-06, 'epochs': 11000}, Score: 0.11752301620999712\n",
      "Tested params: {'lr': 1e-06, 'epochs': 15000}, Score: 0.10524325090440437\n",
      "Tested params: {'lr': 0.01, 'epochs': 5000}, Score: 0.11034098682985669\n",
      "Best parameters: {'lr': 1e-05, 'epochs': 18000}, Best score: 0.07918000111135785\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "iterations = 15\n",
    "\n",
    "param_space = {\n",
    "    'lr': [0.01,0.001,0.0001,0.00001,0.000001],\n",
    "    'epochs': np.linspace(1000, 20000, num=20).astype(int).tolist()\n",
    "}\n",
    "\n",
    "best_score = float('inf')\n",
    "best_params_linear = {}\n",
    "\n",
    "for _ in range(iterations):\n",
    "\n",
    "    # Randomly select parameters\n",
    "    params = {key: random.choice(value) for key, value in param_space.items()}\n",
    "    scores = []\n",
    "\n",
    "    for i, (train_set, _) in enumerate(cross_validator.cross_validation(data_train, n_splits=2, n_repeats=5, random_state=42, stratify=True)):\n",
    "    \n",
    "        train_set = data_processor.encode_nominal_features(train_set)\n",
    "\n",
    "        train_data = train_set.to_numpy()\n",
    "        X_train = train_data[:,:-2]\n",
    "        y_train = train_data[:,-2:]\n",
    "\n",
    "        linear = LinearNetwork(config)\n",
    "\n",
    "        _, val_losses = linear.logistic_regression(X_train,y_train,X_val,y_val,epochs=params['epochs'],lr=params['lr'],patience=500)\n",
    "\n",
    "        score = val_losses[-1]\n",
    "        scores.append(score)\n",
    "\n",
    "        # Skip to the next parameter set if score > 0.2\n",
    "        if score > 0.2:\n",
    "            print(f\"Skipping params: {params} due to high score: {score}\")\n",
    "            break  # Exit the current for-loop\n",
    "        \n",
    "    avg_score = np.mean(scores)\n",
    "\n",
    "    print(f\"Tested params: {params}, Score: {avg_score}\")\n",
    "    \n",
    "    if avg_score < best_score:\n",
    "        best_score = avg_score\n",
    "        best_params_linear = params\n",
    "        \n",
    "\n",
    "print(f\"Best parameters: {best_params_linear}, Best score: {best_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping params: {'lr': 1e-05, 'epochs': 3000, 'n_hidden': 18} due to high score: 0.6272058086162202\n",
      "Tested params: {'lr': 1e-05, 'epochs': 3000, 'n_hidden': 18}, Score: 0.6272058086162202\n",
      "Tested params: {'lr': 0.0001, 'epochs': 1000, 'n_hidden': 16}, Score: 0.07799183867071817\n",
      "Skipping params: {'lr': 1e-07, 'epochs': 3000, 'n_hidden': 35} due to high score: 0.6888789387687329\n",
      "Tested params: {'lr': 1e-07, 'epochs': 3000, 'n_hidden': 35}, Score: 0.6888789387687329\n",
      "Skipping params: {'lr': 1e-06, 'epochs': 11000, 'n_hidden': 41} due to high score: 0.631694338789376\n",
      "Tested params: {'lr': 1e-06, 'epochs': 11000, 'n_hidden': 41}, Score: 0.631694338789376\n",
      "Skipping params: {'lr': 1e-07, 'epochs': 11000, 'n_hidden': 29} due to high score: 0.6788966268274266\n",
      "Tested params: {'lr': 1e-07, 'epochs': 11000, 'n_hidden': 29}, Score: 0.6788966268274266\n",
      "Skipping params: {'lr': 1e-06, 'epochs': 7000, 'n_hidden': 12} due to high score: 0.6438606983164123\n",
      "Tested params: {'lr': 1e-06, 'epochs': 7000, 'n_hidden': 12}, Score: 0.6438606983164123\n",
      "Tested params: {'lr': 0.0001, 'epochs': 5000, 'n_hidden': 35}, Score: 0.08395704739606415\n",
      "Skipping params: {'lr': 1e-05, 'epochs': 3000, 'n_hidden': 20} due to high score: 0.6251774793635138\n",
      "Tested params: {'lr': 1e-05, 'epochs': 3000, 'n_hidden': 20}, Score: 0.6251774793635138\n",
      "Tested params: {'lr': 1e-05, 'epochs': 19000, 'n_hidden': 9}, Score: 0.07848785430306252\n",
      "Tested params: {'lr': 1e-05, 'epochs': 19000, 'n_hidden': 12}, Score: 0.07779141878068323\n",
      "Skipping params: {'lr': 1e-05, 'epochs': 1000, 'n_hidden': 37} due to high score: 0.6349559510112779\n",
      "Tested params: {'lr': 1e-05, 'epochs': 1000, 'n_hidden': 37}, Score: 0.6349559510112779\n",
      "Skipping params: {'lr': 1e-07, 'epochs': 9000, 'n_hidden': 26} due to high score: 0.681192068403033\n",
      "Tested params: {'lr': 1e-07, 'epochs': 9000, 'n_hidden': 26}, Score: 0.681192068403033\n",
      "Skipping params: {'lr': 1e-07, 'epochs': 3000, 'n_hidden': 33} due to high score: 0.688756954642716\n",
      "Tested params: {'lr': 1e-07, 'epochs': 3000, 'n_hidden': 33}, Score: 0.688756954642716\n",
      "Skipping params: {'lr': 1e-07, 'epochs': 19000, 'n_hidden': 12} due to high score: 0.6707953485201674\n",
      "Tested params: {'lr': 1e-07, 'epochs': 19000, 'n_hidden': 12}, Score: 0.6707953485201674\n",
      "Skipping params: {'lr': 1e-07, 'epochs': 17000, 'n_hidden': 27} due to high score: 0.6725292452443822\n",
      "Tested params: {'lr': 1e-07, 'epochs': 17000, 'n_hidden': 27}, Score: 0.6725292452443822\n",
      "Best parameters: {'lr': 1e-05, 'epochs': 19000, 'n_hidden': 12}, Best score: 0.07779141878068323\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "iterations = 15\n",
    "\n",
    "param_space = {\n",
    "    'lr': [0.0001,0.00001,0.000001,0.0000001],\n",
    "    'epochs': np.arange(1000, 20000, 2000).tolist(),\n",
    "    'n_hidden': np.linspace(X_val.shape[1],5*X_val.shape[1],num=20).astype(int).tolist()\n",
    "}\n",
    "\n",
    "best_score = float('inf')\n",
    "best_params_ffn = {}\n",
    "\n",
    "for _ in range(iterations):\n",
    "\n",
    "    # Randomly select parameters\n",
    "    params = {key: random.choice(value) for key, value in param_space.items()}\n",
    "    scores = []\n",
    "\n",
    "    for i, (train_set, _) in enumerate(cross_validator.cross_validation(data_train, n_splits=2, n_repeats=5, random_state=42, stratify=True)):\n",
    "    \n",
    "        train_set = data_processor.encode_nominal_features(train_set)\n",
    "\n",
    "        train_data = train_set.to_numpy()\n",
    "        X_train = train_data[:,:-2]\n",
    "        y_train = train_data[:,-2:]\n",
    "\n",
    "        ffn = FeedForwardNetwork(config,n_input=X_train.shape[1],n_hidden_1=params['n_hidden'],n_hidden_2=params['n_hidden'],n_output=y_train.shape[1])\n",
    "\n",
    "        _, val_losses, _ = ffn.train(X_train,y_train,X_val,y_val,epochs=params['epochs'],lr=params['lr'],patience=500)\n",
    "\n",
    "        score = val_losses[-1]\n",
    "        scores.append(score)\n",
    "\n",
    "        # Skip to the next parameter set if score > 0.2\n",
    "        if score > 0.2:\n",
    "            print(f\"Skipping params: {params} due to high score: {score}\")\n",
    "            break  # Exit the current for-loop\n",
    "\n",
    "    avg_score = np.mean(scores)\n",
    "\n",
    "    print(f\"Tested params: {params}, Score: {avg_score}\")\n",
    "    \n",
    "    if avg_score < best_score:\n",
    "        best_score = avg_score\n",
    "        best_params_ffn = params\n",
    "        \n",
    "\n",
    "print(f\"Best parameters: {best_params_ffn}, Best score: {best_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping params: {'lr': 1e-07, 'epochs': 3000, 'n_encoder': 4} due to high score: 1.011108004191568\n",
      "Tested params: {'lr': 1e-07, 'epochs': 3000, 'n_encoder': 4}, Score: 1.011108004191568\n",
      "Skipping params: {'lr': 1e-06, 'epochs': 19000, 'n_encoder': 6} due to high score: 0.4728657953227713\n",
      "Tested params: {'lr': 1e-06, 'epochs': 19000, 'n_encoder': 6}, Score: 0.4728657953227713\n",
      "Skipping params: {'lr': 1e-07, 'epochs': 11000, 'n_encoder': 5} due to high score: 1.01066547851833\n",
      "Tested params: {'lr': 1e-07, 'epochs': 11000, 'n_encoder': 5}, Score: 1.01066547851833\n",
      "Skipping params: {'lr': 1e-07, 'epochs': 17000, 'n_encoder': 4} due to high score: 1.010321610686602\n",
      "Tested params: {'lr': 1e-07, 'epochs': 17000, 'n_encoder': 4}, Score: 1.010321610686602\n",
      "Skipping params: {'lr': 1e-07, 'epochs': 1000, 'n_encoder': 7} due to high score: 1.011273146741658\n",
      "Tested params: {'lr': 1e-07, 'epochs': 1000, 'n_encoder': 7}, Score: 1.011273146741658\n",
      "Skipping params: {'lr': 1e-07, 'epochs': 3000, 'n_encoder': 7} due to high score: 1.011007702333121\n",
      "Tested params: {'lr': 1e-07, 'epochs': 3000, 'n_encoder': 7}, Score: 1.011007702333121\n",
      "Skipping params: {'lr': 1e-07, 'epochs': 17000, 'n_encoder': 2} due to high score: 1.010799607352082\n",
      "Tested params: {'lr': 1e-07, 'epochs': 17000, 'n_encoder': 2}, Score: 1.010799607352082\n",
      "Skipping params: {'lr': 1e-07, 'epochs': 3000, 'n_encoder': 7} due to high score: 1.0110023801934305\n",
      "Tested params: {'lr': 1e-07, 'epochs': 3000, 'n_encoder': 7}, Score: 1.0110023801934305\n",
      "Skipping params: {'lr': 1e-05, 'epochs': 9000, 'n_encoder': 4} due to high score: 0.3525445570972959\n",
      "Tested params: {'lr': 1e-05, 'epochs': 9000, 'n_encoder': 4}, Score: 0.3525445570972959\n",
      "Skipping params: {'lr': 1e-07, 'epochs': 19000, 'n_encoder': 4} due to high score: 1.0103309901705453\n",
      "Tested params: {'lr': 1e-07, 'epochs': 19000, 'n_encoder': 4}, Score: 1.0103309901705453\n",
      "Skipping params: {'lr': 1e-06, 'epochs': 15000, 'n_encoder': 7} due to high score: 0.6148636304692933\n",
      "Tested params: {'lr': 1e-06, 'epochs': 15000, 'n_encoder': 7}, Score: 0.6148636304692933\n",
      "Skipping params: {'lr': 1e-07, 'epochs': 3000, 'n_encoder': 4} due to high score: 1.011147614217105\n",
      "Tested params: {'lr': 1e-07, 'epochs': 3000, 'n_encoder': 4}, Score: 1.011147614217105\n",
      "Skipping params: {'lr': 0.0001, 'epochs': 1000, 'n_encoder': 6} due to high score: 0.3493073699440521\n",
      "Tested params: {'lr': 0.0001, 'epochs': 1000, 'n_encoder': 6}, Score: 0.3493073699440521\n",
      "Skipping params: {'lr': 1e-05, 'epochs': 11000, 'n_encoder': 5} due to high score: 0.34799525203167603\n",
      "Tested params: {'lr': 1e-05, 'epochs': 11000, 'n_encoder': 5}, Score: 0.34799525203167603\n",
      "Tested params: {'lr': 0.0001, 'epochs': 5000, 'n_encoder': 4}, Score: 0.16544402383172216\n",
      "Best parameters: {'lr': 0.0001, 'epochs': 5000, 'n_encoder': 4}, Best score: 0.16544402383172216\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "iterations = 15\n",
    "\n",
    "param_space = {\n",
    "    'lr': [0.0001,0.00001,0.000001,0.0000001],\n",
    "    'epochs': np.arange(1000, 20000, 2000).tolist(),\n",
    "    'n_encoder': np.arange(2,X_val.shape[1]-1,1).tolist()\n",
    "}\n",
    "\n",
    "best_score = float('inf')\n",
    "best_params_auto = {}\n",
    "\n",
    "for _ in range(iterations):\n",
    "\n",
    "    # Randomly select parameters\n",
    "    params = {key: random.choice(value) for key, value in param_space.items()}\n",
    "    scores = []\n",
    "\n",
    "    for i, (train_set, _) in enumerate(cross_validator.cross_validation(data_train, n_splits=2, n_repeats=5, random_state=42, stratify=True)):\n",
    "    \n",
    "        train_set = data_processor.encode_nominal_features(train_set)\n",
    "\n",
    "        train_data = train_set.to_numpy()\n",
    "        X_train = train_data[:,:-2]\n",
    "        y_train = train_data[:,-2:]\n",
    "\n",
    "        autoE = AutoEncoder(config,n_input=X_train.shape[1],n_encoder=params['n_encoder'])\n",
    "\n",
    "        losses = autoE.train(X_train, max_epochs=params['epochs'], lr=params['lr'])\n",
    "\n",
    "        score = losses[-1]\n",
    "        scores.append(score)\n",
    "\n",
    "        # Skip to the next parameter set if score > 0.2\n",
    "        if score > 0.2:\n",
    "            print(f\"Skipping params: {params} due to high score: {score}\")\n",
    "            break  # Exit the current for-loop\n",
    "\n",
    "    avg_score = np.mean(scores)\n",
    "\n",
    "    print(f\"Tested params: {params}, Score: {avg_score}\")\n",
    "    \n",
    "    if avg_score < best_score:\n",
    "        best_score = avg_score\n",
    "        best_params_auto = params\n",
    "        \n",
    "\n",
    "print(f\"Best parameters: {best_params_auto}, Best score: {best_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1706938365331789"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoE = AutoEncoder(config,n_input=X_train.shape[1],n_encoder=best_params_auto['n_encoder'])\n",
    "losses = autoE.train(X_train, max_epochs=best_params_auto['epochs'], lr=best_params_auto['lr'])\n",
    "losses[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping params: {'lr': 1e-05, 'epochs': 3000, 'n_hidden_2': 40} due to high score: 0.6185642916115307\n",
      "Tested params: {'lr': 1e-05, 'epochs': 3000, 'n_hidden_2': 40}, Score: 0.6185642916115307\n",
      "Tested params: {'lr': 0.0001, 'epochs': 3000, 'n_hidden_2': 25}, Score: 0.0909688673222744\n",
      "Tested params: {'lr': 0.0001, 'epochs': 11000, 'n_hidden_2': 10}, Score: 0.09024419182337626\n",
      "Skipping params: {'lr': 1e-06, 'epochs': 17000, 'n_hidden_2': 25} due to high score: 0.6313254634054578\n",
      "Tested params: {'lr': 1e-06, 'epochs': 17000, 'n_hidden_2': 25}, Score: 0.6313254634054578\n",
      "Skipping params: {'lr': 1e-06, 'epochs': 13000, 'n_hidden_2': 55} due to high score: 0.6333929824355566\n",
      "Tested params: {'lr': 1e-06, 'epochs': 13000, 'n_hidden_2': 55}, Score: 0.6333929824355566\n",
      "Skipping params: {'lr': 1e-06, 'epochs': 9000, 'n_hidden_2': 40} due to high score: 0.6390195697651001\n",
      "Tested params: {'lr': 1e-06, 'epochs': 9000, 'n_hidden_2': 40}, Score: 0.6390195697651001\n",
      "Skipping params: {'lr': 1e-06, 'epochs': 15000, 'n_hidden_2': 25} due to high score: 0.632384716003542\n",
      "Tested params: {'lr': 1e-06, 'epochs': 15000, 'n_hidden_2': 25}, Score: 0.632384716003542\n",
      "Skipping params: {'lr': 1e-07, 'epochs': 3000, 'n_hidden_2': 10} due to high score: 0.6888689449214547\n",
      "Tested params: {'lr': 1e-07, 'epochs': 3000, 'n_hidden_2': 10}, Score: 0.6888689449214547\n",
      "Skipping params: {'lr': 1e-07, 'epochs': 11000, 'n_hidden_2': 55} due to high score: 0.6788888770435096\n",
      "Tested params: {'lr': 1e-07, 'epochs': 11000, 'n_hidden_2': 55}, Score: 0.6788888770435096\n",
      "Skipping params: {'lr': 1e-06, 'epochs': 3000, 'n_hidden_2': 55} due to high score: 0.6618141224568954\n",
      "Tested params: {'lr': 1e-06, 'epochs': 3000, 'n_hidden_2': 55}, Score: 0.6618141224568954\n",
      "Skipping params: {'lr': 1e-06, 'epochs': 11000, 'n_hidden_2': 25} due to high score: 0.636115427585428\n",
      "Tested params: {'lr': 1e-06, 'epochs': 11000, 'n_hidden_2': 25}, Score: 0.636115427585428\n",
      "Tested params: {'lr': 1e-05, 'epochs': 11000, 'n_hidden_2': 40}, Score: 0.0970254032636999\n",
      "Tested params: {'lr': 0.0001, 'epochs': 17000, 'n_hidden_2': 25}, Score: 0.09090202869370692\n",
      "Tested params: {'lr': 0.0001, 'epochs': 1000, 'n_hidden_2': 10}, Score: 0.11393291237192382\n",
      "Tested params: {'lr': 0.0001, 'epochs': 19000, 'n_hidden_2': 25}, Score: 0.09083573026722255\n",
      "Best parameters: {'lr': 0.0001, 'epochs': 11000, 'n_hidden_2': 10}, Best score: 0.09024419182337626\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "iterations = 15\n",
    "\n",
    "param_space = {\n",
    "    'lr': [0.0001,0.00001,0.000001,0.0000001],\n",
    "    'epochs': np.arange(1000, 20000, 2000).tolist(),\n",
    "    'n_hidden_2': np.arange(X_val.shape[1]+1, 60, 15)\n",
    "}\n",
    "\n",
    "best_score = float('inf')\n",
    "best_params_combined = {}\n",
    "\n",
    "for _ in range(iterations):\n",
    "\n",
    "    # Randomly select parameters\n",
    "    params = {key: random.choice(value) for key, value in param_space.items()}\n",
    "    scores = []\n",
    "\n",
    "    for i, (train_set, _) in enumerate(cross_validator.cross_validation(data_train, n_splits=2, n_repeats=5, random_state=42, stratify=True)):\n",
    "    \n",
    "        train_set = data_processor.encode_nominal_features(train_set)\n",
    "\n",
    "        train_data = train_set.to_numpy()\n",
    "        X_train = train_data[:,:-2]\n",
    "        y_train = train_data[:,-2:]\n",
    "\n",
    "        combined = CombinedModel(autoE,n_hidden_2=params['n_hidden_2'],n_output=y_val.shape[1])\n",
    "\n",
    "        _, val_losses, _ = combined.train(X_train,y_train,X_val,y_val,epochs=params['epochs'], lr=params['lr'],patience=500)\n",
    "\n",
    "\n",
    "        score = val_losses[-1]\n",
    "        scores.append(score)\n",
    "\n",
    "        # Skip to the next parameter set if score > 0.2\n",
    "        if score > 0.2:\n",
    "            print(f\"Skipping params: {params} due to high score: {score}\")\n",
    "            break  # Exit the current for-loop\n",
    "\n",
    "    avg_score = np.mean(scores)\n",
    "\n",
    "    print(f\"Tested params: {params}, Score: {avg_score}\")\n",
    "    \n",
    "    if avg_score < best_score:\n",
    "        best_score = avg_score\n",
    "        best_params_combined = params\n",
    "        \n",
    "\n",
    "print(f\"Best parameters: {best_params_combined}, Best score: {best_score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Model Tested params: {'lr': 1e-05, 'epochs': 18000}, Average Score: 0.09809413994911045\n",
      "FFN Model Tested params: {'lr': 1e-05, 'epochs': 19000, 'n_hidden': 12}, Average Score: 0.1030250682605847\n",
      "Combined Model Tested params: {'lr': 0.0001, 'epochs': 11000, 'n_hidden_2': 10}, Average Score: 0.130989453441213\n",
      "Linear Model Scores: [0.1185287374993094, 0.06864945211059292, 0.09171165434482872, 0.08849421768965238, 0.08810409285273223, 0.11793364841383407, 0.11311571399844014, 0.09297990841031414, 0.10225246500658963, 0.09917150916481103]\n",
      "FFN Model Scores: [0.12444202753050522, 0.0642392203406292, 0.09724921209556625, 0.08712223912576633, 0.08892320689871766, 0.15386638773255762, 0.11090618101110572, 0.09241723607885126, 0.10756072215220035, 0.10352424963994729]\n",
      "Combined Model Scores: [0.1771090263377562, 0.10981703045794589, 0.09633452171992318, 0.10861374350258855, 0.09062366962739594, 0.20350910669208547, 0.15949422890460724, 0.09690454514275289, 0.14452946184303198, 0.12295920018404277]\n"
     ]
    }
   ],
   "source": [
    "linear_scores = []\n",
    "ffn_scores = []\n",
    "combined_scores = []\n",
    "\n",
    "for i, (train_set, test_set) in enumerate(cross_validator.cross_validation(data_train, n_splits=2, n_repeats=5, random_state=42, stratify=True)):\n",
    "\n",
    "    train_set = data_processor.encode_nominal_features(train_set)\n",
    "    test_set = data_processor.encode_nominal_features(test_set)\n",
    "\n",
    "    train_data = train_set.to_numpy()\n",
    "    X_train = train_data[:,:-2]\n",
    "    y_train = train_data[:,-2:]\n",
    "\n",
    "    test_data = test_set.to_numpy()\n",
    "    X_test = test_data[:,:-2]\n",
    "    y_test = test_data[:,-2:]\n",
    "\n",
    "    linear = LinearNetwork(config)\n",
    "    _, linear_val_losses = linear.logistic_regression(X_train,y_train,X_test,y_test,epochs=best_params_linear['epochs'],lr=best_params_linear['lr'],patience=np.inf)\n",
    "\n",
    "    ffn = FeedForwardNetwork(config,n_input=X_train.shape[1],n_hidden_1=best_params_ffn['n_hidden'],n_hidden_2=best_params_ffn['n_hidden'],n_output=y_train.shape[1])\n",
    "    _, ffn_val_losses, _ = ffn.train(X_train,y_train,X_test,y_test,epochs=best_params_ffn['epochs'],lr=best_params_ffn['lr'],patience=np.inf)\n",
    "\n",
    "    autoE = AutoEncoder(config,n_input=X_train.shape[1],n_encoder=best_params_auto['n_encoder'])\n",
    "    losses = autoE.train(X_train, max_epochs=best_params_auto['epochs'], lr=best_params_auto['lr'])\n",
    "    combined = CombinedModel(autoE,n_hidden_2=best_params_combined['n_hidden_2'],n_output=y_test.shape[1])\n",
    "    _, combined_val_losses, _ = combined.train(X_train,y_train,X_test,y_test,epochs=best_params_combined['epochs'], lr=best_params_combined['lr'],patience=np.inf)\n",
    "\n",
    "\n",
    "    linear_score = linear_val_losses[-1]\n",
    "    ffn_score = ffn_val_losses[-1]\n",
    "    combined_score = combined_val_losses[-1]\n",
    "    \n",
    "    linear_scores.append(linear_score)\n",
    "    ffn_scores.append(ffn_score)\n",
    "    combined_scores.append(combined_score)\n",
    "\n",
    "avg_score_linear = np.mean(linear_scores)\n",
    "avg_score_ffn = np.mean(ffn_scores)\n",
    "avg_score_combined = np.mean(combined_scores)\n",
    "\n",
    "print(f\"Linear Model Tested params: {best_params_linear}, Average Score: {avg_score_linear}\")\n",
    "print(f\"FFN Model Tested params: {best_params_ffn}, Average Score: {avg_score_ffn}\")\n",
    "print(f\"Combined Model Tested params: {best_params_combined}, Average Score: {avg_score_combined}\")\n",
    "\n",
    "print(f\"Linear Model Scores: {linear_scores}\")\n",
    "print(f\"FFN Model Scores: {ffn_scores}\")\n",
    "print(f\"Combined Model Scores: {combined_scores}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Model vs. FFN Model: t-statistic = -0.5434423049075543, p-value = 0.5934925289940808\n",
      "Linear Model vs. Combined Model: t-statistic = -2.5010920470186218, p-value = 0.022257435969579537\n",
      "FFN Model vs. Combined Model: t-statistic = -1.9443903676965, p-value = 0.0676453571673575\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "t_stat, p_val = stats.ttest_ind(linear_scores, ffn_scores)\n",
    "print(f\"Linear Model vs. FFN Model: t-statistic = {t_stat}, p-value = {p_val}\")\n",
    "\n",
    "# Comparing Linear Model vs. Combined Model\n",
    "t_stat, p_val = stats.ttest_ind(linear_scores, combined_scores)\n",
    "print(f\"Linear Model vs. Combined Model: t-statistic = {t_stat}, p-value = {p_val}\")\n",
    "\n",
    "# Comparing FFN Model vs. Combined Model\n",
    "t_stat, p_val = stats.ttest_ind(ffn_scores, combined_scores)\n",
    "print(f\"FFN Model vs. Combined Model: t-statistic = {t_stat}, p-value = {p_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANOVA result: F-statistic = 4.08609733111498, p-value = 0.02816553445288122\n",
      " Multiple Comparison of Means - Tukey HSD, FWER=0.05  \n",
      "======================================================\n",
      " group1  group2 meandiff p-adj   lower   upper  reject\n",
      "------------------------------------------------------\n",
      "Combined    FFN   -0.028 0.0803 -0.0587  0.0028  False\n",
      "Combined Linear  -0.0329 0.0344 -0.0637 -0.0021   True\n",
      "     FFN Linear  -0.0049 0.9169 -0.0357  0.0258  False\n",
      "------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Combine all scores into a single array, and create an array of labels\n",
    "scores = np.concatenate([linear_scores, ffn_scores, combined_scores])\n",
    "labels = ['Linear'] * len(linear_scores) + ['FFN'] * len(ffn_scores) + ['Combined'] * len(combined_scores)\n",
    "\n",
    "# Conduct ANOVA\n",
    "anova_result = stats.f_oneway(linear_scores, ffn_scores, combined_scores)\n",
    "print(f\"ANOVA result: F-statistic = {anova_result.statistic}, p-value = {anova_result.pvalue}\")\n",
    "\n",
    "# If ANOVA shows significant differences, conduct post-hoc testing with Tukey's HSD\n",
    "if anova_result.pvalue < 0.05:\n",
    "    tukey = pairwise_tukeyhsd(endog=scores, groups=labels, alpha=0.05)\n",
    "    print(tukey)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARCHIVED ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = data_train.to_numpy()\n",
    "# X_train = data[:,:-2]\n",
    "# y_train = data[:,-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_test = data_val.to_numpy()\n",
    "# X_val = data_test[:,:-2]\n",
    "# y_val = data_test[:,-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoE = AutoEncoder(config,n_input=X_train.shape[1],n_encoder=5)\n",
    "\n",
    "# autoE.train(X_train, max_epochs=20000, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined = CombinedModel(autoE,n_hidden_2=50,n_output=y_val.shape[1])\n",
    "\n",
    "# loss, val_metrics, final_loss = combined.train(X_train,y_train,X_val,y_val,epochs=10000,lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.min(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.plot(loss)\n",
    "# plt.plot(val_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ffn = FeedForwardNetwork(config,n_input=X_train.shape[1],n_hidden_1=24,n_hidden_2=24,n_output=y_train.shape[1])\n",
    "\n",
    "# loss, val_metrics, final_mse = ffn.train(X_train,y_train,X_val,y_val,5000,0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(loss)\n",
    "# plt.plot(val_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear = LinearNetwork(config)\n",
    "\n",
    "# losses, val_losses = linear.logistic_regression(X_train,y_train,X_val,y_val,epochs=1000,lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(losses)\n",
    "# plt.plot(val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
