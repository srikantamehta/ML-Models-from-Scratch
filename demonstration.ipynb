{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_preprocessor import DataProcessor\n",
    "from data_configs.configs import *\n",
    "from models.neural_networks import *\n",
    "from src.cross_validation import CrossValidation\n",
    "import numpy as np\n",
    "\n",
    "config = car_config\n",
    "data_processor = DataProcessor(config=config)\n",
    "cross_validator = CrossValidation(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Srikanta\\Documents\\Intro to Machine Learning\\programming_assignment_1\\src\\data_preprocessor.py:47: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[column].fillna(data[column].mode()[0], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "raw_data = data_processor.load_data()\n",
    "data_1 = data_processor.impute_missing_values(raw_data)\n",
    "data_2 = data_processor.encode_ordinal_features(data_1)\n",
    "data_3 = data_processor.standardize_data(data_2,data_2,features=['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.341253</td>\n",
       "      <td>-1.341253</td>\n",
       "      <td>-1.341253</td>\n",
       "      <td>-1.22439</td>\n",
       "      <td>-1.22439</td>\n",
       "      <td>-1.22439</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.341253</td>\n",
       "      <td>-1.341253</td>\n",
       "      <td>-1.341253</td>\n",
       "      <td>-1.22439</td>\n",
       "      <td>-1.22439</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.341253</td>\n",
       "      <td>-1.341253</td>\n",
       "      <td>-1.341253</td>\n",
       "      <td>-1.22439</td>\n",
       "      <td>-1.22439</td>\n",
       "      <td>1.22439</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.341253</td>\n",
       "      <td>-1.341253</td>\n",
       "      <td>-1.341253</td>\n",
       "      <td>-1.22439</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-1.22439</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.341253</td>\n",
       "      <td>-1.341253</td>\n",
       "      <td>-1.341253</td>\n",
       "      <td>-1.22439</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1723</th>\n",
       "      <td>1.341253</td>\n",
       "      <td>1.341253</td>\n",
       "      <td>1.341253</td>\n",
       "      <td>1.22439</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1724</th>\n",
       "      <td>1.341253</td>\n",
       "      <td>1.341253</td>\n",
       "      <td>1.341253</td>\n",
       "      <td>1.22439</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.22439</td>\n",
       "      <td>vgood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1725</th>\n",
       "      <td>1.341253</td>\n",
       "      <td>1.341253</td>\n",
       "      <td>1.341253</td>\n",
       "      <td>1.22439</td>\n",
       "      <td>1.22439</td>\n",
       "      <td>-1.22439</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1726</th>\n",
       "      <td>1.341253</td>\n",
       "      <td>1.341253</td>\n",
       "      <td>1.341253</td>\n",
       "      <td>1.22439</td>\n",
       "      <td>1.22439</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1727</th>\n",
       "      <td>1.341253</td>\n",
       "      <td>1.341253</td>\n",
       "      <td>1.341253</td>\n",
       "      <td>1.22439</td>\n",
       "      <td>1.22439</td>\n",
       "      <td>1.22439</td>\n",
       "      <td>vgood</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1728 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        buying     maint     doors  persons  lug_boot   safety  Class\n",
       "0    -1.341253 -1.341253 -1.341253 -1.22439  -1.22439 -1.22439  unacc\n",
       "1    -1.341253 -1.341253 -1.341253 -1.22439  -1.22439  0.00000  unacc\n",
       "2    -1.341253 -1.341253 -1.341253 -1.22439  -1.22439  1.22439  unacc\n",
       "3    -1.341253 -1.341253 -1.341253 -1.22439   0.00000 -1.22439  unacc\n",
       "4    -1.341253 -1.341253 -1.341253 -1.22439   0.00000  0.00000  unacc\n",
       "...        ...       ...       ...      ...       ...      ...    ...\n",
       "1723  1.341253  1.341253  1.341253  1.22439   0.00000  0.00000   good\n",
       "1724  1.341253  1.341253  1.341253  1.22439   0.00000  1.22439  vgood\n",
       "1725  1.341253  1.341253  1.341253  1.22439   1.22439 -1.22439  unacc\n",
       "1726  1.341253  1.341253  1.341253  1.22439   1.22439  0.00000   good\n",
       "1727  1.341253  1.341253  1.341253  1.22439   1.22439  1.22439  vgood\n",
       "\n",
       "[1728 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_val = cross_validator.random_partition(data_3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_val = data_processor.encode_nominal_features(data_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>Class_acc</th>\n",
       "      <th>Class_good</th>\n",
       "      <th>Class_unacc</th>\n",
       "      <th>Class_vgood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>-0.447084</td>\n",
       "      <td>-0.447084</td>\n",
       "      <td>0.447084</td>\n",
       "      <td>-1.22439</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.22439</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1201</th>\n",
       "      <td>0.447084</td>\n",
       "      <td>1.341253</td>\n",
       "      <td>-1.341253</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>-0.447084</td>\n",
       "      <td>-0.447084</td>\n",
       "      <td>1.341253</td>\n",
       "      <td>-1.22439</td>\n",
       "      <td>1.22439</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>1.341253</td>\n",
       "      <td>-0.447084</td>\n",
       "      <td>1.341253</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>0.447084</td>\n",
       "      <td>1.341253</td>\n",
       "      <td>0.447084</td>\n",
       "      <td>1.22439</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-1.22439</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>-1.341253</td>\n",
       "      <td>-1.341253</td>\n",
       "      <td>1.341253</td>\n",
       "      <td>1.22439</td>\n",
       "      <td>-1.22439</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>-1.341253</td>\n",
       "      <td>0.447084</td>\n",
       "      <td>0.447084</td>\n",
       "      <td>-1.22439</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1206</th>\n",
       "      <td>0.447084</td>\n",
       "      <td>1.341253</td>\n",
       "      <td>-1.341253</td>\n",
       "      <td>1.22439</td>\n",
       "      <td>-1.22439</td>\n",
       "      <td>-1.22439</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>-1.341253</td>\n",
       "      <td>-1.341253</td>\n",
       "      <td>1.341253</td>\n",
       "      <td>1.22439</td>\n",
       "      <td>-1.22439</td>\n",
       "      <td>1.22439</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084</th>\n",
       "      <td>0.447084</td>\n",
       "      <td>0.447084</td>\n",
       "      <td>-1.341253</td>\n",
       "      <td>-1.22439</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>346 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        buying     maint     doors  persons  lug_boot   safety  Class_acc  \\\n",
       "599  -0.447084 -0.447084  0.447084 -1.22439   0.00000  1.22439          0   \n",
       "1201  0.447084  1.341253 -1.341253  0.00000   0.00000  0.00000          1   \n",
       "628  -0.447084 -0.447084  1.341253 -1.22439   1.22439  0.00000          0   \n",
       "1498  1.341253 -0.447084  1.341253  0.00000   0.00000  0.00000          1   \n",
       "1263  0.447084  1.341253  0.447084  1.22439   0.00000 -1.22439          0   \n",
       "...        ...       ...       ...      ...       ...      ...        ...   \n",
       "100  -1.341253 -1.341253  1.341253  1.22439  -1.22439  0.00000          0   \n",
       "274  -1.341253  0.447084  0.447084 -1.22439   0.00000  0.00000          0   \n",
       "1206  0.447084  1.341253 -1.341253  1.22439  -1.22439 -1.22439          0   \n",
       "101  -1.341253 -1.341253  1.341253  1.22439  -1.22439  1.22439          0   \n",
       "1084  0.447084  0.447084 -1.341253 -1.22439   0.00000  0.00000          0   \n",
       "\n",
       "      Class_good  Class_unacc  Class_vgood  \n",
       "599            0            1            0  \n",
       "1201           0            0            0  \n",
       "628            0            1            0  \n",
       "1498           0            0            0  \n",
       "1263           0            1            0  \n",
       "...          ...          ...          ...  \n",
       "100            0            1            0  \n",
       "274            0            1            0  \n",
       "1206           0            1            0  \n",
       "101            0            1            0  \n",
       "1084           0            1            0  \n",
       "\n",
       "[346 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_linear = {'lr': 0.001, 'epochs': 17000}\n",
    "best_params_ffn = {'lr': 0.0001, 'epochs': 15000, 'n_hidden': 50}\n",
    "best_params_auto = {'lr': 0.0001, 'epochs': 15000, 'n_encoder': 4}\n",
    "best_params_combined = {'lr': 0.001, 'epochs': 19000, 'n_hidden_2': 40}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Fold Cross-Validation ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Model Tested params: {'lr': 0.001, 'epochs': 17000}, Average Score: 0.4013790070896668\n",
      "FFN Model Tested params: {'lr': 0.0001, 'epochs': 15000, 'n_hidden': 50}, Average Score: 0.07533373028744057\n",
      "Combined Model Tested params: {'lr': 0.001, 'epochs': 19000, 'n_hidden_2': 40}, Average Score: 0.13289618117734572\n"
     ]
    }
   ],
   "source": [
    "linear_scores = []\n",
    "ffn_scores = []\n",
    "combined_scores = []\n",
    "\n",
    "for i, (train_set, test_set) in enumerate(cross_validator.cross_validation(data_train, n_splits=2, n_repeats=1, random_state=42, stratify=True)):\n",
    "\n",
    "    train_set = data_processor.encode_nominal_features(train_set)\n",
    "    test_set = data_processor.encode_nominal_features(test_set)\n",
    "\n",
    "    train_data = train_set.to_numpy()\n",
    "    X_train = train_data[:,:-4]\n",
    "    y_train = train_data[:,-4:]\n",
    "\n",
    "    test_data = test_set.to_numpy()\n",
    "    X_test = test_data[:,:-4]\n",
    "    y_test = test_data[:,-4:]\n",
    "\n",
    "    linear = LinearNetwork(config)\n",
    "    _, linear_val_losses = linear.logistic_regression(X_train,y_train,X_test,y_test,epochs=best_params_linear['epochs'],lr=best_params_linear['lr'],patience=500)\n",
    "\n",
    "    ffn = FeedForwardNetwork(config,n_input=X_train.shape[1],n_hidden_1=best_params_ffn['n_hidden'],n_hidden_2=best_params_ffn['n_hidden'],n_output=y_train.shape[1])\n",
    "    _, ffn_val_losses, _ = ffn.train(X_train,y_train,X_test,y_test,epochs=best_params_ffn['epochs'],lr=best_params_ffn['lr'],patience=500)\n",
    "\n",
    "    autoE = AutoEncoder(config,n_input=X_train.shape[1],n_encoder=best_params_auto['n_encoder'])\n",
    "    losses = autoE.train(X_train, max_epochs=best_params_auto['epochs'], lr=best_params_auto['lr'])\n",
    "    combined = CombinedModel(autoE,n_hidden_2=best_params_combined['n_hidden_2'],n_output=y_test.shape[1])\n",
    "    _, combined_val_losses, _ = combined.train(X_train,y_train,X_test,y_test,epochs=best_params_combined['epochs'], lr=best_params_combined['lr'],patience=500)\n",
    "\n",
    "\n",
    "    linear_score = np.min(linear_val_losses)\n",
    "    ffn_score = np.min(ffn_val_losses)\n",
    "    combined_score = np.min(combined_val_losses)\n",
    "    \n",
    "    linear_scores.append(linear_score)\n",
    "    ffn_scores.append(ffn_score)\n",
    "    combined_scores.append(combined_score)\n",
    "\n",
    "avg_score_linear = np.mean(linear_scores)\n",
    "avg_score_ffn = np.mean(ffn_scores)\n",
    "avg_score_combined = np.mean(combined_scores)\n",
    "\n",
    "print(f\"Linear Model Tested params: {best_params_linear}, Average Score: {avg_score_linear}\")\n",
    "print(f\"FFN Model Tested params: {best_params_ffn}, Average Score: {avg_score_ffn}\")\n",
    "print(f\"Combined Model Tested params: {best_params_combined}, Average Score: {avg_score_combined}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1bef9f2b410>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(linear_scores)\n",
    "plt.plot(ffn_scores)\n",
    "plt.plot(combined_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Propagation and Back Propagation ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Model ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Weights:\n",
      " [[0.00446055 0.00323912 0.00831545 0.00809626]\n",
      " [0.00175728 0.00453764 0.00084118 0.00056452]\n",
      " [0.00404031 0.00026058 0.00963457 0.00013669]\n",
      " [0.00847414 0.00886973 0.00477701 0.00170167]\n",
      " [0.00994896 0.00957061 0.00291931 0.00886868]\n",
      " [0.00034229 0.00680761 0.00040041 0.00991561]\n",
      " [0.00120173 0.00130615 0.00071035 0.00259252]]\n",
      "X*W =\n",
      " [[ 0.02212238  0.03035262  0.00560638  0.03561167]\n",
      " [ 0.0133116   0.01978754  0.02655887  0.01577522]\n",
      " [-0.0029115  -0.00642573  0.01080818 -0.00219296]\n",
      " ...\n",
      " [ 0.03463175  0.0375672   0.03208572  0.03381364]\n",
      " [-0.00380071 -0.00687908  0.00320731 -0.01344621]\n",
      " [ 0.01502622  0.00480179  0.01394739  0.00636712]]\n",
      "\n",
      "Softmax(X*W) =\n",
      " [[0.24965893 0.25172217 0.24556943 0.25304947]\n",
      " [0.24861404 0.25022927 0.25192941 0.24922728]\n",
      " [0.24931283 0.24843823 0.2527569  0.24949204]\n",
      " ...\n",
      " [0.2500263  0.25076132 0.24939054 0.24982184]\n",
      " [0.25035301 0.24958351 0.25211365 0.24794984]\n",
      " [0.25124822 0.24869244 0.25097731 0.24908203]]\n",
      "\n",
      "Error =\n",
      " [[-0.24965893 -0.25172217  0.75443057 -0.25304947]\n",
      " [-0.24861404 -0.25022927  0.74807059 -0.24922728]\n",
      " [-0.24931283 -0.24843823  0.7472431  -0.24949204]\n",
      " ...\n",
      " [-0.2500263   0.74923868 -0.24939054 -0.24982184]\n",
      " [-0.25035301 -0.24958351  0.74788635 -0.24794984]\n",
      " [ 0.74875178 -0.24869244 -0.25097731 -0.24908203]]\n",
      "\n",
      "Gradient =\n",
      " [[ -22.50497379 -143.29982467  314.91241045 -149.10761199]\n",
      " [ -16.62707238   28.04494626  -37.08196399   25.66409011]\n",
      " [  11.88079831   40.63445482  -77.57471306   25.05945993]\n",
      " [  22.72816421   -1.97993193  -24.04149857    3.29326628]\n",
      " [  86.30481816   12.87545529 -104.7514137     5.57114025]\n",
      " [  27.28683971   10.26161827  -59.59402216   22.04556418]\n",
      " [ 111.44790957   13.54725395 -155.45286093   30.45769742]]\n",
      "\n",
      "New weights:\n",
      " [[-0.01804442 -0.14006071  0.32322786 -0.14101136]\n",
      " [-0.0148698   0.03258258 -0.03624079  0.02622861]\n",
      " [ 0.01592111  0.04089503 -0.06794014  0.02519615]\n",
      " [ 0.0312023   0.00688979 -0.01926449  0.00499493]\n",
      " [ 0.09625378  0.02244606 -0.1018321   0.01443982]\n",
      " [ 0.02762913  0.01706923 -0.05919362  0.03196117]\n",
      " [ 0.11264964  0.01485341 -0.15474251  0.03305021]]\n",
      "\n",
      "Training Loss=\n",
      " 1.3841999386400363\n",
      "\n",
      "X*W =\n",
      " [[ 0.31200386 -0.16280327  0.05049865 -0.10600619]\n",
      " [ 0.07911959 -0.02066469  0.02039728 -0.00341896]\n",
      " [-0.10818045 -0.16074677  0.42512498 -0.15691977]\n",
      " ...\n",
      " [ 0.19019297 -0.01301989 -0.00709661 -0.03197817]\n",
      " [-0.18283764 -0.15994458  0.49354028 -0.17167674]\n",
      " [ 0.05249891 -0.10370701  0.23305691 -0.14170629]]\n",
      "\n",
      "Softmax(X*W) =\n",
      " [[0.32784171 0.20391919 0.25240267 0.21583643]\n",
      " [0.26533805 0.2401396  0.25020545 0.2443169 ]\n",
      " [0.21711858 0.20600024 0.37009106 0.20679011]\n",
      " ...\n",
      " [0.29088069 0.23738904 0.23879933 0.23293094]\n",
      " [0.19995514 0.20458553 0.39326    0.20219932]\n",
      " [0.25794752 0.22064393 0.30899162 0.21241692]]\n",
      "\n",
      "Error =\n",
      " [[-0.32784171 -0.20391919  0.74759733 -0.21583643]\n",
      " [-0.26533805 -0.2401396   0.74979455 -0.2443169 ]\n",
      " [-0.21711858 -0.20600024  0.62990894 -0.20679011]\n",
      " ...\n",
      " [-0.29088069  0.76261096 -0.23879933 -0.23293094]\n",
      " [-0.19995514 -0.20458553  0.60674    -0.20219932]\n",
      " [ 0.74205248 -0.22064393 -0.30899162 -0.21241692]]\n",
      "\n",
      "Gradient =\n",
      " [[ -16.19716975 -115.99146821  253.06388453 -120.87524658]\n",
      " [ -13.04080103   23.47489088  -31.84402163   21.40993178]\n",
      " [   7.33121455   31.99759703  -57.69251805   18.36370648]\n",
      " [  17.98322987   -2.0723202   -18.09970745    2.18879778]\n",
      " [  71.13859694   10.77005385  -86.32703417    4.41838338]\n",
      " [  20.79825232    6.92479697  -44.87070183   17.14765254]\n",
      " [  90.07700417    8.91365252 -122.48137389   23.4907172 ]]\n",
      "\n",
      "New weights:\n",
      " [[-0.03424159 -0.25605217  0.57629175 -0.2618866 ]\n",
      " [-0.0279106   0.05605747 -0.06808481  0.04763854]\n",
      " [ 0.02325232  0.07289263 -0.12563266  0.04355986]\n",
      " [ 0.04918553  0.00481747 -0.0373642   0.00718373]\n",
      " [ 0.16739238  0.03321611 -0.18815914  0.0188582 ]\n",
      " [ 0.04842738  0.02399403 -0.10406432  0.04910882]\n",
      " [ 0.20272664  0.02376706 -0.27722388  0.05654093]]\n",
      "\n",
      "Training Loss=\n",
      " 1.1011488175438453\n",
      "\n"
     ]
    }
   ],
   "source": [
    "linear = LinearNetwork(config)\n",
    "\n",
    "losses, val_losses = linear.logistic_regression(X_train,y_train,X_test,y_test,epochs=2,lr=best_params_linear['lr'],patience=np.inf,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FFN Model ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer 1 Weights:\n",
      " [[9.14555964e-03 9.02107984e-03 1.02110885e-03 2.46941514e-05\n",
      "  8.07650099e-03]\n",
      " [8.78559727e-03 7.44875777e-03 3.37945023e-04 9.01725594e-03\n",
      "  3.31404290e-03]\n",
      " [6.94623881e-03 1.03687555e-03 5.11046717e-03 1.80693292e-03\n",
      "  6.24299679e-03]\n",
      " [5.62732269e-03 1.49201670e-04 2.64474080e-03 8.53182389e-03\n",
      "  6.43102594e-03]\n",
      " [6.63628088e-03 5.51082017e-04 9.84589274e-03 3.56769289e-03\n",
      "  9.19068313e-03]\n",
      " [1.13424473e-03 5.84709872e-03 2.61846916e-04 7.04291106e-03\n",
      "  4.96378305e-03]]\n",
      "\n",
      "Hidden Layer 2 Weights:\n",
      " [[0.00402463 0.00856175 0.00699011 0.00027559 0.00054404]\n",
      " [0.00071146 0.00717461 0.00761011 0.00670066 0.00859768]\n",
      " [0.00028546 0.00559017 0.00508597 0.00123926 0.00195506]\n",
      " [0.00244397 0.00334034 0.00155638 0.00130922 0.00573794]\n",
      " [0.00589907 0.00553872 0.00067009 0.00353963 0.0084731 ]]\n",
      "\n",
      "Output Layer Weights:\n",
      " [[0.00968621 0.00085368 0.00681911 0.0075328 ]\n",
      " [0.00713899 0.00510209 0.00809516 0.00127928]\n",
      " [0.0085573  0.00633241 0.00678873 0.00904508]\n",
      " [0.00067794 0.00395324 0.00599979 0.00405225]\n",
      " [0.00784207 0.0004092  0.00446593 0.00967764]]\n",
      "\n",
      "Hidden Layer 1 Biases:\n",
      " [[0. 0. 0. 0. 0.]]\n",
      "\n",
      "Hidden Layer 2 Biases:\n",
      " [[0. 0. 0. 0. 0.]]\n",
      "\n",
      "Output Layer Biases:\n",
      " [[0. 0. 0. 0.]]\n",
      "\n",
      "Forward Pass:\n",
      "Z1 = X*W1+b:\n",
      " [[ 0.00167065 -0.01268295  0.02064561  0.01373382  0.01830052]\n",
      " [ 0.03599099  0.03113211  0.01781489  0.01709633  0.03310754]\n",
      " [-0.00394542 -0.00042207 -0.00125882 -0.005618   -0.00721216]\n",
      " ...\n",
      " [ 0.04020464  0.01627198  0.02305763  0.02934354  0.03555635]\n",
      " [-0.00357128  0.00837547 -0.01179013 -0.01800503 -0.00698495]\n",
      " [ 0.00367582  0.00640777 -0.01049422  0.0093127  -0.00107751]]\n",
      "\n",
      "A1 (Hidden 1) = tanh(Z1):\n",
      " [[ 0.00167065 -0.01268227  0.02064267  0.01373296  0.01829848]\n",
      " [ 0.03597545  0.03112206  0.017813    0.01709466  0.03309545]\n",
      " [-0.0039454  -0.00042207 -0.00125882 -0.00561794 -0.00721204]\n",
      " ...\n",
      " [ 0.04018299  0.01627054  0.02305355  0.02933512  0.03554137]\n",
      " [-0.00357127  0.00837528 -0.01178958 -0.01800309 -0.00698484]\n",
      " [ 0.00367581  0.00640769 -0.01049383  0.00931243 -0.00107751]]\n",
      "\n",
      "Z2 = A1*W2:\n",
      " [[ 1.45100265e-04  1.85932289e-04  5.37880071e-05  2.38119167e-05\n",
      "   1.66072023e-04]\n",
      " [ 4.09025676e-04  8.71287690e-04  6.27693825e-04  3.80054596e-04\n",
      "   7.00483845e-04]\n",
      " [-7.28127372e-05 -1.02555992e-04 -5.07694654e-05 -3.83586111e-05\n",
      "  -1.01579999e-04]\n",
      " ...\n",
      " [ 4.61233166e-04  8.84487833e-04  5.91426368e-04  3.12876763e-04\n",
      "   6.76289447e-04]\n",
      " [-9.69828129e-05 -1.35216220e-04 -5.38883887e-05 -7.76853578e-06\n",
      "  -1.15468029e-04]\n",
      " [ 3.27600043e-05  4.39202973e-05  3.48577888e-05  3.93222650e-05\n",
      "   8.08792223e-05]]\n",
      "A2 (Hidden 2) = tanh(Z2):\n",
      " [[ 1.45100264e-04  1.85932287e-04  5.37880070e-05  2.38119167e-05\n",
      "   1.66072021e-04]\n",
      " [ 4.09025653e-04  8.71287470e-04  6.27693743e-04  3.80054578e-04\n",
      "   7.00483730e-04]\n",
      " [-7.28127371e-05 -1.02555992e-04 -5.07694654e-05 -3.83586111e-05\n",
      "  -1.01579999e-04]\n",
      " ...\n",
      " [ 4.61233133e-04  8.84487603e-04  5.91426299e-04  3.12876752e-04\n",
      "   6.76289343e-04]\n",
      " [-9.69828126e-05 -1.35216219e-04 -5.38883886e-05 -7.76853578e-06\n",
      "  -1.15468028e-04]\n",
      " [ 3.27600043e-05  4.39202973e-05  3.48577888e-05  3.93222650e-05\n",
      "   8.08792222e-05]]\n",
      "\n",
      "Classification Output (w/ Softmax):\n",
      " [[0.25000029 0.24999956 0.2500001  0.25000005]\n",
      " [0.25000098 0.24999829 0.25000053 0.2500002 ]\n",
      " [0.24999985 0.25000025 0.24999994 0.24999996]\n",
      " ...\n",
      " [0.25000106 0.24999826 0.25000052 0.25000016]\n",
      " [0.24999979 0.25000031 0.24999993 0.24999997]\n",
      " [0.25000007 0.24999984 0.25000003 0.25000006]]\n",
      "\n",
      "Output Error:\n",
      " [[ 0.25000029  0.24999956 -0.7499999   0.25000005]\n",
      " [ 0.25000098  0.24999829 -0.74999947  0.2500002 ]\n",
      " [ 0.24999985  0.25000025 -0.75000006  0.24999996]\n",
      " ...\n",
      " [ 0.25000106 -0.75000174  0.25000052  0.25000016]\n",
      " [ 0.24999979  0.25000031 -0.75000007  0.24999997]\n",
      " [-0.74999993  0.24999984  0.25000003  0.25000006]]\n",
      "\n",
      "Output Gradients:\n",
      " [[-0.01687737 -0.00862085  0.0343119  -0.00881368]\n",
      " [-0.02952484 -0.0175018   0.06469917 -0.01767253]\n",
      " [-0.01807787 -0.01247114  0.04281924 -0.01227023]\n",
      " [-0.01261053 -0.00765762  0.02812254 -0.0078544 ]\n",
      " [-0.02927541 -0.01486635  0.05954419 -0.01540243]]\n",
      "\n",
      "Hidden Layer 2 Error\n",
      " [[-0.00059616 -0.00269128  0.00089215 -0.00232899  0.00113278]\n",
      " [-0.00059615 -0.00269128  0.00089215 -0.00232899  0.00113279]\n",
      " [-0.00059616 -0.00269129  0.00089215 -0.00232899  0.00113278]\n",
      " ...\n",
      " [ 0.00536928  0.00030179  0.00134847 -0.00028244  0.00518952]\n",
      " [-0.00059616 -0.00269129  0.00089215 -0.00232899  0.00113278]\n",
      " [-0.00346326 -0.00173511 -0.00087642  0.00299286 -0.00224335]]\n",
      "\n",
      "Hidden Layer 2 Gradients:\n",
      " [[ 0.00147325  0.00781474 -0.00279491  0.00770589 -0.00352291]\n",
      " [ 0.00155102  0.00666467 -0.00221065  0.00590868 -0.00272627]\n",
      " [-0.0009376   0.00315658 -0.00169437  0.0042741  -0.00293249]\n",
      " [-0.00186707  0.00740699 -0.00414307  0.01176214 -0.0064993 ]\n",
      " [-0.00092461  0.00793635 -0.00379232  0.01007676 -0.0059506 ]]\n",
      "\n",
      "Hidden Layer 1 Error\n",
      " [[-1.92307266e-05 -1.88071552e-05 -1.13442151e-05 -5.60654992e-06\n",
      "  -1.64652869e-05]\n",
      " [-1.92058012e-05 -1.87918523e-05 -1.13454018e-05 -5.60588573e-06\n",
      "  -1.64526186e-05]\n",
      " [-1.92305238e-05 -1.88102324e-05 -1.13490555e-05 -5.60747533e-06\n",
      "  -1.64700207e-05]\n",
      " ...\n",
      " [ 3.63059164e-05  5.89569447e-05  1.98632768e-05  4.55972422e-05\n",
      "   7.71228909e-05]\n",
      " [-1.92305824e-05 -1.88089207e-05 -1.13474982e-05 -5.60583876e-06\n",
      "  -1.64700804e-05]\n",
      " [-3.53153026e-05 -2.08149312e-05 -1.58208071e-05 -2.45757326e-05\n",
      "  -3.90419777e-05]]\n",
      "\n",
      "Hidden Layer 1 Gradients:\n",
      " [[ 0.00279969  0.00223586  0.00143724  0.00152584  0.00291208]\n",
      " [ 0.00295225  0.00308291  0.00165552  0.00158817  0.00335965]\n",
      " [-0.00035763 -0.00016082 -0.00010102 -0.00053837 -0.000672  ]\n",
      " [-0.000445    0.00084639  0.00013184 -0.00102593 -0.00075305]\n",
      " [ 0.00102478  0.00076757  0.00064331 -0.00018196  0.00028195]\n",
      " [ 0.00010111  0.00080728  0.00049283 -0.00172425 -0.00141267]]\n",
      "\n",
      "New Weights/Biases:\n",
      "Output W:\n",
      " [[0.00968789 0.00085454 0.00681568 0.00753368]\n",
      " [0.00714194 0.00510384 0.00808869 0.00128105]\n",
      " [0.00855911 0.00633366 0.00678445 0.0090463 ]\n",
      " [0.0006792  0.003954   0.00599698 0.00405303]\n",
      " [0.00784499 0.00041069 0.00445998 0.00967918]]\n",
      "\n",
      "Output biases:\n",
      " [[-0.002275 -0.014375  0.031525 -0.014875]]\n",
      "\n",
      "Hidden 2 W:\n",
      " [[0.00402448 0.00856097 0.00699039 0.00027482 0.00054439]\n",
      " [0.0007113  0.00717395 0.00761033 0.00670007 0.00859795]\n",
      " [0.00028555 0.00558986 0.00508614 0.00123883 0.00195535]\n",
      " [0.00244416 0.0033396  0.00155679 0.00130805 0.00573859]\n",
      " [0.00589916 0.00553792 0.00067047 0.00353863 0.00847369]]\n",
      "\n",
      "Hidden 2 biases:\n",
      " [[ 6.86142552e-05  1.46587033e-04 -3.10269592e-05  7.04961003e-05\n",
      "  -2.68894193e-05]]\n",
      "\n",
      "Hidden 1 W:\n",
      " [[9.14527967e-03 9.02085625e-03 1.02096512e-03 2.45415673e-05\n",
      "  8.07620978e-03]\n",
      " [8.78530205e-03 7.44844947e-03 3.37779471e-04 9.01709712e-03\n",
      "  3.31370694e-03]\n",
      " [6.94627458e-03 1.03689163e-03 5.11047727e-03 1.80698676e-03\n",
      "  6.24306399e-03]\n",
      " [5.62736719e-03 1.49117031e-04 2.64472762e-03 8.53192649e-03\n",
      "  6.43110125e-03]\n",
      " [6.63617840e-03 5.51005260e-04 9.84582841e-03 3.56771109e-03\n",
      "  9.19065494e-03]\n",
      " [1.13423461e-03 5.84701799e-03 2.61797632e-04 7.04308348e-03\n",
      "  4.96392432e-03]]\n",
      "\n",
      "Hidden 1 biases:\n",
      " [[1.31886262e-06 1.10545017e-06 7.15930561e-07 5.46950493e-07\n",
      "  1.21731743e-06]]\n",
      "\n",
      "Classification Loss: 1.3658235771332787\n",
      "\n",
      "\n",
      "Forward Pass:\n",
      "Z1 = X*W1+b:\n",
      " [[ 0.0016727  -0.0126814   0.0206466   0.01373522  0.0183029 ]\n",
      " [ 0.03599139  0.03113244  0.01781508  0.01709664  0.03310805]\n",
      " [-0.00394415 -0.00042089 -0.00125809 -0.00561756 -0.00721103]\n",
      " ...\n",
      " [ 0.04020541  0.0162724   0.02305798  0.02934403  0.03555713]\n",
      " [-0.00357012  0.00837662 -0.01178943 -0.01800474 -0.00698401]\n",
      " [ 0.00367705  0.00640863 -0.01049358  0.00931318 -0.00107648]]\n",
      "\n",
      "A1 (Hidden 1) = tanh(Z1):\n",
      " [[ 0.0016727  -0.01268072  0.02064366  0.01373435  0.01830085]\n",
      " [ 0.03597586  0.03112238  0.01781319  0.01709497  0.03309596]\n",
      " [-0.00394413 -0.00042089 -0.00125809 -0.0056175  -0.0072109 ]\n",
      " ...\n",
      " [ 0.04018376  0.01627096  0.02305389  0.02933561  0.03554216]\n",
      " [-0.0035701   0.00837643 -0.01178889 -0.0180028  -0.00698389]\n",
      " [ 0.00367703  0.00640854 -0.0104932   0.00931291 -0.00107648]]\n",
      "\n",
      "Z2 = A1*W2:\n",
      " [[ 2.13749525e-04  3.32547284e-04  2.28097463e-05  9.42931829e-05\n",
      "   1.39250090e-04]\n",
      " [ 4.77643407e-04  1.01779203e-03  5.96713532e-04  4.50448251e-04\n",
      "   6.73661105e-04]\n",
      " [-4.18572023e-06  4.40758709e-05 -8.17798792e-05  3.21689335e-05\n",
      "  -1.28454831e-04]\n",
      " ...\n",
      " [ 5.29859218e-04  1.03099292e-03  5.60455398e-04  3.83258949e-04\n",
      "   6.49479695e-04]\n",
      " [-2.83624428e-05  1.14189258e-05 -8.49051078e-05  6.27712331e-05\n",
      "  -1.42354167e-04]\n",
      " [ 1.01386386e-04  1.90524957e-04  3.85467186e-06  1.09817483e-04\n",
      "   5.40159568e-05]]\n",
      "A2 (Hidden 2) = tanh(Z2):\n",
      " [[ 2.13749522e-04  3.32547272e-04  2.28097463e-05  9.42931827e-05\n",
      "   1.39250089e-04]\n",
      " [ 4.77643371e-04  1.01779168e-03  5.96713461e-04  4.50448221e-04\n",
      "   6.73661003e-04]\n",
      " [-4.18572023e-06  4.40758709e-05 -8.17798790e-05  3.21689335e-05\n",
      "  -1.28454830e-04]\n",
      " ...\n",
      " [ 5.29859168e-04  1.03099255e-03  5.60455339e-04  3.83258931e-04\n",
      "   6.49479603e-04]\n",
      " [-2.83624428e-05  1.14189258e-05 -8.49051076e-05  6.27712330e-05\n",
      "  -1.42354166e-04]\n",
      " [ 1.01386386e-04  1.90524955e-04  3.85467186e-06  1.09817483e-04\n",
      "   5.40159568e-05]]\n",
      "\n",
      "Classification Output (w/ Softmax):\n",
      " [[0.24938749 0.24638726 0.25796078 0.24626447]\n",
      " [0.24938817 0.246386   0.25796121 0.24626462]\n",
      " [0.24938705 0.24638794 0.25796062 0.24626439]\n",
      " ...\n",
      " [0.24938825 0.24638597 0.2579612  0.24626458]\n",
      " [0.24938699 0.246388   0.25796061 0.2462644 ]\n",
      " [0.24938727 0.24638754 0.25796071 0.24626449]]\n",
      "\n",
      "Output Error:\n",
      " [[ 0.24938749  0.24638726 -0.74203922  0.24626447]\n",
      " [ 0.24938817  0.246386   -0.74203879  0.24626462]\n",
      " [ 0.24938705  0.24638794 -0.74203938  0.24626439]\n",
      " ...\n",
      " [ 0.24938825 -0.75361403  0.2579612   0.24626458]\n",
      " [ 0.24938699  0.246388   -0.74203939  0.2462644 ]\n",
      " [-0.75061273  0.24638754  0.25796071  0.24626449]]\n",
      "\n",
      "Output Gradients:\n",
      " [[-0.01534464  0.00107931  0.01304146  0.00122387]\n",
      " [-0.02624501  0.00322693  0.01924087  0.00377721]\n",
      " [-0.01876953 -0.01683795  0.05239654 -0.01678906]\n",
      " [-0.01103009  0.00231274  0.00625463  0.00246273]\n",
      " [-0.02987579 -0.01864844  0.06784049 -0.01931626]]\n",
      "\n",
      "Hidden Layer 2 Error\n",
      " [[-0.00057563 -0.00264802  0.00088852 -0.00230827  0.00113179]\n",
      " [-0.00057563 -0.00264802  0.00088852 -0.00230828  0.0011318 ]\n",
      " [-0.00057564 -0.00264802  0.00088852 -0.00230827  0.00113179]\n",
      " ...\n",
      " [ 0.00538551  0.00033683  0.00133932 -0.0002653   0.00518108]\n",
      " [-0.00057564 -0.00264802  0.00088852 -0.00230827  0.00113179]\n",
      " [-0.00344785 -0.00170127 -0.00088614  0.0030095  -0.00225323]]\n",
      "\n",
      "Hidden Layer 2 Gradients:\n",
      " [[ 0.00145839  0.00778578 -0.00280659  0.00769289 -0.00354018]\n",
      " [ 0.00153717  0.00663712 -0.00221901  0.00589606 -0.00273914]\n",
      " [-0.00094394  0.0031444  -0.00170029  0.00426867 -0.00294115]\n",
      " [-0.00188433  0.00737416 -0.004159    0.0117477  -0.00652271]\n",
      " [-0.00093934  0.0079085  -0.0038073   0.0100646  -0.00597222]]\n",
      "\n",
      "Hidden Layer 1 Error\n",
      " [[-1.87933260e-05 -1.83758231e-05 -1.10890772e-05 -5.39045282e-06\n",
      "  -1.60368586e-05]\n",
      " [-1.87689609e-05 -1.83608638e-05 -1.10902336e-05 -5.38980995e-06\n",
      "  -1.60245149e-05]\n",
      " [-1.87931308e-05 -1.83788316e-05 -1.10938108e-05 -5.39134495e-06\n",
      "  -1.60414736e-05]\n",
      " ...\n",
      " [ 3.66082498e-05  5.91933063e-05  2.00241633e-05  4.57186532e-05\n",
      "   7.73995335e-05]\n",
      " [-1.87931883e-05 -1.83775498e-05 -1.10922889e-05 -5.38977170e-06\n",
      "  -1.60415320e-05]\n",
      " [-3.50338049e-05 -2.06094267e-05 -1.56772308e-05 -2.44797905e-05\n",
      "  -3.87986125e-05]]\n",
      "\n",
      "Hidden Layer 1 Gradients:\n",
      " [[ 2.79444768e-03  2.22861957e-03  1.43365503e-03  1.52227043e-03\n",
      "   2.90632340e-03]\n",
      " [ 2.93167900e-03  3.05922253e-03  1.64260822e-03  1.57627910e-03\n",
      "   3.33828908e-03]\n",
      " [-3.57705288e-04 -1.63193057e-04 -1.01718722e-04 -5.39770498e-04\n",
      "  -6.73080071e-04]\n",
      " [-4.54224107e-04  8.28840928e-04  1.24079033e-04 -1.03537014e-03\n",
      "  -7.65703516e-04]\n",
      " [ 1.01152508e-03  7.51154056e-04  6.34640805e-04 -1.90433829e-04\n",
      "   2.67582674e-04]\n",
      " [ 7.60171702e-05  7.72014657e-04  4.75207053e-04 -1.74282631e-03\n",
      "  -1.44179612e-03]]\n",
      "\n",
      "New Weights/Biases:\n",
      "Output W:\n",
      " [[0.00968943 0.00085444 0.00681438 0.00753356]\n",
      " [0.00714456 0.00510352 0.00808677 0.00128067]\n",
      " [0.00856099 0.00633534 0.00677921 0.00904798]\n",
      " [0.0006803  0.00395377 0.00599635 0.00405279]\n",
      " [0.00784798 0.00041256 0.00445319 0.00968111]]\n",
      "\n",
      "Output biases:\n",
      " [[-0.00450765 -0.02850039  0.06249992 -0.02949187]]\n",
      "\n",
      "Hidden 2 W:\n",
      " [[0.00402433 0.00856019 0.00699067 0.00027405 0.00054474]\n",
      " [0.00071115 0.00717328 0.00761055 0.00669948 0.00859822]\n",
      " [0.00028564 0.00558954 0.00508631 0.00123841 0.00195564]\n",
      " [0.00244435 0.00333886 0.00155721 0.00130687 0.00573924]\n",
      " [0.00589925 0.00553713 0.00067085 0.00353762 0.00847429]]\n",
      "\n",
      "Hidden 2 biases:\n",
      " [[ 1.35909998e-04  2.90369556e-04 -6.16827257e-05  1.39641072e-04\n",
      "  -5.35376759e-05]]\n",
      "\n",
      "Hidden 1 W:\n",
      " [[9.14500023e-03 9.02063339e-03 1.02082176e-03 2.43893402e-05\n",
      "  8.07591915e-03]\n",
      " [8.78500888e-03 7.44814355e-03 3.37615210e-04 9.01693949e-03\n",
      "  3.31337311e-03]\n",
      " [6.94631035e-03 1.03690795e-03 5.11048745e-03 1.80704074e-03\n",
      "  6.24313130e-03]\n",
      " [5.62741261e-03 1.49034147e-04 2.64471521e-03 8.53203002e-03\n",
      "  6.43117782e-03]\n",
      " [6.63607725e-03 5.50930144e-04 9.84576495e-03 3.56773013e-03\n",
      "  9.19062818e-03]\n",
      " [1.13422701e-03 5.84694079e-03 2.61750112e-04 7.04325776e-03\n",
      "  4.96406850e-03]]\n",
      "\n",
      "Hidden 1 biases:\n",
      " [[2.61057537e-06 2.18552917e-06 1.41641248e-06 1.08130047e-06\n",
      "  2.40863503e-06]]\n",
      "\n",
      "Classification Loss: 1.346062821807482\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ffn = FeedForwardNetwork(config,n_input=X_train.shape[1],n_hidden_1=5,n_hidden_2=5,n_output=y_train.shape[1],verbose=True)\n",
    " \n",
    "metrics, val_metrics, final_metric = ffn.train(X_train,y_train,X_test,y_test,epochs=2,lr=best_params_ffn['lr'],patience=np.inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder Model ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Encoder Weights:\n",
      "[[0.00114302 0.00296262 0.0032355  0.00578904]\n",
      " [0.00825401 0.00237674 0.00046043 0.00625786]\n",
      " [0.00468365 0.00357627 0.00807853 0.0004185 ]\n",
      " [0.00812117 0.00396022 0.00128349 0.00551117]\n",
      " [0.00945245 0.0047531  0.00143235 0.00643536]\n",
      " [0.00531645 0.00377731 0.00141302 0.00172905]]\n",
      "\n",
      "Initial Decoder Weights:\n",
      "[[0.00018379 0.00629444 0.00685309 0.00236229 0.00505592 0.00332206]\n",
      " [0.00547388 0.00279516 0.00362544 0.00615789 0.00411428 0.00855833]\n",
      " [0.00321571 0.00080174 0.00047602 0.0058993  0.00502324 0.00452646]\n",
      " [0.00803677 0.00605406 0.00862847 0.00077716 0.00434239 0.00276789]]\n",
      "\n",
      "Initial Encoder Biases:\n",
      "[[0.00114302 0.00296262 0.0032355  0.00578904]\n",
      " [0.00825401 0.00237674 0.00046043 0.00625786]\n",
      " [0.00468365 0.00357627 0.00807853 0.0004185 ]\n",
      " [0.00812117 0.00396022 0.00128349 0.00551117]\n",
      " [0.00945245 0.0047531  0.00143235 0.00643536]\n",
      " [0.00531645 0.00377731 0.00141302 0.00172905]]\n",
      "\n",
      "Initial Decoder Biases:\n",
      "[[0.00018379 0.00629444 0.00685309 0.00236229 0.00505592 0.00332206]\n",
      " [0.00547388 0.00279516 0.00362544 0.00615789 0.00411428 0.00855833]\n",
      " [0.00321571 0.00080174 0.00047602 0.0058993  0.00502324 0.00452646]\n",
      " [0.00803677 0.00605406 0.00862847 0.00077716 0.00434239 0.00276789]]\n",
      "\n",
      "Forward Pass:\n",
      "\n",
      "\n",
      "Encoder layer Z1;\n",
      "[[ 0.02170453  0.01292867  0.0109335   0.00114764]\n",
      " [ 0.02702517  0.0175538   0.01770488  0.01996785]\n",
      " [-0.00467029 -0.00351191  0.0007996  -0.00635112]\n",
      " ...\n",
      " [ 0.03938067  0.01997753  0.01622469  0.02617009]\n",
      " [-0.02158014 -0.00615858  0.00442032 -0.00947334]\n",
      " [ 0.00047728 -0.00018254 -0.00214165  0.00406731]]\n",
      "\n",
      "Encoder Activation Function (Sigmoid) A1 = sigmoid(Z1):\n",
      "[[0.50542592 0.50323212 0.50273335 0.50028691]\n",
      " [0.50675588 0.50438834 0.5044261  0.5049918 ]\n",
      " [0.49883243 0.49912202 0.5001999  0.49841222]\n",
      " ...\n",
      " [0.5098439  0.50499422 0.50405608 0.50654215]\n",
      " [0.49460517 0.49846036 0.50110508 0.49763168]\n",
      " [0.50011932 0.49995437 0.49946459 0.50101683]]\n",
      "\n",
      "Decoder layer output:\n",
      "[[0.00848486 0.00801982 0.00984419 0.00764739 0.00932362 0.00964622]\n",
      " [0.00853469 0.00806126 0.00989889 0.0076713  0.00936403 0.00968122]\n",
      " [0.00843794 0.00795345 0.00976672 0.00759011 0.00925251 0.00957249]\n",
      " ...\n",
      " [0.00854984 0.00809148 0.00993545 0.00768134 0.00938701 0.00969928]\n",
      " [0.00843018 0.00792099 0.00972905 0.00758078 0.00922957 0.00955472]\n",
      " [0.0084613  0.00797905 0.00980068 0.00759596 0.00927005 0.00958777]]\n",
      "\n",
      "Decoder error:\n",
      "[[ 1.34973739  1.34927234 -1.33140834 -1.21674304 -1.21506682 -1.21474422]\n",
      " [-1.33271783 -1.33319126 -1.33135363  1.23206173 -1.2150264  -1.21470922]\n",
      " [ 0.45552211 -0.43913073 -0.43731746  1.23198054  0.00925251  0.00957249]\n",
      " ...\n",
      " [-0.43853433 -1.33316104 -1.33131707 -1.21670909 -1.21500343  0.00969928]\n",
      " [-1.33282235  0.45500516 -0.43735513  1.23197122  1.23362001  0.00955472]\n",
      " [-0.43862288 -0.43910512  0.45688485 -1.21679448  1.23366049  0.00958777]]\n",
      "\n",
      "Decoder gradients:\n",
      "[[ 3.40759049 16.2561323  -3.14255344 -9.13011594  8.19589833  4.75922937]\n",
      " [ 3.0985633  17.26246912 -2.91097138 -8.42699439  9.05386072  5.10703363]\n",
      " [ 2.97912684 17.5951377  -3.66009445 -7.97274436  9.62040547  5.51663336]\n",
      " [ 2.61623731 16.62963759 -2.40606064 -8.65932008  8.75004055  5.46521914]]\n",
      "\n",
      "Decoder Biases:\n",
      "[  7.18336838  35.463224    -4.41187412 -15.56428235  19.87206271\n",
      "  11.5221721 ]\n",
      "\n",
      "Encoder error:\n",
      "[[-0.00335868 -0.0041386  -0.00349781 -0.00051402]\n",
      " [-0.00625597 -0.00591362 -0.00258021 -0.00948663]\n",
      " [-0.00067211  0.00184673  0.00206556 -0.00043671]\n",
      " ...\n",
      " [-0.0066426  -0.00583984 -0.0040872  -0.0073181 ]\n",
      " [ 0.00219997  0.0012835   0.00234459 -0.00134745]\n",
      " [ 0.00092032 -0.00107679 -0.00062073  0.00054916]]\n",
      "\n",
      "Encoder gradients:\n",
      "[[-0.08668406 -0.85186207 -0.47640705 -1.45799502]\n",
      " [-1.13851273 -0.59245735 -0.19290643 -1.13651512]\n",
      " [-1.26180539 -0.75463081 -0.16596124 -1.64145628]\n",
      " [-0.38122953 -0.97351873 -0.97362401 -0.05330513]\n",
      " [-0.95208603 -0.79604946 -0.91620895 -0.85478683]\n",
      " [-0.6667391  -1.45454981 -0.74638168 -0.49311243]]\n",
      "\n",
      "Encoder Biases:\n",
      "[0.07406637 0.05174477 0.02739738 0.08511116]\n",
      "\n",
      "New Decoder Weights:\n",
      "[[-0.00015697  0.00466883  0.00716735  0.0032753   0.00423633  0.00284614]\n",
      " [ 0.00516403  0.00106892  0.00391653  0.00700059  0.00320889  0.00804763]\n",
      " [ 0.0029178  -0.00095778  0.00084203  0.00669658  0.0040612   0.00397479]\n",
      " [ 0.00777515  0.0043911   0.00886907  0.0016431   0.00346738  0.00222137]]\n",
      "\n",
      "New Decoder Biases:\n",
      "[[-0.00071834 -0.00354632  0.00044119  0.00155643 -0.00198721 -0.00115222]]\n",
      "\n",
      "New Encoder Weights:\n",
      "[[0.00115169 0.00304781 0.00328314 0.00593484]\n",
      " [0.00836787 0.00243598 0.00047972 0.00637151]\n",
      " [0.00480983 0.00365174 0.00809513 0.00058265]\n",
      " [0.00815929 0.00405758 0.00138085 0.0055165 ]\n",
      " [0.00954766 0.0048327  0.00152397 0.00652084]\n",
      " [0.00538312 0.00392277 0.00148766 0.00177837]]\n",
      "\n",
      "New Encoder Biases:\n",
      "[[-0.00071834 -0.00354632  0.00044119  0.00155643 -0.00198721 -0.00115222]]\n",
      "\n",
      "Output Loss: 0.9895172429415174\n",
      "\n",
      "\n",
      "Forward Pass:\n",
      "\n",
      "\n",
      "Encoder layer Z1;\n",
      "[[ 0.02194692  0.01322575  0.01118602  0.00118287]\n",
      " [ 0.02750286  0.01799993  0.01789853  0.020686  ]\n",
      " [-0.00462094 -0.00361414  0.0006724  -0.00630715]\n",
      " ...\n",
      " [ 0.03986233  0.02040779  0.01652277  0.02671055]\n",
      " [-0.02173366 -0.00625892  0.00424888 -0.00937491]\n",
      " [ 0.00039834 -0.00013515 -0.00211486  0.00400327]]\n",
      "\n",
      "Encoder Activation Function (Sigmoid) A1 = sigmoid(Z1):\n",
      "[[0.50548651 0.50330639 0.50279648 0.50029572]\n",
      " [0.50687528 0.50449986 0.50447451 0.50517132]\n",
      " [0.49884477 0.49909647 0.5001681  0.49842322]\n",
      " ...\n",
      " [0.50996426 0.50510177 0.5041306  0.50667724]\n",
      " [0.4945668  0.49843528 0.50106222 0.49765629]\n",
      " [0.50009959 0.49996621 0.49947129 0.50100082]]\n",
      "\n",
      "Decoder layer output:\n",
      "[[0.00715834 0.00106698 0.01089593 0.01092454 0.00554593 0.00744674]\n",
      " [0.00720708 0.00109454 0.01095521 0.01095669 0.00557936 0.0074778 ]\n",
      " [0.00711541 0.00102577 0.01081302 0.01085264 0.00548712 0.00737935]\n",
      " ...\n",
      " [0.00722041 0.00111655 0.01099278 0.0109712  0.00559821 0.00749341]\n",
      " [0.00710931 0.00100086 0.01077372 0.01083872 0.00546784 0.00736371]\n",
      " [0.00713771 0.00104454 0.01084769 0.0108624  0.00550133 0.00739288]]\n",
      "\n",
      "Decoder error:\n",
      "[[ 1.34841086  1.34231951 -1.33035659 -1.2134659  -1.21884451 -1.2169437 ]\n",
      " [-1.33404544 -1.34015798 -1.33029731  1.23534713 -1.21881107 -1.21691264]\n",
      " [ 0.45419958 -0.44605841 -0.43627116  1.23524308  0.00548712  0.00737935]\n",
      " ...\n",
      " [-0.43986376 -1.34013597 -1.33025975 -1.21341924 -1.21879223  0.00749341]\n",
      " [-1.33414321  0.44808504 -0.43631046  1.23522916  1.22985828  0.00736371]\n",
      " [-0.43994646 -0.44603963  0.45793187 -1.21352803  1.22989177  0.00739288]]\n",
      "\n",
      "Decoder gradients:\n",
      "[[ 2.94791222 13.84016506 -2.80414588 -8.00801374  6.87625345  3.98790276]\n",
      " [ 2.62790965 14.85487921 -2.56447744 -7.31408365  7.7367169   4.32379224]\n",
      " [ 2.51478076 15.19527178 -3.30258922 -6.86049325  8.30174598  4.74588182]\n",
      " [ 2.13239175 14.21304925 -2.07549926 -7.53065488  7.43159339  4.69816694]]\n",
      "\n",
      "Decoder Biases:\n",
      "[  6.26888998  30.67228957  -3.6883378  -13.30764672  17.26826842\n",
      "  10.00570563]\n",
      "\n",
      "Encoder error:\n",
      "[[-4.01981987e-03 -4.75278184e-03 -4.09601861e-03 -1.08599948e-03]\n",
      " [-5.03977639e-03 -4.64658625e-03 -1.31071124e-03 -8.23791100e-03]\n",
      " [-2.97681853e-04  2.22110676e-03  2.42716229e-03 -5.78737904e-05]\n",
      " ...\n",
      " [-6.20714635e-03 -5.31426886e-03 -3.54118993e-03 -6.82527834e-03]\n",
      " [ 2.11251608e-03  1.13340487e-03  2.15160481e-03 -1.49119037e-03]\n",
      " [ 6.31334029e-04 -1.36112485e-03 -8.93284838e-04  2.42289572e-04]]\n",
      "\n",
      "Encoder gradients:\n",
      "[[-0.02048985 -0.79094439 -0.4187606  -1.40536351]\n",
      " [-0.84955211 -0.28623754  0.11893613 -0.84042996]\n",
      " [-1.30005552 -0.7880688  -0.21186891 -1.66693531]\n",
      " [-0.54079756 -1.12110283 -1.11335268 -0.20448283]\n",
      " [-0.81083212 -0.63920982 -0.7497747  -0.70332789]\n",
      " [-0.56901133 -1.34940339 -0.6340696  -0.38166203]]\n",
      "\n",
      "Encoder Biases:\n",
      "[0.04345326 0.02337211 0.00164862 0.05273711]\n",
      "\n",
      "New Decoder Weights:\n",
      "[[-0.00045176  0.00328481  0.00744776  0.0040761   0.00354871  0.00244735]\n",
      " [ 0.00490124 -0.00041657  0.00417298  0.007732    0.00243522  0.00761525]\n",
      " [ 0.00266632 -0.0024773   0.00117229  0.00738263  0.00323102  0.00350021]\n",
      " [ 0.00756191  0.0029698   0.00907662  0.00239616  0.00272422  0.00175155]]\n",
      "\n",
      "New Decoder Biases:\n",
      "[[-0.00134523 -0.00661355  0.00081002  0.00288719 -0.00371403 -0.00215279]]\n",
      "\n",
      "New Encoder Weights:\n",
      "[[0.00115374 0.0031269  0.00332502 0.00607538]\n",
      " [0.00845282 0.0024646  0.00046783 0.00645555]\n",
      " [0.00493983 0.00373054 0.00811632 0.00074934]\n",
      " [0.00821337 0.00416969 0.00149219 0.00553695]\n",
      " [0.00962874 0.00489662 0.00159894 0.00659117]\n",
      " [0.00544003 0.00405771 0.00155106 0.00181653]]\n",
      "\n",
      "New Encoder Biases:\n",
      "[[-0.00134523 -0.00661355  0.00081002  0.00288719 -0.00371403 -0.00215279]]\n",
      "\n",
      "Output Loss: 0.9893815969915417\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "autoE = AutoEncoder(config,n_input=X_train.shape[1],n_encoder=best_params_auto['n_encoder'],verbose=True)\n",
    "losses = autoE.train(X_train, max_epochs=2, lr=best_params_auto['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.006018</td>\n",
       "      <td>-0.004923</td>\n",
       "      <td>0.011807</td>\n",
       "      <td>0.013751</td>\n",
       "      <td>0.002294</td>\n",
       "      <td>0.005554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.006065</td>\n",
       "      <td>-0.004908</td>\n",
       "      <td>0.011870</td>\n",
       "      <td>0.013791</td>\n",
       "      <td>0.002321</td>\n",
       "      <td>0.005581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.005978</td>\n",
       "      <td>-0.004942</td>\n",
       "      <td>0.011718</td>\n",
       "      <td>0.013666</td>\n",
       "      <td>0.002245</td>\n",
       "      <td>0.005492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.005958</td>\n",
       "      <td>-0.004946</td>\n",
       "      <td>0.011680</td>\n",
       "      <td>0.013620</td>\n",
       "      <td>0.002221</td>\n",
       "      <td>0.005460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.006005</td>\n",
       "      <td>-0.004927</td>\n",
       "      <td>0.011774</td>\n",
       "      <td>0.013710</td>\n",
       "      <td>0.002272</td>\n",
       "      <td>0.005525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>0.006008</td>\n",
       "      <td>-0.004921</td>\n",
       "      <td>0.011763</td>\n",
       "      <td>0.013665</td>\n",
       "      <td>0.002254</td>\n",
       "      <td>0.005495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>0.006005</td>\n",
       "      <td>-0.004917</td>\n",
       "      <td>0.011769</td>\n",
       "      <td>0.013670</td>\n",
       "      <td>0.002257</td>\n",
       "      <td>0.005500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>0.006077</td>\n",
       "      <td>-0.004892</td>\n",
       "      <td>0.011908</td>\n",
       "      <td>0.013809</td>\n",
       "      <td>0.002336</td>\n",
       "      <td>0.005595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>0.005974</td>\n",
       "      <td>-0.004960</td>\n",
       "      <td>0.011678</td>\n",
       "      <td>0.013648</td>\n",
       "      <td>0.002229</td>\n",
       "      <td>0.005478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>0.006000</td>\n",
       "      <td>-0.004929</td>\n",
       "      <td>0.011754</td>\n",
       "      <td>0.013679</td>\n",
       "      <td>0.002257</td>\n",
       "      <td>0.005504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>691 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5\n",
       "0    0.006018 -0.004923  0.011807  0.013751  0.002294  0.005554\n",
       "1    0.006065 -0.004908  0.011870  0.013791  0.002321  0.005581\n",
       "2    0.005978 -0.004942  0.011718  0.013666  0.002245  0.005492\n",
       "3    0.005958 -0.004946  0.011680  0.013620  0.002221  0.005460\n",
       "4    0.006005 -0.004927  0.011774  0.013710  0.002272  0.005525\n",
       "..        ...       ...       ...       ...       ...       ...\n",
       "686  0.006008 -0.004921  0.011763  0.013665  0.002254  0.005495\n",
       "687  0.006005 -0.004917  0.011769  0.013670  0.002257  0.005500\n",
       "688  0.006077 -0.004892  0.011908  0.013809  0.002336  0.005595\n",
       "689  0.005974 -0.004960  0.011678  0.013648  0.002229  0.005478\n",
       "690  0.006000 -0.004929  0.011754  0.013679  0.002257  0.005504\n",
       "\n",
       "[691 rows x 6 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "_, Output = autoE.forward_pass(X_train)\n",
    "pd.DataFrame(Output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.341253</td>\n",
       "      <td>-1.341253</td>\n",
       "      <td>1.341253</td>\n",
       "      <td>1.22439</td>\n",
       "      <td>1.22439</td>\n",
       "      <td>1.22439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.341253</td>\n",
       "      <td>1.341253</td>\n",
       "      <td>1.341253</td>\n",
       "      <td>-1.22439</td>\n",
       "      <td>1.22439</td>\n",
       "      <td>1.22439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.447084</td>\n",
       "      <td>0.447084</td>\n",
       "      <td>0.447084</td>\n",
       "      <td>-1.22439</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.447084</td>\n",
       "      <td>0.447084</td>\n",
       "      <td>-0.447084</td>\n",
       "      <td>-1.22439</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-1.22439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.447084</td>\n",
       "      <td>0.447084</td>\n",
       "      <td>0.447084</td>\n",
       "      <td>1.22439</td>\n",
       "      <td>-1.22439</td>\n",
       "      <td>1.22439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>1.341253</td>\n",
       "      <td>1.341253</td>\n",
       "      <td>-1.341253</td>\n",
       "      <td>1.22439</td>\n",
       "      <td>-1.22439</td>\n",
       "      <td>-1.22439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>0.447084</td>\n",
       "      <td>0.447084</td>\n",
       "      <td>-1.341253</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.22439</td>\n",
       "      <td>-1.22439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>0.447084</td>\n",
       "      <td>1.341253</td>\n",
       "      <td>1.341253</td>\n",
       "      <td>1.22439</td>\n",
       "      <td>1.22439</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>1.341253</td>\n",
       "      <td>-0.447084</td>\n",
       "      <td>0.447084</td>\n",
       "      <td>-1.22439</td>\n",
       "      <td>-1.22439</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>0.447084</td>\n",
       "      <td>0.447084</td>\n",
       "      <td>-0.447084</td>\n",
       "      <td>1.22439</td>\n",
       "      <td>-1.22439</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>691 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2        3        4        5\n",
       "0   -1.341253 -1.341253  1.341253  1.22439  1.22439  1.22439\n",
       "1    1.341253  1.341253  1.341253 -1.22439  1.22439  1.22439\n",
       "2   -0.447084  0.447084  0.447084 -1.22439  0.00000  0.00000\n",
       "3   -0.447084  0.447084 -0.447084 -1.22439  0.00000 -1.22439\n",
       "4   -0.447084  0.447084  0.447084  1.22439 -1.22439  1.22439\n",
       "..        ...       ...       ...      ...      ...      ...\n",
       "686  1.341253  1.341253 -1.341253  1.22439 -1.22439 -1.22439\n",
       "687  0.447084  0.447084 -1.341253  0.00000  1.22439 -1.22439\n",
       "688  0.447084  1.341253  1.341253  1.22439  1.22439  0.00000\n",
       "689  1.341253 -0.447084  0.447084 -1.22439 -1.22439  0.00000\n",
       "690  0.447084  0.447084 -0.447084  1.22439 -1.22439  0.00000\n",
       "\n",
       "[691 rows x 6 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined Model ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autoencoder Weights (Hidden Layer 1):\n",
      "[[0.00422861 0.00122079 0.00261815 0.00271042]\n",
      " [0.00641132 0.00041892 0.00161503 0.00853324]\n",
      " [0.00053846 0.00980045 0.00933634 0.00232911]\n",
      " [0.00990359 0.00163403 0.00015616 0.00811577]\n",
      " [0.00098264 0.00580015 0.0021093  0.00671924]\n",
      " [0.00898743 0.00153754 0.00418119 0.00244908]]\n",
      "\n",
      "Autoencoder Biases (Hidden Layer 1):\n",
      "[[-1.56846794e-05 -4.06475103e-06 -2.38550039e-05 -1.45771791e-05]]\n",
      "\n",
      "Hidden Layer 2 Initial Weights:\n",
      "[[8.26039922e-03 9.19512393e-03 1.14180157e-03 6.15840693e-03\n",
      "  6.46925705e-03 3.90094378e-05 6.83475990e-03 1.40343005e-03\n",
      "  4.54699966e-03 9.07006855e-04 8.52278709e-03 5.09487400e-03\n",
      "  2.53126074e-03 9.36573019e-03 2.84495957e-03 8.33950428e-03\n",
      "  8.51412383e-03 9.97451390e-03 8.07235248e-03 1.30426725e-03\n",
      "  2.77575969e-03 7.35672332e-03 6.52548875e-03 4.51257703e-03\n",
      "  1.87486222e-03 6.72790493e-03 3.32154833e-03 5.93478347e-03\n",
      "  6.50181709e-03 3.29309831e-03 5.19496359e-03 5.24406068e-03\n",
      "  4.80259916e-03 3.53178733e-03 6.97927498e-03 2.56675368e-03\n",
      "  7.24557267e-03 1.59437452e-03 7.65049697e-03 8.59613881e-03]\n",
      " [3.02968867e-03 3.42606775e-03 4.71330427e-03 8.31508141e-03\n",
      "  6.46813071e-03 7.38721217e-04 1.27076150e-03 6.22400938e-03\n",
      "  8.18501735e-03 7.80468819e-03 7.12211194e-03 2.46392699e-03\n",
      "  7.57325254e-03 2.83116378e-03 7.34909812e-03 3.63820636e-03\n",
      "  3.33569844e-03 8.03991023e-03 9.97241187e-03 5.70025675e-04\n",
      "  1.88022560e-03 2.90445558e-03 8.70235326e-03 6.37145817e-03\n",
      "  1.00033036e-03 1.85148570e-03 2.89421847e-03 9.76864868e-03\n",
      "  4.21113793e-03 4.80842789e-03 7.17900466e-03 2.62194974e-03\n",
      "  3.61555870e-04 5.31013344e-03 1.21066152e-03 8.05868312e-03\n",
      "  2.17246990e-04 9.36775685e-03 6.15865883e-03 9.33816850e-03]\n",
      " [8.12062072e-03 9.12958719e-03 3.17502307e-03 3.41179725e-03\n",
      "  1.27987585e-03 1.07612191e-03 6.56184892e-03 9.29303137e-03\n",
      "  9.85016820e-03 3.42564040e-03 5.82126769e-04 1.64481216e-04\n",
      "  8.88699099e-03 6.93803996e-03 6.05013957e-03 9.02358206e-03\n",
      "  3.53364771e-03 7.22109654e-03 4.91721649e-03 4.56236205e-03\n",
      "  3.60537217e-03 7.35453621e-03 1.14068613e-03 4.98895060e-03\n",
      "  3.94583273e-03 8.45201777e-03 6.84072939e-03 3.45438814e-03\n",
      "  5.00012021e-03 6.72821737e-03 7.19837165e-03 4.62154309e-03\n",
      "  2.35150923e-03 4.81983700e-03 5.47661683e-03 8.62551141e-03\n",
      "  8.22741199e-03 9.59917015e-03 1.46592830e-03 2.78390214e-03]\n",
      " [2.39290995e-03 1.26977102e-03 1.59929773e-03 1.28865027e-03\n",
      "  8.00025392e-03 1.69082174e-03 6.55433233e-03 5.94567785e-03\n",
      "  2.55401088e-03 9.76626066e-03 4.67152274e-03 6.52419874e-03\n",
      "  8.50532477e-04 8.93106880e-03 4.43273312e-03 8.83529748e-03\n",
      "  5.29873886e-03 2.47205582e-03 3.38586637e-03 2.66843835e-03\n",
      "  2.99973070e-03 4.36752953e-05 8.45514954e-03 9.45478791e-04\n",
      "  1.70694149e-03 3.82226933e-03 4.80635520e-03 4.61357433e-03\n",
      "  8.41228641e-04 1.57481415e-03 3.21543572e-03 3.33850318e-03\n",
      "  4.42148684e-03 4.13180992e-03 7.02813888e-03 8.76091918e-03\n",
      "  7.65922165e-03 5.24527654e-04 5.89808102e-03 2.67594999e-03]]\n",
      "\n",
      "Hidden Layer 2 Initial Biases:\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      "Output Layer Initial Biases:\n",
      "[[9.55826891e-03 8.05528571e-03 3.58315780e-04 6.68586780e-03]\n",
      " [2.25562211e-03 3.45561593e-03 9.76372763e-03 6.50692400e-03]\n",
      " [6.45205787e-03 1.97368241e-03 2.13931567e-04 5.11650906e-03]\n",
      " [8.97496828e-03 8.05731296e-03 7.75632609e-03 3.66339477e-03]\n",
      " [3.83829294e-03 2.53689799e-03 3.67225526e-03 1.07589951e-03]\n",
      " [5.48926398e-03 5.63868328e-03 3.01216600e-03 5.56780414e-03]\n",
      " [9.62397439e-04 1.71688590e-04 7.67561818e-03 8.81864340e-03]\n",
      " [4.65759833e-03 1.31965427e-03 5.88389084e-03 7.15861048e-03]\n",
      " [8.96022965e-03 1.61008805e-03 7.77981170e-03 8.20208643e-03]\n",
      " [8.78080583e-03 3.07548165e-04 5.92840006e-03 7.51755224e-05]\n",
      " [1.51673519e-03 4.51188864e-03 2.30945830e-03 3.49447357e-03]\n",
      " [2.42093991e-03 5.67721456e-03 7.60714438e-03 3.13373682e-03]\n",
      " [1.87790985e-03 9.11782661e-03 1.81478799e-03 9.96478553e-03]\n",
      " [6.74081485e-03 3.83086342e-03 7.91346283e-03 5.11526049e-03]\n",
      " [2.88997061e-03 5.10935280e-03 9.32672824e-03 1.16013736e-03]\n",
      " [3.15042142e-03 8.12608334e-03 7.07658448e-03 1.56570625e-03]\n",
      " [2.79290247e-04 7.20984076e-03 8.38504443e-03 9.13768696e-03]\n",
      " [7.45931584e-03 6.60789056e-03 9.49069605e-03 4.02200589e-03]\n",
      " [8.16675701e-03 5.60003692e-03 8.84317324e-03 8.93211224e-04]\n",
      " [2.43193218e-03 6.93164816e-03 2.73122835e-03 9.56349237e-03]\n",
      " [1.30807943e-03 6.07884550e-03 5.98198356e-03 2.43391838e-03]\n",
      " [1.35533675e-03 1.89446219e-03 5.77044439e-04 5.40617982e-03]\n",
      " [1.42408344e-03 7.56591971e-03 6.11165107e-03 1.47520127e-03]\n",
      " [2.56494689e-03 5.53968016e-03 1.63859261e-04 1.57769745e-03]\n",
      " [8.87620943e-03 5.32681970e-03 8.58132396e-03 1.16826669e-03]\n",
      " [7.33163098e-03 4.87780443e-03 4.56334283e-03 1.12957425e-03]\n",
      " [7.57256206e-03 7.97752271e-03 9.97103501e-03 8.27882794e-03]\n",
      " [7.20695465e-03 8.02068086e-03 4.51007365e-03 4.00488195e-03]\n",
      " [7.53445560e-03 9.84337691e-03 5.09901163e-03 3.18838574e-03]\n",
      " [3.66580782e-03 7.38523126e-03 4.67145436e-03 1.21892623e-03]\n",
      " [2.84457733e-03 8.04003976e-03 5.95020114e-03 9.94867030e-04]\n",
      " [6.61082729e-04 9.25081222e-03 4.95590784e-03 9.06898332e-03]\n",
      " [8.89470288e-04 8.90416472e-03 5.81747974e-03 6.25717691e-03]\n",
      " [3.85520012e-03 7.65016645e-04 5.05596756e-03 1.93780183e-03]\n",
      " [6.42399246e-03 3.18463309e-03 5.30501359e-03 1.96102744e-03]\n",
      " [9.57726884e-03 9.61363275e-03 1.11770832e-03 2.13551257e-03]\n",
      " [4.00831997e-04 2.50845457e-03 9.56770870e-03 9.36803774e-03]\n",
      " [3.55663667e-03 1.00034936e-03 5.30983308e-03 7.20685708e-03]\n",
      " [6.04375006e-04 6.64309213e-03 3.91678468e-03 7.76965871e-04]\n",
      " [5.50393895e-03 9.31493859e-03 7.31019166e-03 2.99735356e-03]]\n",
      "\n",
      "Output Layer Initial Biases:\n",
      "[[0. 0. 0. 0.]]\n",
      "\n",
      "\n",
      "Forward Pass:\n",
      "\n",
      "Encoder layer (Hidden 1):\n",
      "[[ 0.01076881  0.02192644  0.01471399  0.00919122]\n",
      " [ 0.01505876  0.02232357  0.02568711  0.01947867]\n",
      " [-0.01092496  0.00201837  0.0035106  -0.00630685]\n",
      " ...\n",
      " [ 0.02452528  0.02335082  0.01860903  0.03393019]\n",
      " [-0.01029871 -0.00327469  0.004166   -0.01731682]\n",
      " [ 0.01542326 -0.00875355 -0.00469681  0.00568088]]\n",
      "\n",
      "Sigmoid activation function:\n",
      "[[0.50269218 0.50548139 0.50367843 0.50229779]\n",
      " [0.50376462 0.50558066 0.50642143 0.50486951]\n",
      " [0.49726879 0.50050459 0.50087765 0.49842329]\n",
      " ...\n",
      " [0.50613101 0.50583744 0.50465212 0.50848173]\n",
      " [0.49742534 0.49918133 0.5010415  0.4956709 ]\n",
      " [0.50385574 0.49781163 0.4988258  0.50142022]]\n",
      "\n",
      "Second hidden layer:\n",
      "[[0.01097602 0.01159031 0.00535898 ... 0.01063507 0.01065988 0.0117878 ]\n",
      " [0.01101361 0.01162882 0.00537349 ... 0.01066539 0.01068789 0.01181246]\n",
      " [0.01088413 0.0114929  0.00531424 ... 0.01055088 0.01056078 0.01167654]\n",
      " ...\n",
      " [0.01102821 0.01163989 0.00537756 ... 0.01065648 0.01072628 0.01183994]\n",
      " [0.01087616 0.01148781 0.0053043  ... 0.01053887 0.01053784 0.01165862]\n",
      " [0.01092089 0.01152931 0.00530734 ... 0.01051804 0.01060926 0.01171032]]\n",
      "\n",
      "Second hidden layer activation function (tanh):\n",
      "[[0.01097558 0.01158979 0.00535893 ... 0.01063467 0.01065948 0.01178725]\n",
      " [0.01101317 0.01162829 0.00537344 ... 0.01066499 0.01068748 0.01181191]\n",
      " [0.0108837  0.01149239 0.00531419 ... 0.01055049 0.01056039 0.01167601]\n",
      " ...\n",
      " [0.01102777 0.01163937 0.00537751 ... 0.01065608 0.01072587 0.01183939]\n",
      " [0.01087573 0.0114873  0.00530425 ... 0.01053848 0.01053745 0.01165809]\n",
      " [0.01092046 0.0115288  0.00530729 ... 0.01051765 0.01060886 0.01170979]]\n",
      "\n",
      "Classification Output (Softmax):\n",
      "[[0.24996194 0.25004342 0.25007477 0.24991987]\n",
      " [0.24996179 0.25004352 0.25007502 0.24991967]\n",
      " [0.24996227 0.25004301 0.25007412 0.2499206 ]\n",
      " ...\n",
      " [0.24996167 0.25004365 0.25007525 0.24991944]\n",
      " [0.24996231 0.25004293 0.25007398 0.24992078]\n",
      " [0.24996199 0.25004318 0.25007443 0.24992039]]\n",
      "\n",
      "Output Error:\n",
      "[[ 0.24996194  0.25004342 -0.74992523  0.24991987]\n",
      " [ 0.24996179  0.25004352 -0.74992498  0.24991967]\n",
      " [ 0.24996227  0.25004301 -0.74992588  0.2499206 ]\n",
      " ...\n",
      " [ 0.24996167 -0.74995635  0.25007525  0.24991944]\n",
      " [ 0.24996231  0.25004293 -0.74992602  0.24992078]\n",
      " [-0.75003801  0.25004318  0.25007443  0.24992039]]\n",
      "\n",
      "Output Weight Gradients:\n",
      "[[ 0.24104005  1.56516234 -3.4247348   1.6185324 ]\n",
      " [ 0.2545247   1.65259642 -3.61602642  1.7089053 ]\n",
      " [ 0.11834229  0.76337165 -1.67102615  0.78931221]\n",
      " [ 0.21247474  1.37670486 -3.01273135  1.42355176]\n",
      " [ 0.24548157  1.59455495 -3.4891394   1.64910288]\n",
      " [ 0.03939941  0.25447053 -0.55703267  0.26316273]\n",
      " [ 0.23437297  1.52305078 -3.33256841  1.57514466]\n",
      " [ 0.25449572  1.64190211 -3.59418963  1.69779181]\n",
      " [ 0.27942692  1.8050035  -3.95078818  1.86635776]\n",
      " [ 0.24338715  1.57244287 -3.44196223  1.6261322 ]\n",
      " [ 0.23058893  1.49995401 -3.28175525  1.55121231]\n",
      " [ 0.15693767  1.02229193 -2.23659507  1.05736547]\n",
      " [ 0.22106011  1.42511896 -3.11964655  1.47346748]\n",
      " [ 0.30983602  2.0141566  -4.40705893  2.08306631]\n",
      " [ 0.22981641  1.48467576 -3.24970809  1.53521592]\n",
      " [ 0.32995179  2.14145858 -4.68604746  2.21463709]\n",
      " [ 0.22804231  1.4842852  -3.24738413  1.53505662]\n",
      " [ 0.30658306  1.98911398 -4.35257695  2.0568799 ]\n",
      " [ 0.29184416  1.89159425 -4.13946706  1.95602866]\n",
      " [ 0.10105832  0.65367016 -1.43069562  0.67596713]\n",
      " [ 0.12470032  0.80837603 -1.76904666  0.83597032]\n",
      " [ 0.19529227  1.26782285 -2.77410291  1.31098779]\n",
      " [ 0.27456418  1.78173285 -3.89892946  1.84263244]\n",
      " [ 0.18664913  1.20768806 -2.64308648  1.24874928]\n",
      " [ 0.09457296  0.61225851 -1.33995803  0.63312657]\n",
      " [ 0.23066494  1.4969239  -3.27559122  1.54800239]\n",
      " [ 0.19811288  1.28237237 -2.80659852  1.32611327]\n",
      " [ 0.26350486  1.7066357  -3.73493353  1.76479297]\n",
      " [ 0.18309847  1.18847275 -2.60052472  1.22895351]\n",
      " [ 0.18227687  1.17799489 -2.57831691  1.21804515]\n",
      " [ 0.25288339  1.63616712 -3.58091076  1.69186025]\n",
      " [ 0.17497175  1.1360072  -2.48576901  1.17479006]\n",
      " [ 0.13145238  0.85654758 -1.87391154  0.88591157]\n",
      " [ 0.19739684  1.2774848  -2.79590826  1.32102662]\n",
      " [ 0.22837464  1.48512958 -3.24947033  1.5359661 ]\n",
      " [ 0.3113174   2.01110734 -4.40208335  2.07965861]\n",
      " [ 0.25787601  1.67570567 -3.66661868  1.733037  ]\n",
      " [ 0.23530567  1.51462596 -3.31588358  1.56595195]\n",
      " [ 0.23373859  1.51962841 -3.3249508   1.5715838 ]\n",
      " [ 0.25876054  1.67944929 -3.67489764  1.73668781]]\n",
      "\n",
      "Output Bias Gradients:\n",
      "[  22.72384529  143.77978439 -315.19867419  148.69504451]\n",
      "\n",
      "Hidden Layer 2 Error:\n",
      "[[ 0.0058049  -0.00426741  0.00322447 ... -0.00104157 -0.00093088\n",
      "  -0.00102794]\n",
      " [ 0.00580489 -0.0042674   0.00322446 ... -0.00104157 -0.00093088\n",
      "  -0.00102794]\n",
      " [ 0.00580491 -0.00426742  0.00322447 ... -0.00104157 -0.00093088\n",
      "  -0.00102795]\n",
      " ...\n",
      " [-0.00189115  0.00203985  0.00146476 ...  0.00326742 -0.00365687\n",
      "  -0.0030324 ]\n",
      " [ 0.00580491 -0.00426742  0.00322447 ... -0.00104157 -0.00093089\n",
      "  -0.00102795]\n",
      " [-0.00339395  0.00323969 -0.00301348 ...  0.00071143  0.00238115\n",
      "   0.00077806]]\n",
      "\n",
      "Hidden Layer 2 Weight Gradients:\n",
      "[[ 1.1215693  -0.77573614  0.55784835 -0.26878139 -0.2722259   0.40497022\n",
      "  -0.52647109 -0.24613438 -0.39830987 -0.806295    0.23724249 -0.52675252\n",
      "   1.12908274 -0.51311136 -0.97836951 -0.37623794 -0.11668284 -0.63450608\n",
      "  -0.82967013  0.80491724 -0.30715883  0.46121629 -0.29065586  0.51660203\n",
      "  -0.78020765 -0.20204391 -0.2946276   0.24365701  0.22505529 -0.07243335\n",
      "  -0.25151639  0.56643983  0.200376   -0.55215811 -0.38796772  0.77685987\n",
      "  -0.6208767  -0.18743829 -0.07344192 -0.19581317]\n",
      " [ 1.12592726 -0.77912128  0.56042825 -0.26874538 -0.27255442  0.40629088\n",
      "  -0.52935888 -0.24696247 -0.39867888 -0.80665812  0.2373828  -0.52899197\n",
      "   1.13075926 -0.51423593 -0.98161549 -0.37781452 -0.11924386 -0.6359887\n",
      "  -0.83100986  0.80597521 -0.30890383  0.46206136 -0.29233525  0.51813758\n",
      "  -0.78120221 -0.20147107 -0.29576605  0.24487473  0.22621812 -0.07271929\n",
      "  -0.25266112  0.56603629  0.19929128 -0.55334672 -0.38819559  0.780604\n",
      "  -0.62458368 -0.18833906 -0.07440437 -0.19651158]\n",
      " [ 1.12559831 -0.77887815  0.56025567 -0.2687101  -0.27250207  0.40618137\n",
      "  -0.52916465 -0.24688715 -0.39859425 -0.80651846  0.23733907 -0.52883519\n",
      "   1.13052427 -0.5141144  -0.98135463 -0.37770979 -0.11913479 -0.63584094\n",
      "  -0.83083904  0.80581516 -0.30880027  0.46196418 -0.29223988  0.51799774\n",
      "  -0.78105033 -0.2014639  -0.29567994  0.2447889   0.22613352 -0.0727064\n",
      "  -0.25259161  0.56596033  0.19929326 -0.55321697 -0.38812807  0.78034234\n",
      "  -0.6243488  -0.18827003 -0.07436767 -0.19646522]\n",
      " [ 1.12315536 -0.77700152  0.5589237  -0.26864843 -0.2722421   0.40541183\n",
      "  -0.52754584 -0.24632324 -0.39813202 -0.80594442  0.23714008 -0.52765386\n",
      "   1.12923715 -0.5133524  -0.97953299 -0.37694563 -0.11796839 -0.63492157\n",
      "  -0.82990818  0.80498518 -0.30795872  0.46141776 -0.29147068  0.51702165\n",
      "  -0.78028254 -0.20165352 -0.29504172  0.24408942  0.22542798 -0.07263902\n",
      "  -0.25208185  0.56582881  0.19960456 -0.55240912 -0.38784592  0.77824891\n",
      "  -0.6223623  -0.18770108 -0.07401097 -0.19616168]]\n",
      "\n",
      "Hidden Layer 2 Bias Gradients:\n",
      "[ 2.25633649 -1.56165735  1.12372828 -0.53758114 -0.54546652  0.81393747\n",
      " -1.06138317 -0.49450217 -0.79734188 -1.6134994   0.47480535 -1.06045566\n",
      "  2.26310564 -1.02951935 -1.96676375 -0.75759399 -0.24122561 -1.27357372\n",
      " -1.66350037  1.61302475 -0.61984256  0.92510048 -0.58675294  1.03765401\n",
      " -1.56348752 -0.40242104 -0.59270515  0.49084958  0.45335508 -0.14603\n",
      " -0.50686358  1.13144848  0.39718604 -1.10780648 -0.7765915   1.56481371\n",
      " -1.2528061  -0.37733619 -0.15014196 -0.39404711]\n",
      "\n",
      "Hidden Layer 1 (Encoder) Error:\n",
      "[[-4.68154089e-05 -2.69095206e-05 -2.98895394e-05 -4.48882567e-05]\n",
      " [-4.68140350e-05 -2.69093576e-05 -2.98861788e-05 -4.48848849e-05]\n",
      " [-4.68155838e-05 -2.69128775e-05 -2.98911888e-05 -4.48889252e-05]\n",
      " ...\n",
      " [-3.47354833e-05 -3.16947612e-05 -5.65412592e-06 -1.40813042e-05]\n",
      " [-4.68157828e-05 -2.69128645e-05 -2.98911749e-05 -4.48860431e-05]\n",
      " [ 3.85358334e-05 -1.30618998e-06  1.92372319e-05  1.92539575e-05]]\n",
      "\n",
      "Hidden Layer 1 (Encoder) Weight Gradients:\n",
      "[[0.00120275 0.00164094 0.00104518 0.00195709]\n",
      " [0.00370436 0.00224009 0.00269117 0.00407414]\n",
      " [0.00218827 0.00082263 0.00122011 0.00165671]\n",
      " [0.0080748  0.00266043 0.00484352 0.00645375]\n",
      " [0.00446525 0.00262453 0.00262883 0.00398063]\n",
      " [0.01242269 0.00544729 0.00721481 0.01015187]]\n",
      "\n",
      "Hidden Layer 1 (Encoder) Bias Gradients:\n",
      "[-0.01703931 -0.01280945 -0.01147312 -0.01847152]\n",
      "\n",
      "New Weights/Biases:\n",
      "Output W:\n",
      " [[ 9.31722886e-03  6.49012337e-03  3.78305058e-03  5.06733539e-03]\n",
      " [ 2.00109741e-03  1.80301951e-03  1.33797540e-02  4.79801870e-03]\n",
      " [ 6.33371558e-03  1.21031077e-03  1.88495771e-03  4.32719685e-03]\n",
      " [ 8.76249354e-03  6.68060810e-03  1.07690574e-02  2.23984301e-03]\n",
      " [ 3.59281137e-03  9.42343044e-04  7.16139466e-03 -5.73203371e-04]\n",
      " [ 5.44986457e-03  5.38421275e-03  3.56919867e-03  5.30464141e-03]\n",
      " [ 7.28024470e-04 -1.35136219e-03  1.10081866e-02  7.24349874e-03]\n",
      " [ 4.40310261e-03 -3.22247839e-04  9.47808047e-03  5.46081867e-03]\n",
      " [ 8.68080273e-03 -1.94915452e-04  1.17305999e-02  6.33572867e-03]\n",
      " [ 8.53741868e-03 -1.26489471e-03  9.37036228e-03 -1.55095668e-03]\n",
      " [ 1.28614627e-03  3.01193463e-03  5.59121355e-03  1.94326125e-03]\n",
      " [ 2.26400224e-03  4.65492263e-03  9.84373944e-03  2.07637135e-03]\n",
      " [ 1.65684974e-03  7.69270766e-03  4.93443454e-03  8.49131805e-03]\n",
      " [ 6.43097882e-03  1.81670683e-03  1.23205218e-02  3.03219418e-03]\n",
      " [ 2.66015420e-03  3.62467704e-03  1.25764363e-02 -3.75078558e-04]\n",
      " [ 2.82046962e-03  5.98462475e-03  1.17626319e-02 -6.48930837e-04]\n",
      " [ 5.12479399e-05  5.72555556e-03  1.16324286e-02  7.60263034e-03]\n",
      " [ 7.15273277e-03  4.61877658e-03  1.38432730e-02  1.96512598e-03]\n",
      " [ 7.87491286e-03  3.70844267e-03  1.29826403e-02 -1.06281744e-03]\n",
      " [ 2.33087386e-03  6.27797799e-03  4.16192397e-03  8.88752524e-03]\n",
      " [ 1.18337912e-03  5.27046948e-03  7.75103022e-03  1.59794806e-03]\n",
      " [ 1.16004448e-03  6.26639339e-04  3.35114735e-03  4.09519203e-03]\n",
      " [ 1.14951926e-03  5.78418687e-03  1.00105805e-02 -3.67431165e-04]\n",
      " [ 2.37829776e-03  4.33199210e-03  2.80694574e-03  3.28948168e-04]\n",
      " [ 8.78163647e-03  4.71456119e-03  9.92128199e-03  5.35140122e-04]\n",
      " [ 7.10096604e-03  3.38088054e-03  7.83893405e-03 -4.18428132e-04]\n",
      " [ 7.37444918e-03  6.69515034e-03  1.27776335e-02  6.95271467e-03]\n",
      " [ 6.94344979e-03  6.31404516e-03  8.24500718e-03  2.24008898e-03]\n",
      " [ 7.35135713e-03  8.65490416e-03  7.69953635e-03  1.95943224e-03]\n",
      " [ 3.48353095e-03  6.20723637e-03  7.24977128e-03  8.81077649e-07]\n",
      " [ 2.59169394e-03  6.40387264e-03  9.53111190e-03 -6.96993216e-04]\n",
      " [ 4.86110975e-04  8.11480502e-03  7.44167684e-03  7.89419326e-03]\n",
      " [ 7.58017905e-04  8.04761713e-03  7.69139128e-03  5.37126533e-03]\n",
      " [ 3.65780328e-03 -5.12468157e-04  7.85187583e-03  6.16775215e-04]\n",
      " [ 6.19561782e-03  1.69950350e-03  8.55448392e-03  4.25061339e-04]\n",
      " [ 9.26595144e-03  7.60252541e-03  5.51979167e-03  5.58539550e-05]\n",
      " [ 1.42955984e-04  8.32748901e-04  1.32343274e-02  7.63500075e-03]\n",
      " [ 3.32133100e-03 -5.14276603e-04  8.62571666e-03  5.64090513e-03]\n",
      " [ 3.70636420e-04  5.12346372e-03  7.24173548e-03 -7.94617930e-04]\n",
      " [ 5.24517841e-03  7.63548930e-03  1.09850893e-02  1.26066574e-03]]\n",
      "\n",
      "Output biases:\n",
      " [[-0.02272385 -0.14377978  0.31519867 -0.14869504]]\n",
      "\n",
      "Hidden 2 W:\n",
      " [[ 0.00713883  0.00997086  0.00058395  0.00642719  0.00674148 -0.00036596\n",
      "   0.00736123  0.00164956  0.00494531  0.0017133   0.00828554  0.00562163\n",
      "   0.00140218  0.00987884  0.00382333  0.00871574  0.00863081  0.01060902\n",
      "   0.00890202  0.00049935  0.00308292  0.00689551  0.00681614  0.00399597\n",
      "   0.00265507  0.00692995  0.00361618  0.00569113  0.00627676  0.00336553\n",
      "   0.00544648  0.00467762  0.00460222  0.00408395  0.00736724  0.00178989\n",
      "   0.00786645  0.00178181  0.00772394  0.00879195]\n",
      " [ 0.00190376  0.00420519  0.00415288  0.00858383  0.00674069  0.00033243\n",
      "   0.00180012  0.00647097  0.0085837   0.00861135  0.00688473  0.00299292\n",
      "   0.00644249  0.0033454   0.00833071  0.00401602  0.00345494  0.0086759\n",
      "   0.01080342 -0.00023595  0.00218913  0.00244239  0.00899469  0.00585332\n",
      "   0.00178153  0.00205296  0.00318998  0.00952377  0.00398492  0.00488115\n",
      "   0.00743167  0.00205591  0.00016226  0.00586348  0.00159886  0.00727808\n",
      "   0.00084183  0.0095561   0.00623306  0.00953468]\n",
      " [ 0.00699502  0.00990847  0.00261477  0.00368051  0.00155238  0.00066994\n",
      "   0.00709101  0.00953992  0.01024876  0.00423216  0.00034479  0.00069332\n",
      "   0.00775647  0.00745215  0.00703149  0.00940129  0.00365278  0.00785694\n",
      "   0.00574806  0.00375655  0.00391417  0.00689257  0.00143293  0.00447095\n",
      "   0.00472688  0.00865348  0.00713641  0.0032096   0.00477399  0.00680092\n",
      "   0.00745096  0.00405558  0.00215222  0.00537305  0.00586474  0.00784517\n",
      "   0.00885176  0.00978744  0.0015403   0.00298037]\n",
      " [ 0.00126975  0.00204677  0.00104037  0.0015573   0.0082725   0.00128541\n",
      "   0.00708188  0.006192    0.00295214  0.01057221  0.00443438  0.00705185\n",
      "  -0.0002787   0.00944442  0.00541227  0.00921224  0.00541671  0.00310698\n",
      "   0.00421577  0.00186345  0.00330769 -0.00041774  0.00874662  0.00042846\n",
      "   0.00248722  0.00402392  0.0051014   0.00436948  0.0006158   0.00164745\n",
      "   0.00346752  0.00277267  0.00422188  0.00468422  0.00741598  0.00798267\n",
      "   0.00828158  0.00071223  0.00597209  0.00287211]]\n",
      "\n",
      "Hidden 2 biases:\n",
      " [[-0.00225634  0.00156166 -0.00112373  0.00053758  0.00054547 -0.00081394\n",
      "   0.00106138  0.0004945   0.00079734  0.0016135  -0.00047481  0.00106046\n",
      "  -0.00226311  0.00102952  0.00196676  0.00075759  0.00024123  0.00127357\n",
      "   0.0016635  -0.00161302  0.00061984 -0.0009251   0.00058675 -0.00103765\n",
      "   0.00156349  0.00040242  0.00059271 -0.00049085 -0.00045336  0.00014603\n",
      "   0.00050686 -0.00113145 -0.00039719  0.00110781  0.00077659 -0.00156481\n",
      "   0.00125281  0.00037734  0.00015014  0.00039405]]\n",
      "\n",
      "Hidden 1 W:\n",
      " [[0.00422741 0.00121915 0.0026171  0.00270847]\n",
      " [0.00640762 0.00041668 0.00161234 0.00852917]\n",
      " [0.00053627 0.00979963 0.00933512 0.00232745]\n",
      " [0.00989552 0.00163137 0.00015131 0.00810931]\n",
      " [0.00097817 0.00579752 0.00210667 0.00671525]\n",
      " [0.00897501 0.00153209 0.00417398 0.00243893]]\n",
      "\n",
      "Hidden 1 biases:\n",
      " [[ 1.35462634e-06  8.74469659e-06 -1.23818808e-05  3.89433912e-06]]\n",
      "\n",
      "Classification Loss: 1.1976455696817145\n",
      "\n",
      "\n",
      "Forward Pass:\n",
      "\n",
      "Encoder layer (Hidden 1):\n",
      "[[ 0.01075893  0.02193021  0.01471086  0.00919035]\n",
      " [ 0.01505549  0.02232344  0.02568582  0.01947743]\n",
      " [-0.01090013  0.0020338   0.00352672 -0.00628216]\n",
      " ...\n",
      " [ 0.02451852  0.02335232  0.01860565  0.03392733]\n",
      " [-0.01026725 -0.00325697  0.00418588 -0.01728712]\n",
      " [ 0.01543466 -0.00874216 -0.00468917  0.00569437]]\n",
      "\n",
      "Sigmoid activation function:\n",
      "[[0.50268971 0.50548233 0.50367765 0.50229757]\n",
      " [0.5037638  0.50558063 0.5064211  0.5048692 ]\n",
      " [0.49727499 0.50050845 0.50088168 0.49842946]\n",
      " ...\n",
      " [0.50612932 0.50583781 0.50465128 0.50848102]\n",
      " [0.49743321 0.49918576 0.50104647 0.49567833]\n",
      " [0.50385859 0.49781447 0.49882771 0.50142359]]\n",
      "\n",
      "Second hidden layer:\n",
      "[[0.00645563 0.01471832 0.0031086  ... 0.01139094 0.01095917 0.01257708]\n",
      " [0.00648594 0.01476189 0.00311949 ... 0.01142247 0.01098766 0.01260303]\n",
      " [0.00638304 0.01460779 0.00307345 ... 0.01130364 0.01085894 0.01246261]\n",
      " ...\n",
      " [0.00649552 0.01477641 0.00312107 ... 0.0114144  0.01102638 0.01263137]\n",
      " [0.00637931 0.01459981 0.00306562 ... 0.01129093 0.01083574 0.01244398]\n",
      " [0.00641434 0.01464788 0.00306385 ... 0.01127166 0.01090771 0.01249728]]\n",
      "\n",
      "Second hidden layer activation function (tanh):\n",
      "[[0.00645554 0.01471725 0.00310859 ... 0.01139045 0.01095873 0.01257642]\n",
      " [0.00648585 0.01476081 0.00311948 ... 0.01142198 0.01098722 0.01260236]\n",
      " [0.00638295 0.01460675 0.00307344 ... 0.01130316 0.01085851 0.01246196]\n",
      " ...\n",
      " [0.00649543 0.01477533 0.00312106 ... 0.0114139  0.01102593 0.0126307 ]\n",
      " [0.00637922 0.01459877 0.00306561 ... 0.01129045 0.01083531 0.01244334]\n",
      " [0.00641425 0.01464683 0.00306384 ... 0.01127118 0.01090728 0.01249663]]\n",
      "\n",
      "Classification Output (Softmax):\n",
      "[[0.23971186 0.2123132  0.33681337 0.21116157]\n",
      " [0.23971148 0.21231268 0.33681505 0.21116079]\n",
      " [0.23971281 0.21231446 0.33680889 0.21116384]\n",
      " ...\n",
      " [0.23971121 0.2123124  0.33681619 0.2111602 ]\n",
      " [0.23971298 0.21231471 0.33680799 0.21116431]\n",
      " [0.23971236 0.21231415 0.33681029 0.2111632 ]]\n",
      "\n",
      "Output Error:\n",
      "[[ 0.23971186  0.2123132  -0.66318663  0.21116157]\n",
      " [ 0.23971148  0.21231268 -0.66318495  0.21116079]\n",
      " [ 0.23971281  0.21231446 -0.66319111  0.21116384]\n",
      " ...\n",
      " [ 0.23971121 -0.7876876   0.33681619  0.2111602 ]\n",
      " [ 0.23971298  0.21231471 -0.66319201  0.21116431]\n",
      " [-0.76028764  0.21231415  0.33681029  0.2111632 ]]\n",
      "\n",
      "Output Weight Gradients:\n",
      "[[ 9.46756438e-02  7.51251234e-01 -1.62390144e+00  7.77974565e-01]\n",
      " [ 2.20879728e-01  1.71907536e+00 -3.72024224e+00  1.78028715e+00]\n",
      " [ 4.62697050e-02  3.61093654e-01 -7.81211191e-01  3.73847832e-01]\n",
      " [ 1.61092958e-01  1.25320567e+00 -2.71205212e+00  1.29775348e+00]\n",
      " [ 1.83561825e-01  1.43318468e+00 -3.10116313e+00  1.48441662e+00]\n",
      " [ 1.88928460e-03  1.71120785e-02 -3.67253862e-02  1.77240231e-02]\n",
      " [ 1.91756110e-01  1.49547738e+00 -3.23615367e+00  1.54892018e+00]\n",
      " [ 1.88701813e-01  1.46000887e+00 -3.16063214e+00  1.51192145e+00]\n",
      " [ 2.14906707e-01  1.66483752e+00 -3.60369749e+00  1.72395327e+00]\n",
      " [ 2.15372153e-01  1.66633014e+00 -3.60747982e+00  1.72577753e+00]\n",
      " [ 1.42020862e-01  1.11592440e+00 -2.41372163e+00  1.15577637e+00]\n",
      " [ 1.38997504e-01  1.08550714e+00 -2.34890732e+00  1.12440268e+00]\n",
      " [ 8.13543090e-02  6.34588492e-01 -1.37285166e+00  6.56908856e-01]\n",
      " [ 2.42054169e-01  1.89022458e+00 -4.09007584e+00  1.95779709e+00]\n",
      " [ 2.16907291e-01  1.67697562e+00 -3.63053371e+00  1.73665080e+00]\n",
      " [ 2.47534395e-01  1.93036810e+00 -4.17719630e+00  1.99929381e+00]\n",
      " [ 1.62155692e-01  1.27090059e+00 -2.74938745e+00  1.31633116e+00]\n",
      " [ 2.47546536e-01  1.92713368e+00 -4.17041399e+00  1.99573378e+00]\n",
      " [ 2.49596226e-01  1.93905249e+00 -4.19672554e+00  2.00807682e+00]\n",
      " [ 1.93150551e-02  1.55841335e-01 -3.36531050e-01  1.61374660e-01]\n",
      " [ 1.03814061e-01  8.06986801e-01 -1.74657031e+00  8.35769453e-01]\n",
      " [ 1.04383880e-01  8.20267403e-01 -1.77405439e+00  8.49403111e-01]\n",
      " [ 2.04644432e-01  1.59578491e+00 -3.45320726e+00  1.65277791e+00]\n",
      " [ 9.52750194e-02  7.44734460e-01 -1.61113399e+00  7.71124509e-01]\n",
      " [ 1.12362943e-01  8.68600742e-01 -1.88051733e+00  8.99553650e-01]\n",
      " [ 1.69203934e-01  1.31987096e+00 -2.85599885e+00  1.36692395e+00]\n",
      " [ 1.53038213e-01  1.18869902e+00 -2.57279816e+00  1.23106092e+00]\n",
      " [ 1.64300270e-01  1.28161300e+00 -2.77313018e+00  1.32721691e+00]\n",
      " [ 1.10592329e-01  8.66296361e-01 -1.87398914e+00  8.97100450e-01]\n",
      " [ 1.28666487e-01  9.98426919e-01 -2.16096624e+00  1.03387284e+00]\n",
      " [ 1.87729804e-01  1.45807157e+00 -3.15571593e+00  1.50991456e+00]\n",
      " [ 8.41813866e-02  6.63525738e-01 -1.43489543e+00  6.87188300e-01]\n",
      " [ 7.69605160e-02  6.07293468e-01 -1.31332930e+00  6.29075315e-01]\n",
      " [ 1.68383267e-01  1.30584862e+00 -2.82659050e+00  1.35235862e+00]\n",
      " [ 1.78947513e-01  1.39798842e+00 -3.02492630e+00  1.44799036e+00]\n",
      " [ 1.64193331e-01  1.27879869e+00 -2.76728942e+00  1.32429740e+00]\n",
      " [ 2.13580199e-01  1.66522565e+00 -3.60355558e+00  1.72474973e+00]\n",
      " [ 1.72211627e-01  1.32835800e+00 -2.87592476e+00  1.37535513e+00]\n",
      " [ 1.63356169e-01  1.27873697e+00 -2.76651708e+00  1.32442394e+00]\n",
      " [ 1.88009188e-01  1.46701960e+00 -3.17427831e+00  1.51924952e+00]]\n",
      "\n",
      "Output Bias Gradients:\n",
      "[  15.64140116  117.70916295 -255.26451027  121.91394615]\n",
      "\n",
      "Hidden Layer 2 Error:\n",
      "[[ 0.00217246 -0.00699611  0.00143888 ... -0.00384184 -0.00379333\n",
      "  -0.00413986]\n",
      " [ 0.00217245 -0.00699608  0.00143887 ... -0.00384183 -0.00379332\n",
      "  -0.00413984]\n",
      " [ 0.00217247 -0.00699618  0.00143889 ... -0.00384188 -0.00379337\n",
      "  -0.0041399 ]\n",
      " ...\n",
      " [-0.00053451  0.00457814  0.00211351 ...  0.00529698 -0.0016753\n",
      "  -0.00079077]\n",
      " [ 0.00217247 -0.00699619  0.00143889 ... -0.00384188 -0.00379338\n",
      "  -0.00413991]\n",
      " [-0.00336149  0.00438006 -0.00300983 ...  0.00146184  0.00307692\n",
      "   0.00159913]]\n",
      "\n",
      "Hidden Layer 2 Weight Gradients:\n",
      "[[ 0.27761976 -1.28459885  0.14157169 -0.77322125 -0.86139697  0.22586624\n",
      "  -1.02969711 -0.85663959 -1.05018624 -1.2941421  -0.4047822  -0.83243975\n",
      "   0.35407964 -1.22422421 -1.38546855 -1.15916806 -0.67671762 -1.31244889\n",
      "  -1.43547945  0.39808009 -0.56793484 -0.13076462 -0.94399285 -0.06430093\n",
      "  -0.88463345 -0.76905864 -0.75079491 -0.48795462 -0.29547781 -0.52956826\n",
      "  -0.85628946  0.01593183 -0.17108405 -0.96154894 -0.91384224 -0.18243485\n",
      "  -1.16429749 -0.75682593 -0.66335518 -0.82990762]\n",
      " [ 0.27976299 -1.29028518  0.14306971 -0.77511188 -0.86395665  0.2268228\n",
      "  -1.03470885 -0.85976628 -1.05308091 -1.2966994  -0.40674753 -0.83610174\n",
      "   0.35374018 -1.22816337 -1.39077862 -1.16373882 -0.68135368 -1.31670903\n",
      "  -1.43945784  0.39820933 -0.57080659 -0.13170418 -0.94816344 -0.06446766\n",
      "  -0.88647488 -0.77058244 -0.75372604 -0.48913458 -0.2959855  -0.53150465\n",
      "  -0.85972317  0.01392897 -0.17337018 -0.96451996 -0.91614637 -0.1815262\n",
      "  -1.17033973 -0.75984781 -0.66644511 -0.83295648]\n",
      " [ 0.27963494 -1.28984502  0.14299551 -0.77490883 -0.86370998  0.22674752\n",
      "  -1.03433179 -0.8594908  -1.05277667 -1.29637102 -0.40660552 -0.83582345\n",
      "   0.35368754 -1.22779772 -1.3903424  -1.16337387 -0.68106421 -1.31632111\n",
      "  -1.43905985  0.39813467 -0.57060631 -0.13164249 -0.94785162 -0.06445538\n",
      "  -0.88625257 -0.77039208 -0.75348449 -0.48900863 -0.29592219 -0.53134753\n",
      "  -0.85945457  0.01399555 -0.17326244 -0.96423682 -0.91589858 -0.18153436\n",
      "  -1.16990426 -0.75959397 -0.66622261 -0.83270519]\n",
      " [ 0.27853618 -1.28660431  0.14232034 -0.77369853 -0.86211922  0.2262026\n",
      "  -1.0314509  -0.85755554 -1.05080957 -1.29449702 -0.40554054 -0.83379961\n",
      "   0.35362521 -1.22535978 -1.38730187 -1.16082417 -0.67865829 -1.31375003\n",
      "  -1.43656351  0.39787358 -0.56909571 -0.13111336 -0.94559653 -0.06440421\n",
      "  -0.88499072 -0.76933014 -0.75177843 -0.48826914 -0.29562419 -0.53029369\n",
      "  -0.85757926  0.01483016 -0.17222908 -0.96237143 -0.91438016 -0.18191784\n",
      "  -1.16653085 -0.75775896 -0.66459404 -0.8309983 ]]\n",
      "\n",
      "Hidden Layer 2 Bias Gradients:\n",
      "[ 0.56175929 -2.58634988  0.28791303 -1.55228791 -1.73055637  0.4546347\n",
      " -2.07426318 -1.7224641  -2.10873424 -2.59583654 -0.81560551 -1.67613765\n",
      "  0.70702106 -2.46025974 -2.78721485 -2.33251009 -1.36756981 -2.63786366\n",
      " -2.8831061   0.79655406 -1.14480502 -0.26424936 -1.90096137 -0.12929004\n",
      " -1.7749094  -1.54279033 -1.51046272 -0.97961742 -0.59275714 -1.06528963\n",
      " -1.72333222  0.02560549 -0.3493633  -1.93198346 -1.83462151 -0.36233496\n",
      " -2.34671591 -1.52252575 -1.33640041 -1.6693434 ]\n",
      "\n",
      "Hidden Layer 1 (Encoder) Error:\n",
      "[[-2.13859937e-04 -1.85592319e-04 -1.97138644e-04 -1.78229620e-04]\n",
      " [-2.13853211e-04 -1.85590822e-04 -1.97116051e-04 -1.78215809e-04]\n",
      " [-2.13861910e-04 -1.85616342e-04 -1.97150650e-04 -1.78233396e-04]\n",
      " ...\n",
      " [ 8.41327627e-05  7.93669218e-05  1.10675443e-04  8.29444046e-05]\n",
      " [-2.13863050e-04 -1.85616426e-04 -1.97150785e-04 -1.78222209e-04]\n",
      " [ 8.03768761e-05  3.70726462e-05  5.92099854e-05  5.40260564e-05]]\n",
      "\n",
      "Hidden Layer 1 (Encoder) Weight Gradients:\n",
      "[[0.01317214 0.01293686 0.01291912 0.01160523]\n",
      " [0.02388583 0.02131603 0.0227573  0.0202982 ]\n",
      " [0.00767329 0.00598452 0.00664309 0.00608493]\n",
      " [0.03221609 0.02541644 0.02876131 0.02591493]\n",
      " [0.01934107 0.01667451 0.01740568 0.01594546]\n",
      " [0.04825744 0.03926441 0.04277195 0.03900068]]\n",
      "\n",
      "Hidden Layer 1 (Encoder) Bias Gradients:\n",
      "[-0.08590036 -0.07853513 -0.08085291 -0.07311689]\n",
      "\n",
      "New Weights/Biases:\n",
      "Output W:\n",
      " [[ 9.22255321e-03  5.73887213e-03  5.40695202e-03  4.28936083e-03]\n",
      " [ 1.78021768e-03  8.39441472e-05  1.70999963e-02  3.01773155e-03]\n",
      " [ 6.28744588e-03  8.49217112e-04  2.66616890e-03  3.95334902e-03]\n",
      " [ 8.60140058e-03  5.42740243e-03  1.34811096e-02  9.42089532e-04]\n",
      " [ 3.40924954e-03 -4.90841639e-04  1.02625578e-02 -2.05761999e-03]\n",
      " [ 5.44797528e-03  5.36710067e-03  3.60592406e-03  5.28691739e-03]\n",
      " [ 5.36268359e-04 -2.84683957e-03  1.42443403e-02  5.69457857e-03]\n",
      " [ 4.21440080e-03 -1.78225671e-03  1.26387126e-02  3.94889722e-03]\n",
      " [ 8.46589602e-03 -1.85975297e-03  1.53342974e-02  4.61177541e-03]\n",
      " [ 8.32204653e-03 -2.93122484e-03  1.29778421e-02 -3.27673421e-03]\n",
      " [ 1.14412541e-03  1.89601023e-03  8.00493518e-03  7.87484885e-04]\n",
      " [ 2.12500474e-03  3.56941550e-03  1.21926468e-02  9.51968677e-04]\n",
      " [ 1.57549543e-03  7.05811916e-03  6.30728619e-03  7.83440919e-03]\n",
      " [ 6.18892465e-03 -7.35177534e-05  1.64105976e-02  1.07439709e-03]\n",
      " [ 2.44324691e-03  1.94770142e-03  1.62069700e-02 -2.11172936e-03]\n",
      " [ 2.57293523e-03  4.05425666e-03  1.59398282e-02 -2.64822465e-03]\n",
      " [-1.10907752e-04  4.45465497e-03  1.43818160e-02  6.28629918e-03]\n",
      " [ 6.90518624e-03  2.69164289e-03  1.80136870e-02 -3.06077941e-05]\n",
      " [ 7.62531663e-03  1.76939018e-03  1.71793658e-02 -3.07089426e-03]\n",
      " [ 2.31155880e-03  6.12213666e-03  4.49845502e-03  8.72615058e-03]\n",
      " [ 1.07956506e-03  4.46348267e-03  9.49760054e-03  7.62178607e-04]\n",
      " [ 1.05566060e-03 -1.93628063e-04  5.12520174e-03  3.24578892e-03]\n",
      " [ 9.44874830e-04  4.18840195e-03  1.34637878e-02 -2.02020908e-03]\n",
      " [ 2.28302274e-03  3.58725764e-03  4.41807973e-03 -4.42176341e-04]\n",
      " [ 8.66927352e-03  3.84596045e-03  1.18017993e-02 -3.64413528e-04]\n",
      " [ 6.93176211e-03  2.06100958e-03  1.06949329e-02 -1.78535209e-03]\n",
      " [ 7.22141097e-03  5.50645132e-03  1.53504317e-02  5.72165375e-03]\n",
      " [ 6.77914952e-03  5.03243216e-03  1.10181374e-02  9.12872073e-04]\n",
      " [ 7.24076480e-03  7.78860780e-03  9.57352549e-03  1.06233179e-03]\n",
      " [ 3.35486446e-03  5.20880945e-03  9.41073752e-03 -1.03299176e-03]\n",
      " [ 2.40396414e-03  4.94580107e-03  1.26868278e-02 -2.20690777e-03]\n",
      " [ 4.01929588e-04  7.45127928e-03  8.87657227e-03  7.20700496e-03]\n",
      " [ 6.81057389e-04  7.44032366e-03  9.00472058e-03  4.74219002e-03]\n",
      " [ 3.48942001e-03 -1.81831677e-03  1.06784663e-02 -7.35583401e-04]\n",
      " [ 6.01667031e-03  3.01515079e-04  1.15794102e-02 -1.02292902e-03]\n",
      " [ 9.10175811e-03  6.32372672e-03  8.28708110e-03 -1.26844345e-03]\n",
      " [-7.06242148e-05 -8.32476750e-04  1.68378830e-02  5.91025102e-03]\n",
      " [ 3.14911938e-03 -1.84263461e-03  1.15016414e-02  4.26555000e-03]\n",
      " [ 2.07280251e-04  3.84472675e-03  1.00082526e-02 -2.11904187e-03]\n",
      " [ 5.05716923e-03  6.16846970e-03  1.41593676e-02 -2.58583774e-04]]\n",
      "\n",
      "Output biases:\n",
      " [[-0.03836525 -0.26148895  0.57046318 -0.27060899]]\n",
      "\n",
      "Hidden 2 W:\n",
      " [[ 0.00686121  0.01125546  0.00044238  0.00720041  0.00760288 -0.00059183\n",
      "   0.00839093  0.0025062   0.0059955   0.00300744  0.00869033  0.00645407\n",
      "   0.0010481   0.01110307  0.0052088   0.00987491  0.00930752  0.01192147\n",
      "   0.0103375   0.00010127  0.00365085  0.00702627  0.00776014  0.00406028\n",
      "   0.0035397   0.00769901  0.00436697  0.00617908  0.00657224  0.0038951\n",
      "   0.00630277  0.00466169  0.00477331  0.00504549  0.00828108  0.00197233\n",
      "   0.00903075  0.00253864  0.00838729  0.00962186]\n",
      " [ 0.001624    0.00549547  0.00400981  0.00935894  0.00760464  0.00010561\n",
      "   0.00283483  0.00733074  0.00963678  0.00990805  0.00729148  0.00382902\n",
      "   0.00608875  0.00457356  0.00972149  0.00517976  0.0041363   0.00999261\n",
      "   0.01224288 -0.00063416  0.00275994  0.0025741   0.00994285  0.00591779\n",
      "   0.00266801  0.00282354  0.00394371  0.01001291  0.00428091  0.00541265\n",
      "   0.00829139  0.00204198  0.00033563  0.006828    0.002515    0.00745961\n",
      "   0.00201217  0.01031594  0.00689951  0.01036764]\n",
      " [ 0.00671539  0.01119831  0.00247177  0.00445542  0.00241609  0.00044319\n",
      "   0.00812535  0.01039941  0.01130154  0.00552853  0.00075139  0.00152914\n",
      "   0.00740278  0.00867995  0.00842184  0.01056467  0.00433385  0.00917326\n",
      "   0.00718712  0.00335841  0.00448478  0.00702421  0.00238078  0.00453541\n",
      "   0.00561314  0.00942387  0.00788989  0.00369861  0.00506991  0.00733227\n",
      "   0.00831042  0.00404159  0.00232548  0.00633729  0.00678064  0.0080267\n",
      "   0.01002167  0.01054703  0.00220652  0.00381307]\n",
      " [ 0.00099122  0.00333338  0.00089805  0.002331    0.00913462  0.00105921\n",
      "   0.00811333  0.00704956  0.00400295  0.0118667   0.00483992  0.00788565\n",
      "  -0.00063233  0.01066978  0.00679957  0.01037307  0.00609537  0.00442073\n",
      "   0.00565234  0.00146558  0.00387679 -0.00028663  0.00969222  0.00049286\n",
      "   0.00337221  0.00479325  0.00585318  0.00485775  0.00091142  0.00217775\n",
      "   0.0043251   0.00275784  0.00439411  0.00564659  0.00833036  0.00816459\n",
      "   0.00944811  0.00146999  0.00663669  0.00370311]]\n",
      "\n",
      "Hidden 2 biases:\n",
      " [[-2.81809578e-03  4.14800723e-03 -1.41164130e-03  2.08986905e-03\n",
      "   2.27602289e-03 -1.26857217e-03  3.13564635e-03  2.21696627e-03\n",
      "   2.90607611e-03  4.20933594e-03  3.40800156e-04  2.73659330e-03\n",
      "  -2.97012670e-03  3.48977909e-03  4.75397860e-03  3.09010408e-03\n",
      "   1.60879541e-03  3.91143738e-03  4.54660647e-03 -2.40957881e-03\n",
      "   1.76464759e-03 -6.60851123e-04  2.48771431e-03 -9.08363968e-04\n",
      "   3.33839692e-03  1.94521136e-03  2.10316786e-03  4.88767844e-04\n",
      "   1.39402061e-04  1.21131963e-03  2.23019580e-03 -1.15705397e-03\n",
      "  -4.78227321e-05  3.03978994e-03  2.61121301e-03 -1.20247875e-03\n",
      "   3.59952201e-03  1.89986194e-03  1.48654237e-03  2.06339051e-03]]\n",
      "\n",
      "Hidden 1 W:\n",
      " [[0.00421424 0.00120621 0.00260418 0.00269686]\n",
      " [0.00638373 0.00039536 0.00158958 0.00850887]\n",
      " [0.0005286  0.00979364 0.00932847 0.00232136]\n",
      " [0.0098633  0.00160596 0.00012255 0.0080834 ]\n",
      " [0.00095883 0.00578085 0.00208927 0.00669931]\n",
      " [0.00892675 0.00149282 0.00413121 0.00239993]]\n",
      "\n",
      "Hidden 1 biases:\n",
      " [[8.72549867e-05 8.72798295e-05 6.84710330e-05 7.70112242e-05]]\n",
      "\n",
      "Classification Loss: 1.0743846273598376\n",
      "\n"
     ]
    }
   ],
   "source": [
    "combined = CombinedModel(autoE,n_hidden_2=best_params_combined['n_hidden_2'],n_output=y_test.shape[1],verbose=True)\n",
    "metrics, val_metrics, final_metric = combined.train(X_train,y_train,X_test,y_test,epochs=2, lr=best_params_combined['lr'],patience=500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
