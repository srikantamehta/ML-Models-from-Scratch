{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_preprocessor import DataProcessor\n",
    "from src.cross_validation import CrossValidation\n",
    "from src.evaluation import Evaluation\n",
    "from models.knn import KNN\n",
    "from models.null_model import NullModelClassification, NullModelRegression\n",
    "from data_configs.configs import *\n",
    "import statistics\n",
    "\n",
    "config = machine_config\n",
    "data_processor = DataProcessor(config=config)\n",
    "cross_validator = CrossValidation(config=config)\n",
    "classification_nullmodel = NullModelClassification(config=config)\n",
    "regression_nullmodel = NullModelRegression(config=config)\n",
    "knn_model = KNN(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Processing\n",
    "\n",
    "raw_data = data_processor.load_data()\n",
    "\n",
    "raw_data_2 = raw_data.drop(columns=['vendor_name', 'model_name', 'ERP'])\n",
    "\n",
    "data_1 = data_processor.impute_missing_values(raw_data_2)\n",
    "\n",
    "data_2 = data_processor.encode_nominal_features(data_1)\n",
    "\n",
    "data_3 = data_processor.encode_ordinal_features(data_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_val = cross_validator.random_partition(data_3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "167"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 1/(statistics.stdev(data_train[config['target_column']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn_model.knn_regression(data_val, data_train, k=3, gamma=gamma)['Predicted Value']\n",
    "y_true = data_val[config['target_column']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7180.144110940322\n",
      "45.97683371699105\n",
      "0.9269983376413438\n",
      "0.8589552552715553\n"
     ]
    }
   ],
   "source": [
    "mean_squared_error = Evaluation.mean_squared_error(y_true,y_pred)\n",
    "mean_absolute_error = Evaluation.mean_absolute_error(y_true,y_pred)\n",
    "pearsons = Evaluation.pearsons_correlation(y_true,y_pred)\n",
    "r2 = Evaluation.r2_coefficient(y_true,y_pred)\n",
    "\n",
    "print(mean_squared_error)\n",
    "print(mean_absolute_error)\n",
    "print(pearsons)\n",
    "print(r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average score for k=1: 14747.816666666662\n",
      "Average score for k=2: 12057.709573541897\n",
      "Average score for k=3: 15740.173597644369\n",
      "Average score for k=4: 16065.49321887955\n",
      "Average score for k=5: 17650.53665647917\n",
      "Average score for k=6: 18655.912174566423\n",
      "Average score for k=7: 19798.93073418003\n",
      "Average score for k=8: 21147.523273674735\n",
      "Average score for k=9: 21260.478827043356\n",
      "Average score for k=10: 22652.243578825844\n"
     ]
    }
   ],
   "source": [
    "hyperparameters = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "for k in hyperparameters: \n",
    "    scores = []\n",
    "    for i, (train_set_1, train_set_2) in enumerate(cross_validator.cross_validation(data_train, n_splits=2, n_repeats=5, stratify=False)):\n",
    "        # Train and evaluate using train_set_1\n",
    "        predictions_1 = knn_model.knn_regression(data_val, train_set_1, k=k, gamma=gamma)['Predicted Value']\n",
    "        score_1 = Evaluation().mean_squared_error(data_val[config['target_column']], predictions_1)\n",
    "        scores.append(score_1)\n",
    "        \n",
    "        # Train and evaluate using train_set_2\n",
    "        predictions_2 = knn_model.knn_regression(data_val, train_set_2, k=k, gamma=gamma)['Predicted Value']\n",
    "        score_2 = Evaluation().mean_squared_error(data_val[config['target_column']], predictions_2)\n",
    "        scores.append(score_2)\n",
    "\n",
    "    average_score = sum(scores) / len(scores)\n",
    "    print(f\"Average score for k={k}: {average_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average score for k=3: 6594.961867407115\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for i, (train_set, test_set) in enumerate(cross_validator.cross_validation(data_train, n_splits=2, n_repeats=5, stratify=False)):\n",
    "    \n",
    "    # Train and evaluate \n",
    "    predictions_1 = knn_model.knn_regression(test_set, train_set, k=2, gamma=gamma)['Predicted Value']\n",
    "    score = Evaluation().mean_squared_error(test_set[config['target_column']], predictions_1)\n",
    "    scores.append(score)\n",
    "\n",
    "average_score = sum(scores) / len(scores)\n",
    "print(f\"Average score for k=3: {average_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average score for k=1: 9356.478571428572\n",
      "Average score for k=2: 13282.71818106153\n",
      "Average score for k=3: 14902.262662967642\n",
      "Average score for k=4: 16895.08135359349\n",
      "Average score for k=5: 18402.23146516731\n",
      "Average score for k=6: 19202.779387705454\n",
      "Average score for k=7: 19645.42328272045\n",
      "Average score for k=8: 20230.15793869439\n",
      "Average score for k=9: 21369.272678890313\n",
      "Average score for k=10: 22153.610026442842\n"
     ]
    }
   ],
   "source": [
    "hyperparameters = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "for k in hyperparameters: \n",
    "    scores = []\n",
    "    for i, (train_set_1, train_set_2) in enumerate(cross_validator.cross_validation(data_train, n_splits=2, n_repeats=5, stratify=False)):\n",
    "        # Train and evaluate using train_set_1\n",
    "        condensed_train_set = knn_model.condensed_knn_regression(train_set_1, 10, k=1)\n",
    "        predictions_1 = knn_model.knn_regression(data_val, condensed_train_set, k=k, gamma=gamma)['Predicted Value']\n",
    "        score_1 = Evaluation().mean_squared_error(data_val[config['target_column']], predictions_1)\n",
    "        scores.append(score_1)\n",
    "    \n",
    "    average_score = sum(scores) / len(scores)\n",
    "    print(f\"Average score for k={k}: {average_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average score for k=1: 41032.94523809524\n",
      "Average score for k=2: 36709.586386263494\n",
      "Average score for k=3: 42864.94885268181\n",
      "Average score for k=4: 41257.95830890771\n",
      "Average score for k=5: 42727.95063529443\n",
      "Average score for k=6: 46681.28897307767\n",
      "Average score for k=7: 46989.845029083546\n",
      "Average score for k=8: 44899.23974069616\n",
      "Average score for k=9: 48892.41752829828\n",
      "Average score for k=10: 45828.07034246535\n"
     ]
    }
   ],
   "source": [
    "hyperparameters = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "for k in hyperparameters: \n",
    "    scores = []\n",
    "    for i, (train_set_1, train_set_2) in enumerate(cross_validator.cross_validation(data_train, n_splits=2, n_repeats=5, stratify=False)):\n",
    "        # Train and evaluate using train_set_1\n",
    "        edited_train_set = knn_model.edited_knn_regression(train_set_1, 10, k=1)\n",
    "        predictions_1 = knn_model.knn_regression(data_val, edited_train_set, k=k, gamma=gamma)['Predicted Value']\n",
    "        score_1 = Evaluation().mean_squared_error(data_val[config['target_column']], predictions_1)\n",
    "        scores.append(score_1)\n",
    "    \n",
    "    average_score = sum(scores) / len(scores)\n",
    "    print(f\"Average score for k={k}: {average_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50906.85317460319"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_model = NullModelRegression(config)\n",
    "\n",
    "null_model_results = null_model.naive_regression(data_val)\n",
    "Evaluation().mean_squared_error(data_val[config['target_column']],null_model_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
