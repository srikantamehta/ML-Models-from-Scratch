{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_preprocessor import DataProcessor\n",
    "from src.cross_validation import CrossValidation\n",
    "from src.evaluation import Evaluation\n",
    "from models.knn import KNN\n",
    "from models.null_model import NullModelClassification, NullModelRegression\n",
    "from data_configs.configs import *\n",
    "import statistics\n",
    "import numpy as np\n",
    "\n",
    "config = machine_config\n",
    "data_processor = DataProcessor(config=config)\n",
    "cross_validator = CrossValidation(config=config)\n",
    "classification_nullmodel = NullModelClassification(config=config)\n",
    "regression_nullmodel = NullModelRegression(config=config)\n",
    "knn_model = KNN(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Load and Preprocessing ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = data_processor.load_data()\n",
    "\n",
    "raw_data_2 = raw_data.drop(columns=['vendor_name', 'model_name', 'ERP'])\n",
    "\n",
    "data_1 = data_processor.impute_missing_values(raw_data_2)\n",
    "\n",
    "data_2 = data_processor.encode_nominal_features(data_1)\n",
    "\n",
    "data_3 = data_processor.encode_ordinal_features(data_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Model ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_val = cross_validator.random_partition(data_3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=['MYCT', 'MMIN', 'MMAX', 'CACH', 'CHMIN', 'CHMAX']\n",
    "data_train_standardized = data_processor.standardize_data(data_train, data_train, features=features)\n",
    "data_val_standardized = data_processor.standardize_data(data_train,data_val,features=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 1/(statistics.stdev(data_train[config['target_column']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning k ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average score with k=1: 17798.197619047616\n",
      "Average score with k=2: 18130.714443969664\n",
      "Average score with k=3: 19429.549781328133\n",
      "Average score with k=4: 20229.203383836924\n",
      "Average score with k=5: 20946.234641294293\n",
      "Average score with k=6: 21517.77057989918\n",
      "Average score with k=7: 21825.922663531157\n",
      "Average score with k=8: 22811.173308884907\n",
      "Average score with k=9: 23356.409988656887\n",
      "Average score with k=10: 24080.393695185834\n",
      "Average score with k=11: 25030.218767346007\n",
      "Average score with k=12: 25813.60692095948\n",
      "Average score with k=13: 26636.683899176558\n",
      "Average score with k=14: 27455.921290165843\n",
      "Best k is 1 with the lowest average score of 17798.197619047616\n"
     ]
    }
   ],
   "source": [
    "hyperparameters = np.arange(1,15,1)\n",
    "scores_dict = {}\n",
    "\n",
    "for k in hyperparameters: \n",
    "    scores = []\n",
    "    for i, (train_set_1, train_set_2) in enumerate(cross_validator.cross_validation(data_train_standardized, n_splits=2, n_repeats=5, random_state=42, stratify=False)):\n",
    "        \n",
    "        predictions_1 = knn_model.knn_regression(data_val_standardized, train_set_1, k=k, gamma=gamma)['Predicted Value']\n",
    "        score_1 = Evaluation().mean_squared_error(data_val_standardized[config['target_column']], predictions_1)\n",
    "        scores.append(score_1)\n",
    "\n",
    "    average_score = sum(scores) / len(scores)\n",
    "    print(f\"Average score with k={k}: {average_score}\")\n",
    "    scores_dict[k] = average_score\n",
    "\n",
    "# Find the k with the lowest average score\n",
    "best_k = min(scores_dict, key=scores_dict.get)\n",
    "print(f\"Best k is {best_k} with the lowest average score of {scores_dict[best_k]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning Gamma ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average score with g=0.1: 17798.197619047616\n",
      "Average score with g=0.3: 17798.19761904762\n",
      "Average score with g=0.5: 17798.197619047616\n",
      "Average score with g=0.7: 17798.19761904762\n",
      "Average score with g=0.9: 17798.197619047616\n",
      "Average score with g=1.1: 17798.197619047616\n",
      "Average score with g=1.3: 17798.197619047616\n",
      "Average score with g=1.5: 17798.197619047616\n",
      "Average score with g=1.7: 17798.197619047616\n",
      "Average score with g=1.9: 17798.197619047616\n",
      "Best g is 0.1 with the lowest average score of 17798.197619047616\n"
     ]
    }
   ],
   "source": [
    "hyperparameters = np.arange(0.1,2,0.2)\n",
    "scores_dict = {}\n",
    "\n",
    "for g in hyperparameters: \n",
    "    scores = []\n",
    "    for i, (train_set_1, train_set_2) in enumerate(cross_validator.cross_validation(data_train_standardized, n_splits=2, n_repeats=5, random_state=42, stratify=False)):\n",
    "        \n",
    "        predictions_1 = knn_model.knn_regression(data_val_standardized, train_set_1, k=best_k, gamma=gamma*g)['Predicted Value']\n",
    "        score_1 = Evaluation().mean_squared_error(data_val_standardized[config['target_column']], predictions_1)\n",
    "        scores.append(score_1)\n",
    "\n",
    "    average_score = sum(scores) / len(scores)\n",
    "    print(f\"Average score with g={round(g,2)}: {average_score}\")\n",
    "    scores_dict[g] = average_score\n",
    "\n",
    "# Find the k with the lowest average score\n",
    "best_g = min(scores_dict, key=scores_dict.get)\n",
    "print(f\"Best g is {round(best_g,2)} with the lowest average score of {scores_dict[best_g]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average score for k=1, g=0.1: 9120.061431440046\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for i, (train_set, test_set) in enumerate(cross_validator.cross_validation(data_train_standardized, n_splits=2, n_repeats=5, random_state=42, stratify=False)):\n",
    "    \n",
    "    # Train and evaluate \n",
    "    predictions_1 = knn_model.knn_regression(test_set, train_set, k=best_k, gamma=best_g*gamma)['Predicted Value']\n",
    "    score = Evaluation().mean_squared_error(test_set[config['target_column']], predictions_1)\n",
    "    scores.append(score)  \n",
    "\n",
    "average_score = sum(scores) / len(scores)\n",
    "print(f\"Average score for k={best_k}, g={round(best_g,2)}: {average_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edited KNN ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160.83073308779512"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epsilon = statistics.stdev(data_3[config['target_column']])\n",
    "epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning Epsilon ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average score with e=0.1: 39347.9119047619\n",
      "Average score with e=0.3: 34349.5880952381\n",
      "Average score with e=0.5: 32581.45952380952\n",
      "Average score with e=0.7: 29542.10714285714\n",
      "Average score with e=0.9: 27883.99047619048\n",
      "Average score with e=1.1: 27196.84761904762\n",
      "Average score with e=1.3: 24044.104761904764\n",
      "Average score with e=1.5: 23662.730952380953\n",
      "Average score with e=1.7: 20709.992857142854\n",
      "Average score with e=1.9: 19479.547619047615\n",
      "Best e is 1.9 with the lowest average score of 19479.547619047615\n"
     ]
    }
   ],
   "source": [
    "hyperparameters = np.arange(0.1,2,0.2)\n",
    "scores_dict = {}\n",
    "\n",
    "for e in hyperparameters: \n",
    "    scores = []\n",
    "    for i, (train_set_1, train_set_2) in enumerate(cross_validator.cross_validation(data_train_standardized, n_splits=2, n_repeats=5, random_state=42, stratify=False)):\n",
    "        \n",
    "        edited_train_set = knn_model.edited_knn_regression(train_set_1,epsilon=epsilon*e)\n",
    "\n",
    "        predictions_1 = knn_model.knn_regression(data_val_standardized, edited_train_set, k=best_k, gamma=best_g)['Predicted Value']\n",
    "        score_1 = Evaluation().mean_squared_error(data_val_standardized[config['target_column']], predictions_1)\n",
    "        scores.append(score_1)\n",
    "\n",
    "    average_score = sum(scores) / len(scores)\n",
    "    print(f\"Average score with e={round(e,2)}: {average_score}\")\n",
    "    scores_dict[e] = average_score\n",
    "\n",
    "# Find the k with the lowest average score\n",
    "best_e = min(scores_dict, key=scores_dict.get)\n",
    "print(f\"Best e is {round(best_e,2)} with the lowest average score of {scores_dict[best_e]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning k ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average score with k=1: 19479.547619047615\n",
      "Average score with k=2: 21297.64757883795\n",
      "Average score with k=3: 21758.046519656644\n",
      "Average score with k=4: 21484.66049463321\n",
      "Average score with k=5: 21516.505136336687\n",
      "Average score with k=6: 21429.592751070762\n",
      "Average score with k=7: 21373.617419826307\n",
      "Average score with k=8: 21517.056962455048\n",
      "Average score with k=9: 21658.09816548178\n",
      "Best k is 1 with the lowest average score of 19479.547619047615\n"
     ]
    }
   ],
   "source": [
    "hyperparameters = np.arange(1,10,1)\n",
    "scores_dict = {}\n",
    "\n",
    "for k in hyperparameters: \n",
    "    scores = []\n",
    "    for i, (train_set_1, train_set_2) in enumerate(cross_validator.cross_validation(data_train_standardized, n_splits=2, n_repeats=5, random_state=42, stratify=False)):\n",
    "        \n",
    "        edited_train_set = knn_model.edited_knn_regression(train_set_1,epsilon=epsilon*best_e)\n",
    "\n",
    "        predictions_1 = knn_model.knn_regression(data_val_standardized, edited_train_set, k=k, gamma=best_g)['Predicted Value']\n",
    "        score_1 = Evaluation().mean_squared_error(data_val_standardized[config['target_column']], predictions_1)\n",
    "        scores.append(score_1)\n",
    "\n",
    "    average_score = sum(scores) / len(scores)\n",
    "    print(f\"Average score with k={k}: {average_score}\")\n",
    "    scores_dict[k] = average_score\n",
    "\n",
    "# Find the k with the lowest average score\n",
    "best_k = min(scores_dict, key=scores_dict.get)\n",
    "print(f\"Best k is {best_k} with the lowest average score of {scores_dict[best_k]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning gamma ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average score with g=0.1: 19479.547619047615\n",
      "Average score with g=0.3: 19479.54761904762\n",
      "Average score with g=0.5: 19479.547619047615\n",
      "Average score with g=0.7: 19479.54761904762\n",
      "Average score with g=0.9: 19479.547619047615\n",
      "Average score with g=1.1: 19479.547619047615\n",
      "Average score with g=1.3: 19479.547619047615\n",
      "Average score with g=1.5: 19479.547619047615\n",
      "Average score with g=1.7: 19479.547619047615\n",
      "Average score with g=1.9: 19479.547619047615\n",
      "Best g is 0.1 with the lowest average score of 19479.547619047615\n"
     ]
    }
   ],
   "source": [
    "hyperparameters = np.arange(0.1,2,0.2)\n",
    "scores_dict = {}\n",
    "\n",
    "for g in hyperparameters: \n",
    "    scores = []\n",
    "    for i, (train_set_1, train_set_2) in enumerate(cross_validator.cross_validation(data_train_standardized, n_splits=2, n_repeats=5, random_state=42, stratify=False)):\n",
    "        \n",
    "        edited_train_set = knn_model.edited_knn_regression(train_set_1,epsilon=epsilon*best_e)\n",
    "\n",
    "        predictions_1 = knn_model.knn_regression(data_val_standardized, edited_train_set, k=best_k, gamma=g*gamma)['Predicted Value']\n",
    "        score_1 = Evaluation().mean_squared_error(data_val_standardized[config['target_column']], predictions_1)\n",
    "        scores.append(score_1)\n",
    "\n",
    "    average_score = sum(scores) / len(scores)\n",
    "    print(f\"Average score with g={round(g,2)}: {average_score}\")\n",
    "    scores_dict[g] = average_score\n",
    "\n",
    "# Find the k with the lowest average score\n",
    "best_g = min(scores_dict, key=scores_dict.get)\n",
    "print(f\"Best g is {round(best_g,2)} with the lowest average score of {scores_dict[best_g]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average score for k=1, g=0.1, e=1.9: 9119.874856569133\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for i, (train_set, test_set) in enumerate(cross_validator.cross_validation(data_train_standardized, n_splits=2, n_repeats=5, random_state=42, stratify=False)):\n",
    "    \n",
    "    edited_train_set = knn_model.edited_knn_regression(train_set,epsilon=epsilon*best_e)\n",
    "   \n",
    "    predictions_1 = knn_model.knn_regression(test_set, edited_train_set, k=best_k, gamma=best_g*gamma)['Predicted Value']\n",
    "    score = Evaluation().mean_squared_error(test_set[config['target_column']], predictions_1)\n",
    "    scores.append(score)  \n",
    "\n",
    "average_score = sum(scores) / len(scores)\n",
    "print(f\"Average score for k={best_k}, g={round(best_g,2)}, e={round(best_e,2)}: {average_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Condensed Knn ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average score with e=0.1: 18080.01428571429\n",
      "Average score with e=0.3: 18596.211904761905\n",
      "Average score with e=0.5: 17734.683333333334\n",
      "Average score with e=0.7: 16327.942857142854\n",
      "Average score with e=0.9: 17448.911904761906\n",
      "Average score with e=1.1: 17414.016666666666\n",
      "Average score with e=1.3: 22832.476190476194\n",
      "Average score with e=1.5: 23639.245238095238\n",
      "Average score with e=1.7: 25818.533333333333\n",
      "Average score with e=1.9: 27266.85\n",
      "Best e is 0.7 with the lowest average score of 16327.942857142854\n"
     ]
    }
   ],
   "source": [
    "hyperparameters = np.arange(0.1,2,0.2)\n",
    "scores_dict = {}\n",
    "\n",
    "for e in hyperparameters: \n",
    "    scores = []\n",
    "    for i, (train_set_1, train_set_2) in enumerate(cross_validator.cross_validation(data_train_standardized, n_splits=2, n_repeats=5, random_state=42, stratify=False)):\n",
    "        \n",
    "        edited_train_set = knn_model.condensed_knn_regression(train_set_1,epsilon=epsilon*e)\n",
    "\n",
    "        predictions_1 = knn_model.knn_regression(data_val_standardized, edited_train_set, k=best_k, gamma=best_g)['Predicted Value']\n",
    "        score_1 = Evaluation().mean_squared_error(data_val_standardized[config['target_column']], predictions_1)\n",
    "        scores.append(score_1)\n",
    "\n",
    "    average_score = sum(scores) / len(scores)\n",
    "    print(f\"Average score with e={round(e,2)}: {average_score}\")\n",
    "    scores_dict[e] = average_score\n",
    "\n",
    "# Find the k with the lowest average score\n",
    "best_e = min(scores_dict, key=scores_dict.get)\n",
    "print(f\"Best e is {round(best_e,2)} with the lowest average score of {scores_dict[best_e]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average score with k=1: 17625.688095238096\n",
      "Average score with k=2: 16232.760536683923\n",
      "Average score with k=3: 17012.50211262436\n",
      "Average score with k=4: 17695.03130123066\n",
      "Average score with k=5: 21568.079251297175\n",
      "Average score with k=6: 21111.64424965665\n",
      "Average score with k=7: 22603.02531618776\n",
      "Average score with k=8: 22462.649146159052\n",
      "Average score with k=9: 22575.533020410636\n",
      "Best k is 2 with the lowest average score of 16232.760536683923\n"
     ]
    }
   ],
   "source": [
    "hyperparameters = np.arange(1,10,1)\n",
    "scores_dict = {}\n",
    "\n",
    "for k in hyperparameters: \n",
    "    scores = []\n",
    "    for i, (train_set_1, train_set_2) in enumerate(cross_validator.cross_validation(data_train_standardized, n_splits=2, n_repeats=5, random_state=42, stratify=False)):\n",
    "        \n",
    "        edited_train_set = knn_model.condensed_knn_regression(train_set_1,epsilon=epsilon*best_e)\n",
    "\n",
    "        predictions_1 = knn_model.knn_regression(data_val_standardized, edited_train_set, k=k, gamma=best_g)['Predicted Value']\n",
    "        score_1 = Evaluation().mean_squared_error(data_val_standardized[config['target_column']], predictions_1)\n",
    "        scores.append(score_1)\n",
    "\n",
    "    average_score = sum(scores) / len(scores)\n",
    "    print(f\"Average score with k={k}: {average_score}\")\n",
    "    scores_dict[k] = average_score\n",
    "\n",
    "# Find the k with the lowest average score\n",
    "best_k = min(scores_dict, key=scores_dict.get)\n",
    "print(f\"Best k is {best_k} with the lowest average score of {scores_dict[best_k]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average score with g=0.1: 29641.18627155772\n",
      "Average score with g=0.3: 29640.094904720092\n",
      "Average score with g=0.5: 29639.03640589374\n",
      "Average score with g=0.7: 29638.01147848658\n",
      "Average score with g=0.9: 29637.020777284495\n",
      "Average score with g=1.1: 29636.06490761118\n",
      "Average score with g=1.3: 29635.14442467476\n",
      "Average score with g=1.5: 29634.259833102755\n",
      "Average score with g=1.7: 29633.411586665472\n",
      "Average score with g=1.9: 29632.60008818691\n",
      "Best g is 1.9 with the lowest average score of 29632.60008818691\n"
     ]
    }
   ],
   "source": [
    "hyperparameters = np.arange(0.1,2,0.2)\n",
    "scores_dict = {}\n",
    "\n",
    "for g in hyperparameters: \n",
    "    scores = []\n",
    "    for i, (train_set_1, train_set_2) in enumerate(cross_validator.cross_validation(data_train_standardized, n_splits=2, n_repeats=5, random_state=42, stratify=False)):\n",
    "        \n",
    "        edited_train_set = knn_model.edited_knn_regression(train_set_1,epsilon=epsilon*best_e)\n",
    "\n",
    "        predictions_1 = knn_model.knn_regression(data_val_standardized, edited_train_set, k=best_k, gamma=g*gamma)['Predicted Value']\n",
    "        score_1 = Evaluation().mean_squared_error(data_val_standardized[config['target_column']], predictions_1)\n",
    "        scores.append(score_1)\n",
    "\n",
    "    average_score = sum(scores) / len(scores)\n",
    "    print(f\"Average score with g={round(g,2)}: {average_score}\")\n",
    "    scores_dict[g] = average_score\n",
    "\n",
    "# Find the k with the lowest average score\n",
    "best_g = min(scores_dict, key=scores_dict.get)\n",
    "print(f\"Best g is {round(best_g,2)} with the lowest average score of {scores_dict[best_g]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average score for k=2, g=1.9, e=0.7: 8737.066086407704\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for i, (train_set, test_set) in enumerate(cross_validator.cross_validation(data_train_standardized, n_splits=2, n_repeats=5, random_state=42, stratify=False)):\n",
    "    \n",
    "    edited_train_set = knn_model.edited_knn_regression(train_set,epsilon=epsilon*best_e)\n",
    "   \n",
    "    predictions_1 = knn_model.knn_regression(test_set, edited_train_set, k=best_k, gamma=best_g*gamma)['Predicted Value']\n",
    "    score = Evaluation().mean_squared_error(test_set[config['target_column']], predictions_1)\n",
    "    scores.append(score)  \n",
    "\n",
    "average_score = sum(scores) / len(scores)\n",
    "print(f\"Average score for k={best_k}, g={round(best_g,2)}, e={round(best_e,2)}: {average_score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
