{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_preprocessor import DataProcessor\n",
    "from src.cross_validation import CrossValidation\n",
    "from src.evaluation import Evaluation\n",
    "from models.knn import KNN\n",
    "from models.null_model import NullModelClassification, NullModelRegression\n",
    "from data_configs.configs import *\n",
    "import statistics\n",
    "import numpy as np\n",
    "\n",
    "config = forest_fires_config\n",
    "data_processor = DataProcessor(config=config)\n",
    "cross_validator = CrossValidation(config=config)\n",
    "classification_nullmodel = NullModelClassification(config=config)\n",
    "regression_nullmodel = NullModelRegression(config=config)\n",
    "knn_model = KNN(config)\n",
    "null_model = NullModelRegression(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Load and Preprocessing ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = data_processor.load_data()\n",
    "\n",
    "data_1 = data_processor.impute_missing_values(raw_data)\n",
    "\n",
    "data_2 = data_processor.encode_nominal_features(data_1)\n",
    "\n",
    "data_3 = data_processor.encode_ordinal_features(data_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_4 = data_processor.log_transform(data_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Model ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_val = cross_validator.random_partition(data_4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=['X', 'Y', 'FFMC', 'DMC', 'DC', 'ISI','temp', 'RH', 'wind', 'rain', 'month','day']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7265859330636893"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma = 1/(statistics.stdev(data_train[config['target_column']]))\n",
    "gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63.65581846794089"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statistics.stdev(data_3[config['target_column']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning k ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MSE score with k=1: 12827.605644615393\n",
      "Average MSE score with k=2: 12286.82580512004\n",
      "Average MSE score with k=3: 12199.416791307332\n",
      "Average MSE score with k=4: 12164.780424775794\n",
      "Average MSE score with k=5: 12142.075856759457\n",
      "Average MSE score with k=6: 12129.468874487815\n",
      "Average MSE score with k=7: 12124.364856806615\n",
      "Average MSE score with k=8: 12119.406165249244\n",
      "Average MSE score with k=9: 12116.522890864095\n",
      "Average MSE score with k=10: 12112.839825728597\n",
      "Average MSE score with k=11: 12111.576822898172\n",
      "Average MSE score with k=12: 12109.65228327208\n",
      "Average MSE score with k=13: 12108.095866533891\n",
      "Average MSE score with k=14: 12108.522424369727\n",
      "Best k is 13 with the lowest average MSE score of 12108.095866533891\n"
     ]
    }
   ],
   "source": [
    "hyperparameters = np.arange(1,15,1)\n",
    "scores_dict = {}\n",
    "\n",
    "for k in hyperparameters: \n",
    "    scores = []\n",
    "    for i, (train_set_1, train_set_2) in enumerate(cross_validator.cross_validation(data_train, n_splits=2, n_repeats=5, random_state=42, stratify=False)):\n",
    "        \n",
    "        data_train_standardized = data_processor.standardize_data(train_set_1, train_set_1, features=features)\n",
    "        data_val_standardized = data_processor.standardize_data(train_set_1,data_val,features=features)  \n",
    "\n",
    "        predictions_1 = knn_model.knn_regression(data_val_standardized, data_train_standardized, k=k, gamma=gamma)['Predicted Value']\n",
    "        predictions_1 = data_processor.inverse_log_transform(predictions_1)\n",
    "        y_true = data_processor.inverse_log_transform(data_val_standardized[config['target_column']])\n",
    "        score_1 = Evaluation().mean_squared_error(y_true, predictions_1)\n",
    "        scores.append(score_1)\n",
    "\n",
    "    average_score = sum(scores) / len(scores)\n",
    "    print(f\"Average MSE score with k={k}: {average_score}\")\n",
    "    scores_dict[k] = average_score\n",
    "\n",
    "best_k = min(scores_dict, key=scores_dict.get)\n",
    "print(f\"Best k is {best_k} with the lowest average MSE score of {scores_dict[best_k]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning Gamma ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MSE score with g=0.4: 12091.422644001159\n",
      "Average MSE score with g=0.6: 12094.075479423424\n",
      "Average MSE score with g=0.8: 12098.645216298932\n",
      "Average MSE score with g=1.0: 12108.095866533891\n",
      "Average MSE score with g=1.2: 12126.838974780072\n",
      "Average MSE score with g=1.4: 12157.67592372792\n",
      "Average MSE score with g=1.6: 12198.037354553335\n",
      "Best g is 0.4 with the lowest average MSE score of 12091.422644001159\n"
     ]
    }
   ],
   "source": [
    "hyperparameters = np.arange(0.4,1.6,0.2)\n",
    "scores_dict = {}\n",
    "\n",
    "for g in hyperparameters: \n",
    "    scores = []\n",
    "    for i, (train_set_1, train_set_2) in enumerate(cross_validator.cross_validation(data_train, n_splits=2, n_repeats=5, random_state=42, stratify=False)):\n",
    "        \n",
    "        data_train_standardized = data_processor.standardize_data(train_set_1, train_set_1, features=features)\n",
    "        data_val_standardized = data_processor.standardize_data(train_set_1,data_val,features=features)  \n",
    "\n",
    "        predictions_1 = knn_model.knn_regression(data_val_standardized, data_train_standardized, k=best_k, gamma=gamma*g)['Predicted Value']\n",
    "        predictions_1 = data_processor.inverse_log_transform(predictions_1)\n",
    "        y_true = data_processor.inverse_log_transform(data_val_standardized[config['target_column']])\n",
    "\n",
    "        score_1 = Evaluation().mean_squared_error(y_true, predictions_1)\n",
    "        scores.append(score_1)\n",
    "\n",
    "    average_score = sum(scores) / len(scores)\n",
    "    print(f\"Average MSE score with g={round(g,2)}: {average_score}\")\n",
    "    scores_dict[g] = average_score\n",
    "\n",
    "best_g = min(scores_dict, key=scores_dict.get)\n",
    "print(f\"Best g is {round(best_g,2)} with the lowest average MSE score of {scores_dict[best_g]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Srikanta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\stats\\stats.py:3913: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n",
      "c:\\Users\\Srikanta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\stats\\stats.py:3913: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n",
      "c:\\Users\\Srikanta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\stats\\stats.py:3913: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n",
      "c:\\Users\\Srikanta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\stats\\stats.py:3913: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n",
      "c:\\Users\\Srikanta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\stats\\stats.py:3913: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n",
      "c:\\Users\\Srikanta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\stats\\stats.py:3913: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n",
      "c:\\Users\\Srikanta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\stats\\stats.py:3913: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n",
      "c:\\Users\\Srikanta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\stats\\stats.py:3913: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n",
      "c:\\Users\\Srikanta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\stats\\stats.py:3913: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average null model MSE score: 2161.2278374710386\n",
      "Average null model MAE score: 11.249154171959376\n",
      "Average null model r2 score: -0.05206367958446219\n",
      "Average null model pearson score: nan\n",
      "Average MSE score for k=13, g=0.4: 2158.384242204224\n",
      "Average MAE score for k=13, g=0.4: 11.375752493133465\n",
      "Average r2 score for k=13, g=0.4: -0.04617814691499349\n",
      "Average pearson score for k=13, g=0.4: 0.016974665861499382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Srikanta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\stats\\stats.py:3913: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    }
   ],
   "source": [
    "mse_scores = []\n",
    "mae_scores = []\n",
    "r2_scores = []\n",
    "pearson_scores = []\n",
    "null_model_scores = []\n",
    "\n",
    "# Lists for storing null model metrics\n",
    "null_model_mae_scores = []\n",
    "null_model_r2_scores = []\n",
    "null_model_pearson_scores = []\n",
    "\n",
    "for i, (train_set, test_set) in enumerate(cross_validator.cross_validation(data_train, n_splits=2, n_repeats=5, random_state=42, stratify=False)):\n",
    "\n",
    "    data_train_standardized = data_processor.standardize_data(train_set, train_set, features=features)\n",
    "    data_test_standardized = data_processor.standardize_data(train_set,test_set,features=features)  \n",
    "\n",
    "    # Train and evaluate \n",
    "    predictions_1 = knn_model.knn_regression(data_test_standardized, data_train_standardized, k=best_k, gamma=best_g*gamma)['Predicted Value']\n",
    "    predictions_1 = data_processor.inverse_log_transform(predictions_1)\n",
    "    y_true = data_processor.inverse_log_transform(data_test_standardized[config['target_column']])\n",
    "    \n",
    "    mse_score = Evaluation.mean_squared_error(y_true, predictions_1)\n",
    "    mae_score = Evaluation.mean_absolute_error(y_true, predictions_1)\n",
    "    r2_score = Evaluation.r2_coefficient(y_true, predictions_1)\n",
    "    pearson_score = Evaluation.pearsons_correlation(y_true, predictions_1)\n",
    "    \n",
    "    mse_scores.append(mse_score)\n",
    "    mae_scores.append(mae_score)\n",
    "    r2_scores.append(r2_score)\n",
    "    pearson_scores.append(pearson_score)\n",
    "\n",
    "    # Evaluate null model\n",
    "    y_true = data_processor.inverse_log_transform(test_set[config['target_column']])\n",
    "    null_model_prediction = null_model.naive_regression(test_set)\n",
    "    null_model_prediction = data_processor.inverse_log_transform(null_model_prediction)\n",
    "    null_model_mse = Evaluation.mean_squared_error(y_true, null_model_prediction)\n",
    "    null_model_mae = Evaluation.mean_absolute_error(y_true, null_model_prediction)\n",
    "    null_model_r2 = Evaluation.r2_coefficient(y_true, null_model_prediction)\n",
    "    null_model_pearson = Evaluation.pearsons_correlation(y_true, null_model_prediction)\n",
    "    \n",
    "    null_model_scores.append(null_model_mse)\n",
    "    null_model_mae_scores.append(null_model_mae)\n",
    "    null_model_r2_scores.append(null_model_r2)\n",
    "    null_model_pearson_scores.append(null_model_pearson)\n",
    "\n",
    "\n",
    "average_mse_score = sum(mse_scores) / len(mse_scores)\n",
    "average_mae_score = sum(mae_scores) / len(mae_scores)\n",
    "average_r2_score = sum(r2_scores) / len(r2_scores)\n",
    "average_pearson_score = sum(pearson_scores) / len(pearson_scores)\n",
    "average_null_model_mse = sum(null_model_scores) / len(null_model_scores)\n",
    "average_null_model_mae = sum(null_model_mae_scores) / len(null_model_mae_scores)\n",
    "average_null_model_r2 = sum(null_model_r2_scores) / len(null_model_r2_scores)\n",
    "average_null_model_pearson = sum(null_model_pearson_scores) / len(null_model_pearson_scores)\n",
    "\n",
    "print(f\"Average null model MSE score: {average_null_model_mse}\")\n",
    "print(f\"Average null model MAE score: {average_null_model_mae}\")\n",
    "print(f\"Average null model r2 score: {average_null_model_r2}\")\n",
    "print(f\"Average null model pearson score: {average_null_model_pearson}\")\n",
    "print(f\"Average MSE score for k={best_k}, g={round(best_g,2)}: {average_mse_score}\")\n",
    "print(f\"Average MAE score for k={best_k}, g={round(best_g,2)}: {average_mae_score}\")\n",
    "print(f\"Average r2 score for k={best_k}, g={round(best_g,2)}: {average_r2_score}\")\n",
    "print(f\"Average pearson score for k={best_k}, g={round(best_g,2)}: {average_pearson_score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edited KNN ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.398435955883445"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epsilon = statistics.stdev(data_4[config['target_column']])\n",
    "epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning Epsilon ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MSE score with e=0.1: 12165.630446997091\n",
      "Average MSE score with e=0.3: 12156.47544593398\n",
      "Average MSE score with e=0.5: 12146.075361328856\n",
      "Average MSE score with e=0.7: 12142.275800530082\n",
      "Average MSE score with e=0.9: 12135.826145261988\n",
      "Average MSE score with e=1.1: 12129.34348530095\n",
      "Average MSE score with e=1.3: 12129.747411500051\n",
      "Average MSE score with e=1.5: 12122.098280237715\n",
      "Average MSE score with e=1.7: 12119.584280449677\n",
      "Average MSE score with e=1.9: 12119.414022279254\n",
      "Best e is 1.9 with the lowest average MSE score of 12119.414022279254\n"
     ]
    }
   ],
   "source": [
    "hyperparameters = np.arange(0.1,2,0.2)\n",
    "scores_dict = {}\n",
    "\n",
    "for e in hyperparameters: \n",
    "    scores = []\n",
    "    for i, (train_set_1, train_set_2) in enumerate(cross_validator.cross_validation(data_train, n_splits=2, n_repeats=5, random_state=42, stratify=False)):\n",
    "        \n",
    "        edited_train_set = knn_model.edited_knn_regression(train_set_1, train_set_2, epsilon=epsilon*e, gamma=gamma)\n",
    "\n",
    "        data_train_standardized = data_processor.standardize_data(edited_train_set, edited_train_set, features=features)\n",
    "        data_val_standardized = data_processor.standardize_data(edited_train_set,data_val,features=features)  \n",
    "\n",
    "        predictions_1 = knn_model.knn_regression(data_val_standardized, data_train_standardized, k=best_k, gamma=gamma*best_g)['Predicted Value']\n",
    "        predictions_1 = data_processor.inverse_log_transform(predictions_1)\n",
    "        y_true = data_processor.inverse_log_transform(data_val_standardized[config['target_column']])\n",
    "        score_1 = Evaluation().mean_squared_error(y_true, predictions_1)\n",
    "        scores.append(score_1)\n",
    "\n",
    "    average_score = sum(scores) / len(scores)\n",
    "    print(f\"Average MSE score with e={round(e,2)}: {average_score}\")\n",
    "    scores_dict[e] = average_score\n",
    "\n",
    "best_e = min(scores_dict, key=scores_dict.get)\n",
    "print(f\"Best e is {round(best_e,2)} with the lowest average MSE score of {scores_dict[best_e]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning k ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MSE score with k=1: 12187.642614038468\n",
      "Average MSE score with k=2: 12145.619952350293\n",
      "Average MSE score with k=3: 12138.298076657185\n",
      "Average MSE score with k=4: 12129.879791996118\n",
      "Average MSE score with k=5: 12128.801611850988\n",
      "Average MSE score with k=6: 12128.430449609394\n",
      "Average MSE score with k=7: 12128.329095250663\n",
      "Average MSE score with k=8: 12126.525195625658\n",
      "Average MSE score with k=9: 12123.032612328298\n",
      "Best k is 9 with the lowest average MSE score of 12123.032612328298\n"
     ]
    }
   ],
   "source": [
    "hyperparameters = np.arange(1,10,1)\n",
    "scores_dict = {}\n",
    "\n",
    "for k in hyperparameters: \n",
    "    scores = []\n",
    "    for i, (train_set_1, train_set_2) in enumerate(cross_validator.cross_validation(data_train, n_splits=2, n_repeats=5, random_state=42, stratify=False)):\n",
    "        \n",
    "        edited_train_set = knn_model.edited_knn_regression(train_set_1, train_set_2, epsilon=epsilon*best_e, gamma=gamma)\n",
    "\n",
    "        data_train_standardized = data_processor.standardize_data(edited_train_set, edited_train_set, features=features)\n",
    "        data_val_standardized = data_processor.standardize_data(edited_train_set,data_val,features=features)  \n",
    "\n",
    "        predictions_1 = knn_model.knn_regression(data_val_standardized, data_train_standardized, k=k, gamma=gamma*best_g)['Predicted Value']\n",
    "        predictions_1 = data_processor.inverse_log_transform(predictions_1)\n",
    "        y_true = data_processor.inverse_log_transform(data_val_standardized[config['target_column']])\n",
    "        score_1 = Evaluation().mean_squared_error(y_true, predictions_1)\n",
    "        scores.append(score_1)\n",
    "\n",
    "    average_score = sum(scores) / len(scores)\n",
    "    print(f\"Average MSE score with k={k}: {average_score}\")\n",
    "    scores_dict[k] = average_score\n",
    "\n",
    "best_k = min(scores_dict, key=scores_dict.get)\n",
    "print(f\"Best k is {best_k} with the lowest average MSE score of {scores_dict[best_k]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning gamma ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MSE score with g=0.4: 12123.032612328298\n",
      "Average MSE score with g=0.6: 12123.631866484307\n",
      "Average MSE score with g=0.8: 12124.758718155012\n",
      "Average MSE score with g=1.0: 12126.566000473704\n",
      "Average MSE score with g=1.2: 12128.894204600942\n",
      "Average MSE score with g=1.4: 12131.444313844677\n",
      "Average MSE score with g=1.6: 12134.007425000449\n",
      "Best g is 0.4 with the lowest average MSE score of 12123.032612328298\n"
     ]
    }
   ],
   "source": [
    "hyperparameters = np.arange(0.4,1.6,0.2)\n",
    "scores_dict = {}\n",
    "\n",
    "for g in hyperparameters: \n",
    "    scores = []\n",
    "    for i, (train_set_1, train_set_2) in enumerate(cross_validator.cross_validation(data_train, n_splits=2, n_repeats=5, random_state=42, stratify=False)):\n",
    "        \n",
    "        edited_train_set = knn_model.edited_knn_regression(train_set_1, train_set_2, epsilon=epsilon*best_e, gamma = gamma)\n",
    "\n",
    "        data_train_standardized = data_processor.standardize_data(edited_train_set, edited_train_set, features=features)\n",
    "        data_val_standardized = data_processor.standardize_data(edited_train_set,data_val,features=features)  \n",
    "\n",
    "        predictions_1 = knn_model.knn_regression(data_val_standardized, data_train_standardized, k=best_k, gamma=g*gamma)['Predicted Value']\n",
    "        predictions_1 = data_processor.inverse_log_transform(predictions_1)\n",
    "        y_true = data_processor.inverse_log_transform(data_val_standardized[config['target_column']])\n",
    "        score_1 = Evaluation().mean_squared_error(y_true, predictions_1)\n",
    "        scores.append(score_1)\n",
    "\n",
    "    average_score = sum(scores) / len(scores)\n",
    "    print(f\"Average MSE score with g={round(g,2)}: {average_score}\")\n",
    "    scores_dict[g] = average_score\n",
    "\n",
    "best_g = min(scores_dict, key=scores_dict.get)\n",
    "print(f\"Best g is {round(best_g,2)} with the lowest average MSE score of {scores_dict[best_g]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Srikanta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\stats\\stats.py:3913: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n",
      "c:\\Users\\Srikanta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\stats\\stats.py:3913: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n",
      "c:\\Users\\Srikanta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\stats\\stats.py:3913: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n",
      "c:\\Users\\Srikanta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\stats\\stats.py:3913: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n",
      "c:\\Users\\Srikanta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\stats\\stats.py:3913: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n",
      "c:\\Users\\Srikanta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\stats\\stats.py:3913: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n",
      "c:\\Users\\Srikanta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\stats\\stats.py:3913: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n",
      "c:\\Users\\Srikanta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\stats\\stats.py:3913: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n",
      "c:\\Users\\Srikanta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\stats\\stats.py:3913: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average null model MSE score: 2161.2278374710386\n",
      "Average null model MAE score: 11.249154171959376\n",
      "Average null model r2 score: -0.05206367958446219\n",
      "Average null model pearson score: nan\n",
      "Average MSE score for k=9, g=0.4: 2171.8326540217918\n",
      "Average MAE score for k=9, g=0.4: 11.231100579099355\n",
      "Average r2 score for k=9, g=0.4: -0.05869600556767714\n",
      "Average pearson score for k=9, g=0.4: -0.0207621164695765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Srikanta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\stats\\stats.py:3913: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    }
   ],
   "source": [
    "mse_scores = []\n",
    "mae_scores = []\n",
    "r2_scores = []\n",
    "pearson_scores = []\n",
    "null_model_scores = []\n",
    "\n",
    "# Lists for storing null model metrics\n",
    "null_model_mae_scores = []\n",
    "null_model_r2_scores = []\n",
    "null_model_pearson_scores = []\n",
    "\n",
    "for i, (train_set, test_set) in enumerate(cross_validator.cross_validation(data_train, n_splits=2, n_repeats=5, random_state=42, stratify=False)):\n",
    "\n",
    "    edited_train_set = knn_model.edited_knn_regression(train_set, data_val, epsilon=epsilon*best_e, gamma=gamma)\n",
    "\n",
    "    data_train_standardized = data_processor.standardize_data(edited_train_set, edited_train_set, features=features)\n",
    "    data_test_standardized = data_processor.standardize_data(edited_train_set,test_set,features=features)  \n",
    "\n",
    "    # Train and evaluate \n",
    "    predictions_1 = knn_model.knn_regression(data_test_standardized, data_train_standardized, k=best_k, gamma=best_g*gamma)['Predicted Value']\n",
    "    predictions_1 = data_processor.inverse_log_transform(predictions_1)\n",
    "    y_true = data_processor.inverse_log_transform(data_test_standardized[config['target_column']])\n",
    "    \n",
    "    mse_score = Evaluation.mean_squared_error(y_true, predictions_1)\n",
    "    mae_score = Evaluation.mean_absolute_error(y_true, predictions_1)\n",
    "    r2_score = Evaluation.r2_coefficient(y_true, predictions_1)\n",
    "    pearson_score = Evaluation.pearsons_correlation(y_true, predictions_1)\n",
    "    \n",
    "    mse_scores.append(mse_score)\n",
    "    mae_scores.append(mae_score)\n",
    "    r2_scores.append(r2_score)\n",
    "    pearson_scores.append(pearson_score)\n",
    "\n",
    "    # Evaluate null model\n",
    "    y_true = data_processor.inverse_log_transform(test_set[config['target_column']])\n",
    "    null_model_prediction = null_model.naive_regression(test_set)\n",
    "    null_model_prediction = data_processor.inverse_log_transform(null_model_prediction)\n",
    "    null_model_mse = Evaluation.mean_squared_error(y_true, null_model_prediction)\n",
    "    null_model_mae = Evaluation.mean_absolute_error(y_true, null_model_prediction)\n",
    "    null_model_r2 = Evaluation.r2_coefficient(y_true, null_model_prediction)\n",
    "    null_model_pearson = Evaluation.pearsons_correlation(y_true, null_model_prediction)\n",
    "    \n",
    "    null_model_scores.append(null_model_mse)\n",
    "    null_model_mae_scores.append(null_model_mae)\n",
    "    null_model_r2_scores.append(null_model_r2)\n",
    "    null_model_pearson_scores.append(null_model_pearson)\n",
    "\n",
    "\n",
    "average_mse_score = sum(mse_scores) / len(mse_scores)\n",
    "average_mae_score = sum(mae_scores) / len(mae_scores)\n",
    "average_r2_score = sum(r2_scores) / len(r2_scores)\n",
    "average_pearson_score = sum(pearson_scores) / len(pearson_scores)\n",
    "average_null_model_mse = sum(null_model_scores) / len(null_model_scores)\n",
    "average_null_model_mae = sum(null_model_mae_scores) / len(null_model_mae_scores)\n",
    "average_null_model_r2 = sum(null_model_r2_scores) / len(null_model_r2_scores)\n",
    "average_null_model_pearson = sum(null_model_pearson_scores) / len(null_model_pearson_scores)\n",
    "\n",
    "print(f\"Average null model MSE score: {average_null_model_mse}\")\n",
    "print(f\"Average null model MAE score: {average_null_model_mae}\")\n",
    "print(f\"Average null model r2 score: {average_null_model_r2}\")\n",
    "print(f\"Average null model pearson score: {average_null_model_pearson}\")\n",
    "print(f\"Average MSE score for k={best_k}, g={round(best_g,2)}: {average_mse_score}\")\n",
    "print(f\"Average MAE score for k={best_k}, g={round(best_g,2)}: {average_mae_score}\")\n",
    "print(f\"Average r2 score for k={best_k}, g={round(best_g,2)}: {average_r2_score}\")\n",
    "print(f\"Average pearson score for k={best_k}, g={round(best_g,2)}: {average_pearson_score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Condensed Knn ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning Epsilon ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MSE score with e=0.1: 12075.689711225627\n",
      "Average MSE score with e=0.2: 12074.963502830307\n",
      "Average MSE score with e=0.3: 12079.29479223938\n",
      "Average MSE score with e=0.4: 12077.445894727274\n",
      "Average MSE score with e=0.5: 12074.408221748346\n",
      "Average MSE score with e=0.6: 12075.076508715918\n",
      "Average MSE score with e=0.7: 12073.7317943993\n",
      "Average MSE score with e=0.8: 12063.978418292872\n",
      "Average MSE score with e=0.9: 12075.779713581109\n",
      "Average MSE score with e=1.0: 12070.136343029193\n",
      "Average MSE score with e=1.1: 12074.306525232587\n",
      "Average MSE score with e=1.2: 12068.542900837343\n",
      "Average MSE score with e=1.3: 12070.801100620294\n",
      "Average MSE score with e=1.4: 12051.795920579094\n",
      "Best e is 1.4 with the lowest average MSE score of 12051.795920579094\n"
     ]
    }
   ],
   "source": [
    "hyperparameters = np.arange(0.1,1.5,0.1)\n",
    "scores_dict = {}\n",
    "\n",
    "for e in hyperparameters: \n",
    "    scores = []\n",
    "    for i, (train_set_1, train_set_2) in enumerate(cross_validator.cross_validation(data_train, n_splits=2, n_repeats=5, random_state=42, stratify=False)):\n",
    "        \n",
    "        condesed_train_set = knn_model.condensed_knn_regression(train_set_1,epsilon=epsilon*e)\n",
    "        data_train_standardized = data_processor.standardize_data(condesed_train_set, condesed_train_set, features=features)\n",
    "        data_val_standardized = data_processor.standardize_data(condesed_train_set,data_val,features=features)\n",
    "\n",
    "        predictions_1 = knn_model.knn_regression(data_val_standardized, data_train_standardized, k=best_k, gamma=gamma*best_g)['Predicted Value']\n",
    "        predictions_1 = data_processor.inverse_log_transform(predictions_1)\n",
    "        y_true = data_processor.inverse_log_transform(data_val_standardized[config['target_column']])\n",
    "        score_1 = Evaluation().mean_squared_error(y_true, predictions_1)\n",
    "        scores.append(score_1)\n",
    "\n",
    "    average_score = sum(scores) / len(scores)\n",
    "    print(f\"Average MSE score with e={round(e,2)}: {average_score}\")\n",
    "    scores_dict[e] = average_score\n",
    "\n",
    "best_e = min(scores_dict, key=scores_dict.get)\n",
    "print(f\"Best e is {round(best_e,2)} with the lowest average MSE score of {scores_dict[best_e]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning k ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MSE score with k=1: 13747.827820480778\n",
      "Average MSE score with k=2: 12425.284692834397\n",
      "Average MSE score with k=3: 12122.537762722983\n",
      "Average MSE score with k=4: 12087.74280228351\n",
      "Average MSE score with k=5: 12063.606276632947\n",
      "Average MSE score with k=6: 12057.830278564841\n",
      "Average MSE score with k=7: 12035.235991569492\n",
      "Average MSE score with k=8: 12064.738918689945\n",
      "Average MSE score with k=9: 12055.058427898042\n",
      "Best k is 7 with the lowest average MSE score of 12035.235991569492\n"
     ]
    }
   ],
   "source": [
    "hyperparameters = np.arange(1,10,1)\n",
    "scores_dict = {}\n",
    "\n",
    "for k in hyperparameters: \n",
    "    scores = []\n",
    "    for i, (train_set_1, train_set_2) in enumerate(cross_validator.cross_validation(data_train, n_splits=2, n_repeats=5, random_state=42, stratify=False)):\n",
    "        \n",
    "        condesed_train_set = knn_model.condensed_knn_regression(train_set_1,epsilon=epsilon*best_e)\n",
    "\n",
    "        data_train_standardized = data_processor.standardize_data(condesed_train_set, condesed_train_set, features=features)\n",
    "        data_val_standardized = data_processor.standardize_data(condesed_train_set,data_val,features=features)\n",
    "\n",
    "        predictions_1 = knn_model.knn_regression(data_val_standardized, data_train_standardized, k=k, gamma=gamma*best_g)['Predicted Value']\n",
    "        predictions_1 = data_processor.inverse_log_transform(predictions_1)\n",
    "        y_true = data_processor.inverse_log_transform(data_val_standardized[config['target_column']])\n",
    "        score_1 = Evaluation().mean_squared_error(y_true, predictions_1)\n",
    "        scores.append(score_1)\n",
    "\n",
    "    average_score = sum(scores) / len(scores)\n",
    "    print(f\"Average MSE score with k={k}: {average_score}\")\n",
    "    scores_dict[k] = average_score\n",
    "\n",
    "best_k = min(scores_dict, key=scores_dict.get)\n",
    "print(f\"Best k is {best_k} with the lowest average MSE score of {scores_dict[best_k]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning Gamma ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MSE score with g=0.4: 12050.585635563268\n",
      "Average MSE score with g=0.6: 12069.773317030347\n",
      "Average MSE score with g=0.8: 12114.494640808118\n",
      "Average MSE score with g=1.0: 12136.120702091524\n",
      "Average MSE score with g=1.2: 12171.25497061458\n",
      "Average MSE score with g=1.4: 12326.774812711315\n",
      "Average MSE score with g=1.6: 12739.333595220924\n",
      "Best g is 0.4 with the lowest average MSE score of 12050.585635563268\n"
     ]
    }
   ],
   "source": [
    "hyperparameters = np.arange(0.4,1.6,0.2)\n",
    "scores_dict = {}\n",
    "\n",
    "for g in hyperparameters: \n",
    "    scores = []\n",
    "    for i, (train_set_1, train_set_2) in enumerate(cross_validator.cross_validation(data_train, n_splits=2, n_repeats=5, random_state=42, stratify=False)):\n",
    "        \n",
    "        condesed_train_set = knn_model.condensed_knn_regression(train_set_1,epsilon=epsilon*best_e)\n",
    "\n",
    "        data_train_standardized = data_processor.standardize_data(condesed_train_set, condesed_train_set, features=features)\n",
    "        data_val_standardized = data_processor.standardize_data(condesed_train_set,data_val,features=features)  \n",
    "\n",
    "        predictions_1 = knn_model.knn_regression(data_val_standardized, data_train_standardized, k=best_k, gamma=g*gamma)['Predicted Value']\n",
    "        predictions_1 = data_processor.inverse_log_transform(predictions_1)\n",
    "        \n",
    "        y_true = data_processor.inverse_log_transform(data_val_standardized[config['target_column']])\n",
    "        score_1 = Evaluation().mean_squared_error(y_true, predictions_1)\n",
    "        scores.append(score_1)\n",
    "\n",
    "    average_score = sum(scores) / len(scores)\n",
    "    print(f\"Average MSE score with g={round(g,2)}: {average_score}\")\n",
    "    scores_dict[g] = average_score\n",
    "\n",
    "best_g = min(scores_dict, key=scores_dict.get)\n",
    "print(f\"Best g is {round(best_g,2)} with the lowest average MSE score of {scores_dict[best_g]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Srikanta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\stats\\stats.py:3913: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n",
      "c:\\Users\\Srikanta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\stats\\stats.py:3913: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n",
      "c:\\Users\\Srikanta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\stats\\stats.py:3913: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n",
      "c:\\Users\\Srikanta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\stats\\stats.py:3913: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n",
      "c:\\Users\\Srikanta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\stats\\stats.py:3913: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n",
      "c:\\Users\\Srikanta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\stats\\stats.py:3913: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n",
      "c:\\Users\\Srikanta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\stats\\stats.py:3913: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n",
      "c:\\Users\\Srikanta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\stats\\stats.py:3913: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n",
      "c:\\Users\\Srikanta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\stats\\stats.py:3913: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average null model MSE score: 2161.2278374710386\n",
      "Average null model MAE score: 11.249154171959376\n",
      "Average null model r2 score: -0.05206367958446219\n",
      "Average null model pearson score: nan\n",
      "Average MSE score for k=7, g=0.4: 2149.80484710132\n",
      "Average MAE score for k=7, g=0.4: 11.743525742016795\n",
      "Average r2 score for k=7, g=0.4: -0.04035822620084404\n",
      "Average pearson score for k=7, g=0.4: 0.01500515864695674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Srikanta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\stats\\stats.py:3913: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    }
   ],
   "source": [
    "mse_scores = []\n",
    "mae_scores = []\n",
    "r2_scores = []\n",
    "pearson_scores = []\n",
    "null_model_scores = []\n",
    "\n",
    "# Lists for storing null model metrics\n",
    "null_model_mae_scores = []\n",
    "null_model_r2_scores = []\n",
    "null_model_pearson_scores = []\n",
    "\n",
    "for i, (train_set, test_set) in enumerate(cross_validator.cross_validation(data_train, n_splits=2, n_repeats=5, random_state=42, stratify=False)):\n",
    "\n",
    "    condesed_train_set = knn_model.condensed_knn_classification(train_set)\n",
    "\n",
    "    data_train_standardized = data_processor.standardize_data(condesed_train_set, condesed_train_set, features=features)\n",
    "    data_test_standardized = data_processor.standardize_data(condesed_train_set,test_set,features=features)  \n",
    "\n",
    "    # Train and evaluate \n",
    "    predictions_1 = knn_model.knn_regression(data_test_standardized, data_train_standardized, k=best_k, gamma=best_g*gamma)['Predicted Value']\n",
    "    predictions_1 = data_processor.inverse_log_transform(predictions_1)\n",
    "    y_true = data_processor.inverse_log_transform(data_test_standardized[config['target_column']])\n",
    "    \n",
    "    mse_score = Evaluation.mean_squared_error(y_true, predictions_1)\n",
    "    mae_score = Evaluation.mean_absolute_error(y_true, predictions_1)\n",
    "    r2_score = Evaluation.r2_coefficient(y_true, predictions_1)\n",
    "    pearson_score = Evaluation.pearsons_correlation(y_true, predictions_1)\n",
    "    \n",
    "    mse_scores.append(mse_score)\n",
    "    mae_scores.append(mae_score)\n",
    "    r2_scores.append(r2_score)\n",
    "    pearson_scores.append(pearson_score)\n",
    "\n",
    "    # Evaluate null model\n",
    "    y_true = data_processor.inverse_log_transform(test_set[config['target_column']])\n",
    "    null_model_prediction = null_model.naive_regression(test_set)\n",
    "    null_model_prediction = data_processor.inverse_log_transform(null_model_prediction)\n",
    "    null_model_mse = Evaluation.mean_squared_error(y_true, null_model_prediction)\n",
    "    null_model_mae = Evaluation.mean_absolute_error(y_true, null_model_prediction)\n",
    "    null_model_r2 = Evaluation.r2_coefficient(y_true, null_model_prediction)\n",
    "    null_model_pearson = Evaluation.pearsons_correlation(y_true, null_model_prediction)\n",
    "    \n",
    "    null_model_scores.append(null_model_mse)\n",
    "    null_model_mae_scores.append(null_model_mae)\n",
    "    null_model_r2_scores.append(null_model_r2)\n",
    "    null_model_pearson_scores.append(null_model_pearson)\n",
    "\n",
    "\n",
    "average_mse_score = sum(mse_scores) / len(mse_scores)\n",
    "average_mae_score = sum(mae_scores) / len(mae_scores)\n",
    "average_r2_score = sum(r2_scores) / len(r2_scores)\n",
    "average_pearson_score = sum(pearson_scores) / len(pearson_scores)\n",
    "average_null_model_mse = sum(null_model_scores) / len(null_model_scores)\n",
    "average_null_model_mae = sum(null_model_mae_scores) / len(null_model_mae_scores)\n",
    "average_null_model_r2 = sum(null_model_r2_scores) / len(null_model_r2_scores)\n",
    "average_null_model_pearson = sum(null_model_pearson_scores) / len(null_model_pearson_scores)\n",
    "\n",
    "print(f\"Average null model MSE score: {average_null_model_mse}\")\n",
    "print(f\"Average null model MAE score: {average_null_model_mae}\")\n",
    "print(f\"Average null model r2 score: {average_null_model_r2}\")\n",
    "print(f\"Average null model pearson score: {average_null_model_pearson}\")\n",
    "print(f\"Average MSE score for k={best_k}, g={round(best_g,2)}: {average_mse_score}\")\n",
    "print(f\"Average MAE score for k={best_k}, g={round(best_g,2)}: {average_mae_score}\")\n",
    "print(f\"Average r2 score for k={best_k}, g={round(best_g,2)}: {average_r2_score}\")\n",
    "print(f\"Average pearson score for k={best_k}, g={round(best_g,2)}: {average_pearson_score}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
