{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_preprocessor import DataProcessor\n",
    "from src.cross_validation import CrossValidation\n",
    "from src.evaluation import Evaluation\n",
    "from models.knn import KNN\n",
    "from models.null_model import NullModelClassification, NullModelRegression\n",
    "from data_configs.configs import *\n",
    "import statistics\n",
    "import numpy as np\n",
    "\n",
    "config = albalone_config\n",
    "data_processor = DataProcessor(config=config)\n",
    "cross_validator = CrossValidation(config=config)\n",
    "classification_nullmodel = NullModelClassification(config=config)\n",
    "regression_nullmodel = NullModelRegression(config=config)\n",
    "knn_model = KNN(config)\n",
    "null_model = NullModelRegression(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Load and Preprocessing ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = data_processor.load_data()\n",
    "\n",
    "data_1 = data_processor.impute_missing_values(raw_data)\n",
    "\n",
    "data_2 = data_processor.encode_nominal_features(data_1)\n",
    "\n",
    "data_3 = data_processor.encode_ordinal_features(data_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole weight</th>\n",
       "      <th>Shucked weight</th>\n",
       "      <th>Viscera weight</th>\n",
       "      <th>Shell weight</th>\n",
       "      <th>Rings</th>\n",
       "      <th>Sex_F</th>\n",
       "      <th>Sex_I</th>\n",
       "      <th>Sex_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.0700</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.1550</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.0550</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4172</th>\n",
       "      <td>0.565</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.8870</td>\n",
       "      <td>0.3700</td>\n",
       "      <td>0.2390</td>\n",
       "      <td>0.2490</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4173</th>\n",
       "      <td>0.590</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.9660</td>\n",
       "      <td>0.4390</td>\n",
       "      <td>0.2145</td>\n",
       "      <td>0.2605</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4174</th>\n",
       "      <td>0.600</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.205</td>\n",
       "      <td>1.1760</td>\n",
       "      <td>0.5255</td>\n",
       "      <td>0.2875</td>\n",
       "      <td>0.3080</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4175</th>\n",
       "      <td>0.625</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.150</td>\n",
       "      <td>1.0945</td>\n",
       "      <td>0.5310</td>\n",
       "      <td>0.2610</td>\n",
       "      <td>0.2960</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4176</th>\n",
       "      <td>0.710</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.195</td>\n",
       "      <td>1.9485</td>\n",
       "      <td>0.9455</td>\n",
       "      <td>0.3765</td>\n",
       "      <td>0.4950</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4177 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Length  Diameter  Height  Whole weight  Shucked weight  Viscera weight  \\\n",
       "0      0.455     0.365   0.095        0.5140          0.2245          0.1010   \n",
       "1      0.350     0.265   0.090        0.2255          0.0995          0.0485   \n",
       "2      0.530     0.420   0.135        0.6770          0.2565          0.1415   \n",
       "3      0.440     0.365   0.125        0.5160          0.2155          0.1140   \n",
       "4      0.330     0.255   0.080        0.2050          0.0895          0.0395   \n",
       "...      ...       ...     ...           ...             ...             ...   \n",
       "4172   0.565     0.450   0.165        0.8870          0.3700          0.2390   \n",
       "4173   0.590     0.440   0.135        0.9660          0.4390          0.2145   \n",
       "4174   0.600     0.475   0.205        1.1760          0.5255          0.2875   \n",
       "4175   0.625     0.485   0.150        1.0945          0.5310          0.2610   \n",
       "4176   0.710     0.555   0.195        1.9485          0.9455          0.3765   \n",
       "\n",
       "      Shell weight  Rings  Sex_F  Sex_I  Sex_M  \n",
       "0           0.1500     15      0      0      1  \n",
       "1           0.0700      7      0      0      1  \n",
       "2           0.2100      9      1      0      0  \n",
       "3           0.1550     10      0      0      1  \n",
       "4           0.0550      7      0      1      0  \n",
       "...            ...    ...    ...    ...    ...  \n",
       "4172        0.2490     11      1      0      0  \n",
       "4173        0.2605     10      0      0      1  \n",
       "4174        0.3080      9      0      0      1  \n",
       "4175        0.2960     10      1      0      0  \n",
       "4176        0.4950     12      0      0      1  \n",
       "\n",
       "[4177 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Model ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_val = cross_validator.random_partition(data_3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=['Length', 'Diameter', 'Height', 'Whole weight','Shucked weight', 'Viscera weight', 'Shell weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31178449743328734"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma = 1/(statistics.stdev(data_train[config['target_column']]))\n",
    "gamma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning k ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MSE score with k=1: 9.011244019138756\n",
      "Average MSE score with k=2: 6.6930261481913735\n",
      "Average MSE score with k=3: 6.01618916449827\n",
      "Average MSE score with k=4: 5.730333611942119\n",
      "Average MSE score with k=5: 5.561518517526219\n",
      "Average MSE score with k=6: 5.4809541314959125\n",
      "Average MSE score with k=7: 5.427254608054996\n",
      "Average MSE score with k=8: 5.416797042781171\n",
      "Average MSE score with k=9: 5.367373734824553\n",
      "Average MSE score with k=10: 5.36501849792748\n",
      "Average MSE score with k=11: 5.346401256003911\n",
      "Average MSE score with k=12: 5.3394929506791495\n",
      "Average MSE score with k=13: 5.3320039310301794\n",
      "Average MSE score with k=14: 5.326054590335817\n",
      "Best k is 14 with the lowest average MSE score of 5.326054590335817\n"
     ]
    }
   ],
   "source": [
    "hyperparameters = np.arange(1,15,1)\n",
    "scores_dict = {}\n",
    "\n",
    "for k in hyperparameters: \n",
    "    scores = []\n",
    "    for i, (train_set_1, train_set_2) in enumerate(cross_validator.cross_validation(data_train, n_splits=2, n_repeats=5, random_state=42, stratify=False)):\n",
    "        \n",
    "        data_train_standardized = data_processor.standardize_data(train_set_1, train_set_1, features=features)\n",
    "        data_val_standardized = data_processor.standardize_data(train_set_1,data_val,features=features)  \n",
    "\n",
    "        predictions_1 = knn_model.knn_regression(data_val_standardized, data_train_standardized, k=k, gamma=gamma)['Predicted Value']\n",
    "        score_1 = Evaluation().mean_squared_error(data_val_standardized[config['target_column']], predictions_1)\n",
    "        scores.append(score_1)\n",
    "\n",
    "    average_score = sum(scores) / len(scores)\n",
    "    print(f\"Average MSE score with k={k}: {average_score}\")\n",
    "    scores_dict[k] = average_score\n",
    "\n",
    "best_k = min(scores_dict, key=scores_dict.get)\n",
    "print(f\"Best k is {best_k} with the lowest average MSE score of {scores_dict[best_k]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning Gamma ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MSE score with g=0.4: 5.335759776073148\n",
      "Average MSE score with g=0.6: 5.332348222206654\n",
      "Average MSE score with g=0.8: 5.329107017743394\n",
      "Average MSE score with g=1.0: 5.326054590335817\n",
      "Average MSE score with g=1.2: 5.323209126002804\n",
      "Average MSE score with g=1.4: 5.320587877144758\n",
      "Average MSE score with g=1.6: 5.31820631072449\n",
      "Best g is 1.6 with the lowest average MSE score of 5.31820631072449\n"
     ]
    }
   ],
   "source": [
    "hyperparameters = np.arange(0.4,1.6,0.2)\n",
    "scores_dict = {}\n",
    "\n",
    "for g in hyperparameters: \n",
    "    scores = []\n",
    "    for i, (train_set_1, train_set_2) in enumerate(cross_validator.cross_validation(data_train, n_splits=2, n_repeats=5, random_state=42, stratify=False)):\n",
    "        \n",
    "        data_train_standardized = data_processor.standardize_data(train_set_1, train_set_1, features=features)\n",
    "        data_val_standardized = data_processor.standardize_data(train_set_1,data_val,features=features)  \n",
    "\n",
    "        predictions_1 = knn_model.knn_regression(data_val_standardized, data_train_standardized, k=best_k, gamma=gamma*g)['Predicted Value']\n",
    "        score_1 = Evaluation().mean_squared_error(data_val_standardized[config['target_column']], predictions_1)\n",
    "        scores.append(score_1)\n",
    "\n",
    "    average_score = sum(scores) / len(scores)\n",
    "    print(f\"Average MSE score with g={round(g,2)}: {average_score}\")\n",
    "    scores_dict[g] = average_score\n",
    "\n",
    "best_g = min(scores_dict, key=scores_dict.get)\n",
    "print(f\"Best g is {round(best_g,2)} with the lowest average MSE score of {scores_dict[best_g]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Srikanta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\stats\\stats.py:3913: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n",
      "c:\\Users\\Srikanta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\stats\\stats.py:3913: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n",
      "c:\\Users\\Srikanta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\stats\\stats.py:3913: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n",
      "c:\\Users\\Srikanta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\stats\\stats.py:3913: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n",
      "c:\\Users\\Srikanta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\stats\\stats.py:3913: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n",
      "c:\\Users\\Srikanta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\stats\\stats.py:3913: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n",
      "c:\\Users\\Srikanta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\stats\\stats.py:3913: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n",
      "c:\\Users\\Srikanta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\stats\\stats.py:3913: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n",
      "c:\\Users\\Srikanta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\stats\\stats.py:3913: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average null model MSE score: 10.280610937065877\n",
      "Average null model MAE score: 2.357776660660252\n",
      "Average null model r2 score: 0.0\n",
      "Average null model pearson score: nan\n",
      "Average MSE score for k=14, g=1.6: 5.1089882327866265\n",
      "Average MAE score for k=14, g=1.6: 1.5702938978324343\n",
      "Average r2 score for k=14, g=1.6: 0.5031724623897341\n",
      "Average pearson score for k=14, g=1.6: 0.713623735959675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Srikanta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\stats\\stats.py:3913: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    }
   ],
   "source": [
    "mse_scores =[]\n",
    "mae_scores = []\n",
    "r2_scores = []\n",
    "pearson_scores = []\n",
    "null_model_scores = []\n",
    "\n",
    "# Lists for storing null model metrics\n",
    "null_model_mae_scores = []\n",
    "null_model_r2_scores = []\n",
    "null_model_pearson_scores = []\n",
    "\n",
    "for i, (train_set, test_set) in enumerate(cross_validator.cross_validation(data_train, n_splits=2, n_repeats=5, random_state=42, stratify=False)):\n",
    "\n",
    "    data_train_standardized = data_processor.standardize_data(train_set, train_set, features=features)\n",
    "    data_test_standardized = data_processor.standardize_data(train_set,test_set,features=features)  \n",
    "\n",
    "    # Train and evaluate \n",
    "    predictions_1 = knn_model.knn_regression(data_test_standardized, data_train_standardized, k=best_k, gamma=best_g*gamma)['Predicted Value']\n",
    "    \n",
    "    mse_score = Evaluation.mean_squared_error(data_test_standardized[config['target_column']], predictions_1)\n",
    "    mae_score = Evaluation.mean_absolute_error(data_test_standardized[config['target_column']], predictions_1)\n",
    "    r2_score = Evaluation.r2_coefficient(data_test_standardized[config['target_column']], predictions_1)\n",
    "    pearson_score = Evaluation.pearsons_correlation(data_test_standardized[config['target_column']], predictions_1)\n",
    "    \n",
    "    mse_scores.append(mse_score)\n",
    "    mae_scores.append(mae_score)\n",
    "    r2_scores.append(r2_score)\n",
    "    pearson_scores.append(pearson_score)\n",
    "\n",
    "    # Evaluate null model\n",
    "    null_model_prediction = null_model.naive_regression(test_set)\n",
    "    null_model_mse = Evaluation.mean_squared_error(test_set[config['target_column']], null_model_prediction)\n",
    "    null_model_mae = Evaluation.mean_absolute_error(test_set[config['target_column']], null_model_prediction)\n",
    "    null_model_r2 = Evaluation.r2_coefficient(test_set[config['target_column']], null_model_prediction)\n",
    "    null_model_pearson = Evaluation.pearsons_correlation(test_set[config['target_column']], null_model_prediction)\n",
    "    \n",
    "    null_model_scores.append(null_model_mse)\n",
    "    null_model_mae_scores.append(null_model_mae)\n",
    "    null_model_r2_scores.append(null_model_r2)\n",
    "    null_model_pearson_scores.append(null_model_pearson)\n",
    "\n",
    "\n",
    "average_mse_score = sum(mse_scores) / len(mse_scores)\n",
    "average_mae_score = sum(mae_scores) / len(mae_scores)\n",
    "average_r2_score = sum(r2_scores) / len(r2_scores)\n",
    "average_pearson_score = sum(pearson_scores) / len(pearson_scores)\n",
    "average_null_model_mse = sum(null_model_scores) / len(null_model_scores)\n",
    "average_null_model_mae = sum(null_model_mae_scores) / len(null_model_mae_scores)\n",
    "average_null_model_r2 = sum(null_model_r2_scores) / len(null_model_r2_scores)\n",
    "average_null_model_pearson = sum(null_model_pearson_scores) / len(null_model_pearson_scores)\n",
    "\n",
    "print(f\"Average null model MSE score: {average_null_model_mse}\")\n",
    "print(f\"Average null model MAE score: {average_null_model_mae}\")\n",
    "print(f\"Average null model r2 score: {average_null_model_r2}\")\n",
    "print(f\"Average null model pearson score: {average_null_model_pearson}\")\n",
    "print(f\"Average MSE score for k={best_k}, g={round(best_g,2)}: {average_mse_score}\")\n",
    "print(f\"Average MAE score for k={best_k}, g={round(best_g,2)}: {average_mae_score}\")\n",
    "print(f\"Average r2 score for k={best_k}, g={round(best_g,2)}: {average_r2_score}\")\n",
    "print(f\"Average pearson score for k={best_k}, g={round(best_g,2)}: {average_pearson_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edited KNN ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.224169032068128"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epsilon = statistics.stdev(data_3[config['target_column']])\n",
    "epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning Epsilon ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MSE score with e=0.1: 7.019759180527191\n",
      "Average MSE score with e=0.3: 7.019759180527191\n",
      "Average MSE score with e=0.5: 6.437103273868982\n",
      "Average MSE score with e=0.7: 6.1841592565606645\n",
      "Average MSE score with e=0.9: 6.1841592565606645\n",
      "Average MSE score with e=1.1: 5.8807633841670635\n",
      "Average MSE score with e=1.3: 5.725964286549791\n",
      "Average MSE score with e=1.5: 5.725964286549791\n",
      "Average MSE score with e=1.7: 5.5846453107327765\n",
      "Average MSE score with e=1.9: 5.500619411995783\n",
      "Best e is 1.9 with the lowest average MSE score of 5.500619411995783\n"
     ]
    }
   ],
   "source": [
    "hyperparameters = np.arange(0.1,2,0.2)\n",
    "scores_dict = {}\n",
    "\n",
    "for e in hyperparameters: \n",
    "    scores = []\n",
    "    for i, (train_set_1, train_set_2) in enumerate(cross_validator.cross_validation(data_train, n_splits=2, n_repeats=5, random_state=42, stratify=False)):\n",
    "        \n",
    "        edited_train_set = knn_model.edited_knn_regression(train_set_1, train_set_2, epsilon=epsilon*e, gamma=gamma)\n",
    "\n",
    "        data_train_standardized = data_processor.standardize_data(edited_train_set, edited_train_set, features=features)\n",
    "        data_val_standardized = data_processor.standardize_data(edited_train_set,data_val,features=features)  \n",
    "\n",
    "        predictions_1 = knn_model.knn_regression(data_val_standardized, data_train_standardized, k=best_k, gamma=gamma*best_g)['Predicted Value']\n",
    "        score_1 = Evaluation().mean_squared_error(data_val_standardized[config['target_column']], predictions_1)\n",
    "        scores.append(score_1)\n",
    "\n",
    "    average_score = sum(scores) / len(scores)\n",
    "    print(f\"Average MSE score with e={round(e,2)}: {average_score}\")\n",
    "    scores_dict[e] = average_score\n",
    "\n",
    "best_e = min(scores_dict, key=scores_dict.get)\n",
    "print(f\"Best e is {round(best_e,2)} with the lowest average MSE score of {scores_dict[best_e]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning k ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MSE score with k=1: 8.020933014354068\n",
      "Average MSE score with k=2: 6.350068183753953\n",
      "Average MSE score with k=3: 5.83803300687887\n",
      "Average MSE score with k=4: 5.6754306068453415\n",
      "Average MSE score with k=5: 5.5643224475117155\n",
      "Average MSE score with k=6: 5.531634711156073\n",
      "Average MSE score with k=7: 5.523789248455772\n",
      "Average MSE score with k=8: 5.509620763446195\n",
      "Average MSE score with k=9: 5.489818282949789\n",
      "Best k is 9 with the lowest average MSE score of 5.489818282949789\n"
     ]
    }
   ],
   "source": [
    "hyperparameters = np.arange(1,10,1)\n",
    "scores_dict = {}\n",
    "\n",
    "for k in hyperparameters: \n",
    "    scores = []\n",
    "    for i, (train_set_1, train_set_2) in enumerate(cross_validator.cross_validation(data_train, n_splits=2, n_repeats=5, random_state=42, stratify=False)):\n",
    "        \n",
    "        edited_train_set = knn_model.edited_knn_regression(train_set_1, train_set_2, epsilon=epsilon*best_e, gamma=gamma)\n",
    "\n",
    "        data_train_standardized = data_processor.standardize_data(edited_train_set, edited_train_set, features=features)\n",
    "        data_val_standardized = data_processor.standardize_data(edited_train_set,data_val,features=features)  \n",
    "\n",
    "        predictions_1 = knn_model.knn_regression(data_val_standardized, data_train_standardized, k=k, gamma=gamma*best_g)['Predicted Value']\n",
    "        score_1 = Evaluation().mean_squared_error(data_val_standardized[config['target_column']], predictions_1)\n",
    "        scores.append(score_1)\n",
    "\n",
    "    average_score = sum(scores) / len(scores)\n",
    "    print(f\"Average MSE score with k={k}: {average_score}\")\n",
    "    scores_dict[k] = average_score\n",
    "\n",
    "best_k = min(scores_dict, key=scores_dict.get)\n",
    "print(f\"Best k is {best_k} with the lowest average MSE score of {scores_dict[best_k]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning gamma ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MSE score with g=0.4: 5.502603329803368\n",
      "Average MSE score with g=0.6: 5.50007590463503\n",
      "Average MSE score with g=0.8: 5.49769890532044\n",
      "Average MSE score with g=1.0: 5.495480588657418\n",
      "Average MSE score with g=1.2: 5.493426624677425\n",
      "Average MSE score with g=1.4: 5.491539527782172\n",
      "Average MSE score with g=1.6: 5.489818282949789\n",
      "Best g is 1.6 with the lowest average MSE score of 5.489818282949789\n"
     ]
    }
   ],
   "source": [
    "hyperparameters = np.arange(0.4,1.6,0.2)\n",
    "scores_dict = {}\n",
    "\n",
    "for g in hyperparameters: \n",
    "    scores = []\n",
    "    for i, (train_set_1, train_set_2) in enumerate(cross_validator.cross_validation(data_train, n_splits=2, n_repeats=5, random_state=42, stratify=False)):\n",
    "        \n",
    "        edited_train_set = knn_model.edited_knn_regression(train_set_1, train_set_2, epsilon=epsilon*best_e, gamma=gamma)\n",
    "\n",
    "        data_train_standardized = data_processor.standardize_data(edited_train_set, edited_train_set, features=features)\n",
    "        data_val_standardized = data_processor.standardize_data(edited_train_set,data_val,features=features)  \n",
    "\n",
    "        predictions_1 = knn_model.knn_regression(data_val_standardized, data_train_standardized, k=best_k, gamma=g*gamma)['Predicted Value']\n",
    "        score_1 = Evaluation().mean_squared_error(data_val_standardized[config['target_column']], predictions_1)\n",
    "        scores.append(score_1)\n",
    "\n",
    "    average_score = sum(scores) / len(scores)\n",
    "    print(f\"Average MSE score with g={round(g,2)}: {average_score}\")\n",
    "    scores_dict[g] = average_score\n",
    "\n",
    "best_g = min(scores_dict, key=scores_dict.get)\n",
    "print(f\"Best g is {round(best_g,2)} with the lowest average MSE score of {scores_dict[best_g]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Srikanta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\stats\\stats.py:3913: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n",
      "c:\\Users\\Srikanta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\stats\\stats.py:3913: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n",
      "c:\\Users\\Srikanta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\stats\\stats.py:3913: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n",
      "c:\\Users\\Srikanta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\stats\\stats.py:3913: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n",
      "c:\\Users\\Srikanta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\stats\\stats.py:3913: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n",
      "c:\\Users\\Srikanta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\stats\\stats.py:3913: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n",
      "c:\\Users\\Srikanta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\stats\\stats.py:3913: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n",
      "c:\\Users\\Srikanta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\stats\\stats.py:3913: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n",
      "c:\\Users\\Srikanta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\stats\\stats.py:3913: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average null model MSE score: 10.280610937065877\n",
      "Average null model MAE score: 2.357776660660252\n",
      "Average null model R2 score: 0.0\n",
      "Average null model Pearson score: nan\n",
      "Average MSE score for k=9, g=1.6: 5.283134708476315\n",
      "Average MAE score for k=9, g=1.6: 1.5763915123066348\n",
      "Average R2 score for k=9, g=1.6: 0.48625131612526795\n",
      "Average Pearson score for k=9, g=1.6: 0.7069709024182674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Srikanta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\stats\\stats.py:3913: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    }
   ],
   "source": [
    "mse_scores = []\n",
    "mae_scores = []\n",
    "r2_scores = []\n",
    "pearson_scores = []\n",
    "null_model_scores = []\n",
    "\n",
    "# Lists to store null model metrics for MAE, R^2, and Pearson\n",
    "null_model_mae_scores = []\n",
    "null_model_r2_scores = []\n",
    "null_model_pearson_scores = []\n",
    "\n",
    "for i, (train_set, test_set) in enumerate(cross_validator.cross_validation(data_train, n_splits=2, n_repeats=5, random_state=42, stratify=False)):\n",
    "\n",
    "    edited_train_set = knn_model.edited_knn_regression(train_set, data_val, epsilon=epsilon*best_e, gamma=gamma)\n",
    "\n",
    "    data_train_standardized = data_processor.standardize_data(edited_train_set, edited_train_set, features=features)\n",
    "    data_test_standardized = data_processor.standardize_data(edited_train_set,test_set,features=features)  \n",
    "\n",
    "    predictions_1 = knn_model.knn_regression(data_test_standardized, data_train_standardized, k=best_k, gamma=best_g*gamma)['Predicted Value']\n",
    "\n",
    "    mse_score = Evaluation.mean_squared_error(data_test_standardized[config['target_column']], predictions_1)\n",
    "    mae_score = Evaluation.mean_absolute_error(data_test_standardized[config['target_column']], predictions_1)\n",
    "    r2_score = Evaluation.r2_coefficient(data_test_standardized[config['target_column']], predictions_1)\n",
    "    pearson_score = Evaluation.pearsons_correlation(data_test_standardized[config['target_column']], predictions_1)\n",
    "\n",
    "    mse_scores.append(mse_score)\n",
    "    mae_scores.append(mae_score)\n",
    "    r2_scores.append(r2_score)\n",
    "    pearson_scores.append(pearson_score)\n",
    "    \n",
    "    # Null model evaluation\n",
    "    null_model_prediction = null_model.naive_regression(test_set)\n",
    "    null_model_mse = Evaluation.mean_squared_error(test_set[config['target_column']], null_model_prediction)\n",
    "    null_model_mae = Evaluation.mean_absolute_error(test_set[config['target_column']], null_model_prediction)\n",
    "    null_model_r2 = Evaluation.r2_coefficient(test_set[config['target_column']], null_model_prediction)\n",
    "    null_model_pearson = Evaluation.pearsons_correlation(test_set[config['target_column']], null_model_prediction)\n",
    "\n",
    "    null_model_scores.append(null_model_mse)\n",
    "    null_model_mae_scores.append(null_model_mae)\n",
    "    null_model_r2_scores.append(null_model_r2)\n",
    "    null_model_pearson_scores.append(null_model_pearson)\n",
    "\n",
    "average_mse_score = sum(mse_scores) / len(mse_scores)\n",
    "average_mae_score = sum(mae_scores) / len(mae_scores)\n",
    "average_r2_score = sum(r2_scores) / len(r2_scores)\n",
    "average_pearson_score = sum(pearson_scores) / len(pearson_scores)\n",
    "average_null_model_mse = sum(null_model_scores) / len(null_model_scores)\n",
    "average_null_model_mae = sum(null_model_mae_scores) / len(null_model_mae_scores)\n",
    "average_null_model_r2 = sum(null_model_r2_scores) / len(null_model_r2_scores)\n",
    "average_null_model_pearson = sum(null_model_pearson_scores) / len(null_model_pearson_scores)\n",
    "\n",
    "print(f\"Average null model MSE score: {average_null_model_mse}\")\n",
    "print(f\"Average null model MAE score: {average_null_model_mae}\")\n",
    "print(f\"Average null model R2 score: {average_null_model_r2}\")\n",
    "print(f\"Average null model Pearson score: {average_null_model_pearson}\")\n",
    "print(f\"Average MSE score for k={best_k}, g={round(best_g,2)}: {average_mse_score}\")\n",
    "print(f\"Average MAE score for k={best_k}, g={round(best_g,2)}: {average_mae_score}\")\n",
    "print(f\"Average R2 score for k={best_k}, g={round(best_g,2)}: {average_r2_score}\")\n",
    "print(f\"Average Pearson score for k={best_k}, g={round(best_g,2)}: {average_pearson_score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Condensed Knn ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning Epsilon ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MSE score with e=0.1: 5.363871157313764\n",
      "Average MSE score with e=0.2: 5.3636450283162524\n",
      "Average MSE score with e=0.3: 5.365356633991318\n",
      "Average MSE score with e=0.4: 5.470011141323902\n",
      "Average MSE score with e=0.5: 5.463391054714149\n",
      "Average MSE score with e=0.6: 5.4652651988622045\n",
      "Average MSE score with e=0.7: 5.71327257684247\n",
      "Average MSE score with e=0.8: 5.712733942048611\n",
      "Average MSE score with e=0.9: 5.713396478881825\n",
      "Average MSE score with e=1.0: 5.981877926876671\n",
      "Average MSE score with e=1.1: 5.988532079011377\n",
      "Average MSE score with e=1.2: 6.011768147162297\n",
      "Average MSE score with e=1.3: 6.269499103256668\n",
      "Average MSE score with e=1.4: 6.335307124091774\n",
      "Best e is 0.2 with the lowest average MSE score of 5.3636450283162524\n"
     ]
    }
   ],
   "source": [
    "hyperparameters = np.arange(0.1,1.5,0.1)\n",
    "scores_dict = {}\n",
    "\n",
    "for e in hyperparameters: \n",
    "    scores = []\n",
    "    for i, (train_set_1, train_set_2) in enumerate(cross_validator.cross_validation(data_train, n_splits=2, n_repeats=5, random_state=42, stratify=False)):\n",
    "        \n",
    "        condesed_train_set = knn_model.condensed_knn_regression(train_set_1,epsilon=epsilon*e)\n",
    "\n",
    "        data_train_standardized = data_processor.standardize_data(condesed_train_set, condesed_train_set, features=features)\n",
    "        data_val_standardized = data_processor.standardize_data(condesed_train_set,data_val,features=features)\n",
    "\n",
    "        predictions_1 = knn_model.knn_regression(data_val_standardized, data_train_standardized, k=best_k, gamma=gamma*best_g)['Predicted Value']\n",
    "        score_1 = Evaluation().mean_squared_error(data_val_standardized[config['target_column']], predictions_1)\n",
    "        scores.append(score_1)\n",
    "\n",
    "    average_score = sum(scores) / len(scores)\n",
    "    print(f\"Average MSE score with e={round(e,2)}: {average_score}\")\n",
    "    scores_dict[e] = average_score\n",
    "\n",
    "best_e = min(scores_dict, key=scores_dict.get)\n",
    "print(f\"Best e is {round(best_e,2)} with the lowest average MSE score of {scores_dict[best_e]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning k ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MSE score with k=1: 9.176076555023922\n",
      "Average MSE score with k=2: 6.763807494787376\n",
      "Average MSE score with k=3: 6.057933035967641\n",
      "Average MSE score with k=4: 5.7698409180039025\n",
      "Average MSE score with k=5: 5.588689898856752\n",
      "Average MSE score with k=6: 5.509740948595235\n",
      "Average MSE score with k=7: 5.452569515604357\n",
      "Average MSE score with k=8: 5.40876597250405\n",
      "Average MSE score with k=9: 5.364262796288996\n",
      "Best k is 9 with the lowest average MSE score of 5.364262796288996\n"
     ]
    }
   ],
   "source": [
    "hyperparameters = np.arange(1,10,1)\n",
    "scores_dict = {}\n",
    "\n",
    "for k in hyperparameters: \n",
    "    scores = []\n",
    "    for i, (train_set_1, train_set_2) in enumerate(cross_validator.cross_validation(data_train, n_splits=2, n_repeats=5, random_state=42, stratify=False)):\n",
    "        \n",
    "        condesed_train_set = knn_model.condensed_knn_regression(train_set_1,epsilon=epsilon*best_e)\n",
    "\n",
    "        data_train_standardized = data_processor.standardize_data(condesed_train_set, condesed_train_set, features=features)\n",
    "        data_val_standardized = data_processor.standardize_data(condesed_train_set,data_val,features=features)\n",
    "\n",
    "        predictions_1 = knn_model.knn_regression(data_val_standardized, data_train_standardized, k=k, gamma=gamma*best_g)['Predicted Value']\n",
    "        score_1 = Evaluation().mean_squared_error(data_val_standardized[config['target_column']], predictions_1)\n",
    "        scores.append(score_1)\n",
    "\n",
    "    average_score = sum(scores) / len(scores)\n",
    "    print(f\"Average MSE score with k={k}: {average_score}\")\n",
    "    scores_dict[k] = average_score\n",
    "\n",
    "best_k = min(scores_dict, key=scores_dict.get)\n",
    "print(f\"Best k is {best_k} with the lowest average MSE score of {scores_dict[best_k]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning Gamma ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MSE score with g=0.4: 5.374235778263465\n",
      "Average MSE score with g=0.6: 5.370587960283816\n",
      "Average MSE score with g=0.8: 5.370217536397965\n",
      "Average MSE score with g=1.0: 5.369253859382793\n",
      "Average MSE score with g=1.2: 5.366226276836631\n",
      "Average MSE score with g=1.4: 5.365978528240339\n",
      "Average MSE score with g=1.6: 5.362337614264318\n",
      "Best g is 1.6 with the lowest average MSE score of 5.362337614264318\n"
     ]
    }
   ],
   "source": [
    "hyperparameters = np.arange(0.4,1.6,0.2)\n",
    "scores_dict = {}\n",
    "\n",
    "for g in hyperparameters: \n",
    "    scores = []\n",
    "    for i, (train_set_1, train_set_2) in enumerate(cross_validator.cross_validation(data_train, n_splits=2, n_repeats=5, random_state=42, stratify=False)):\n",
    "        \n",
    "        condesed_train_set = knn_model.condensed_knn_regression(train_set_1,epsilon=epsilon*best_e)\n",
    "\n",
    "        data_train_standardized = data_processor.standardize_data(condesed_train_set, condesed_train_set, features=features)\n",
    "        data_val_standardized = data_processor.standardize_data(condesed_train_set,data_val,features=features)  \n",
    "\n",
    "        predictions_1 = knn_model.knn_regression(data_val_standardized, data_train_standardized, k=best_k, gamma=g*gamma)['Predicted Value']\n",
    "        score_1 = Evaluation().mean_squared_error(data_val_standardized[config['target_column']], predictions_1)\n",
    "        scores.append(score_1)\n",
    "\n",
    "    average_score = sum(scores) / len(scores)\n",
    "    print(f\"Average MSE score with g={round(g,2)}: {average_score}\")\n",
    "    scores_dict[g] = average_score\n",
    "\n",
    "best_g = min(scores_dict, key=scores_dict.get)\n",
    "print(f\"Best g is {round(best_g,2)} with the lowest average MSE score of {scores_dict[best_g]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Srikanta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\stats\\stats.py:3913: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n",
      "c:\\Users\\Srikanta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\stats\\stats.py:3913: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n",
      "c:\\Users\\Srikanta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\stats\\stats.py:3913: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n",
      "c:\\Users\\Srikanta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\stats\\stats.py:3913: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n",
      "c:\\Users\\Srikanta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\stats\\stats.py:3913: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n",
      "c:\\Users\\Srikanta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\stats\\stats.py:3913: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n",
      "c:\\Users\\Srikanta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\stats\\stats.py:3913: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n",
      "c:\\Users\\Srikanta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\stats\\stats.py:3913: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n",
      "c:\\Users\\Srikanta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\stats\\stats.py:3913: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average null model MSE score: 10.280610937065877\n",
      "Average null model MAE score: 2.357776660660252\n",
      "Average null model R2 score: 0.0\n",
      "Average null model Pearson score: nan\n",
      "Average MSE score for k=9, g=1.6: 5.187008768531422\n",
      "Average MAE score for k=9, g=1.6: 1.6263701693198604\n",
      "Average R2 score for k=9, g=1.6: 0.49533757134630657\n",
      "Average Pearson score for k=9, g=1.6: 0.7051203958427629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Srikanta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\stats\\stats.py:3913: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    }
   ],
   "source": [
    "mse_scores = []\n",
    "mae_scores = []\n",
    "r2_scores = []\n",
    "pearson_scores = []\n",
    "null_model_scores = []\n",
    "\n",
    "# Lists to store null model metrics for MAE, R^2, and Pearson\n",
    "null_model_mae_scores = []\n",
    "null_model_r2_scores = []\n",
    "null_model_pearson_scores = []\n",
    "\n",
    "for i, (train_set, test_set) in enumerate(cross_validator.cross_validation(data_train, n_splits=2, n_repeats=5, random_state=42, stratify=False)):\n",
    "\n",
    "    condesed_train_set = knn_model.condensed_knn_regression(train_set,epsilon=epsilon*best_e)\n",
    "\n",
    "    data_train_standardized = data_processor.standardize_data(condesed_train_set, condesed_train_set, features=features)\n",
    "    data_test_standardized = data_processor.standardize_data(edited_train_set,test_set,features=features)  \n",
    "\n",
    "    predictions_1 = knn_model.knn_regression(data_test_standardized, data_train_standardized, k=best_k, gamma=best_g*gamma)['Predicted Value']\n",
    "\n",
    "    mse_score = Evaluation.mean_squared_error(data_test_standardized[config['target_column']], predictions_1)\n",
    "    mae_score = Evaluation.mean_absolute_error(data_test_standardized[config['target_column']], predictions_1)\n",
    "    r2_score = Evaluation.r2_coefficient(data_test_standardized[config['target_column']], predictions_1)\n",
    "    pearson_score = Evaluation.pearsons_correlation(data_test_standardized[config['target_column']], predictions_1)\n",
    "\n",
    "    mse_scores.append(mse_score)\n",
    "    mae_scores.append(mae_score)\n",
    "    r2_scores.append(r2_score)\n",
    "    pearson_scores.append(pearson_score)\n",
    "    \n",
    "    # Null model evaluation\n",
    "    null_model_prediction = null_model.naive_regression(test_set)\n",
    "    null_model_mse = Evaluation.mean_squared_error(test_set[config['target_column']], null_model_prediction)\n",
    "    null_model_mae = Evaluation.mean_absolute_error(test_set[config['target_column']], null_model_prediction)\n",
    "    null_model_r2 = Evaluation.r2_coefficient(test_set[config['target_column']], null_model_prediction)\n",
    "    null_model_pearson = Evaluation.pearsons_correlation(test_set[config['target_column']], null_model_prediction)\n",
    "\n",
    "    null_model_scores.append(null_model_mse)\n",
    "    null_model_mae_scores.append(null_model_mae)\n",
    "    null_model_r2_scores.append(null_model_r2)\n",
    "    null_model_pearson_scores.append(null_model_pearson)\n",
    "\n",
    "\n",
    "average_mse_score = sum(mse_scores) / len(mse_scores)\n",
    "average_mae_score = sum(mae_scores) / len(mae_scores)\n",
    "average_r2_score = sum(r2_scores) / len(r2_scores)\n",
    "average_pearson_score = sum(pearson_scores) / len(pearson_scores)\n",
    "average_null_model_mse = sum(null_model_scores) / len(null_model_scores)\n",
    "average_null_model_mae = sum(null_model_mae_scores) / len(null_model_mae_scores)\n",
    "average_null_model_r2 = sum(null_model_r2_scores) / len(null_model_r2_scores)\n",
    "average_null_model_pearson = sum(null_model_pearson_scores) / len(null_model_pearson_scores)\n",
    "\n",
    "\n",
    "print(f\"Average null model MSE score: {average_null_model_mse}\")\n",
    "print(f\"Average null model MAE score: {average_null_model_mae}\")\n",
    "print(f\"Average null model R2 score: {average_null_model_r2}\")\n",
    "print(f\"Average null model Pearson score: {average_null_model_pearson}\")\n",
    "print(f\"Average MSE score for k={best_k}, g={round(best_g,2)}: {average_mse_score}\")\n",
    "print(f\"Average MAE score for k={best_k}, g={round(best_g,2)}: {average_mae_score}\")\n",
    "print(f\"Average R2 score for k={best_k}, g={round(best_g,2)}: {average_r2_score}\")\n",
    "print(f\"Average Pearson score for k={best_k}, g={round(best_g,2)}: {average_pearson_score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
