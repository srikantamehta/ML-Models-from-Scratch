{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_preprocessor import DataProcessor\n",
    "from data_configs.configs import *\n",
    "from models.decision_tree import DecisionTree, DecisionTreeNode\n",
    "from models.null_model import NullModelClassification, NullModelRegression\n",
    "from src.cross_validation import CrossValidation\n",
    "from src.evaluation import Evaluation\n",
    "import numpy as np\n",
    "\n",
    "config = machine_config\n",
    "data_processor = DataProcessor(config=config)\n",
    "cross_validator = CrossValidation(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Load and Preprocessing ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = data_processor.load_data()\n",
    "\n",
    "data_1 = data_processor.impute_missing_values(raw_data)\n",
    "\n",
    "data_2 = data_1.drop(columns=['vendor_name', 'model_name','ERP'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MYCT</th>\n",
       "      <th>MMIN</th>\n",
       "      <th>MMAX</th>\n",
       "      <th>CACH</th>\n",
       "      <th>CHMIN</th>\n",
       "      <th>CHMAX</th>\n",
       "      <th>PRP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>209.000000</td>\n",
       "      <td>209.000000</td>\n",
       "      <td>209.000000</td>\n",
       "      <td>209.000000</td>\n",
       "      <td>209.000000</td>\n",
       "      <td>209.000000</td>\n",
       "      <td>209.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>203.822967</td>\n",
       "      <td>2867.980861</td>\n",
       "      <td>11796.153110</td>\n",
       "      <td>25.205742</td>\n",
       "      <td>4.698565</td>\n",
       "      <td>18.267943</td>\n",
       "      <td>105.622010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>260.262926</td>\n",
       "      <td>3878.742758</td>\n",
       "      <td>11726.564377</td>\n",
       "      <td>40.628722</td>\n",
       "      <td>6.816274</td>\n",
       "      <td>25.997318</td>\n",
       "      <td>160.830733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>110.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>225.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>16000.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>113.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1500.000000</td>\n",
       "      <td>32000.000000</td>\n",
       "      <td>64000.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>1150.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              MYCT          MMIN          MMAX        CACH       CHMIN  \\\n",
       "count   209.000000    209.000000    209.000000  209.000000  209.000000   \n",
       "mean    203.822967   2867.980861  11796.153110   25.205742    4.698565   \n",
       "std     260.262926   3878.742758  11726.564377   40.628722    6.816274   \n",
       "min      17.000000     64.000000     64.000000    0.000000    0.000000   \n",
       "25%      50.000000    768.000000   4000.000000    0.000000    1.000000   \n",
       "50%     110.000000   2000.000000   8000.000000    8.000000    2.000000   \n",
       "75%     225.000000   4000.000000  16000.000000   32.000000    6.000000   \n",
       "max    1500.000000  32000.000000  64000.000000  256.000000   52.000000   \n",
       "\n",
       "            CHMAX          PRP  \n",
       "count  209.000000   209.000000  \n",
       "mean    18.267943   105.622010  \n",
       "std     25.997318   160.830733  \n",
       "min      0.000000     6.000000  \n",
       "25%      5.000000    27.000000  \n",
       "50%      8.000000    50.000000  \n",
       "75%     24.000000   113.000000  \n",
       "max    176.000000  1150.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_val = cross_validator.random_partition(data_2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Performance ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Decision Tree Scores:\n",
      "mse: 7077.102086775674\n",
      "mae: 38.49862545419775\n",
      "r2: 0.6411596863377425\n",
      "pearson_correlation: 0.8205723803138651\n",
      "\n",
      "Average Pruned Decision Tree Scores:\n",
      "mse: 7617.832635956525\n",
      "mae: 42.278047905909354\n",
      "r2: 0.6128138773730151\n",
      "pearson_correlation: 0.816127889774094\n",
      "\n",
      "Average Null Model Scores:\n",
      "mse: 19073.865381296106\n",
      "mae: 86.17113664476774\n"
     ]
    }
   ],
   "source": [
    "# Initialize lists to store scores for decision tree, pruned decision tree, and null model\n",
    "dt_scores = {'mse': [], 'mae': [], 'r2': [], 'pearson_correlation': []}\n",
    "pruned_dt_scores = {'mse': [], 'mae': [], 'r2': [], 'pearson_correlation': []}\n",
    "null_model_scores = {'mse': [], 'mae': []}  \n",
    "\n",
    "for i, (train_set, test_set) in enumerate(cross_validator.cross_validation(data_train, n_splits=2, n_repeats=5, random_state=42, stratify=False)):\n",
    "    train_data = train_set.drop(columns=config['target_column'])\n",
    "    train_target = train_set[config['target_column']]\n",
    "    test_features = test_set.drop(columns=config['target_column'])\n",
    "    test_true_vals = test_set[config['target_column']]\n",
    "\n",
    "    # Decision Tree Model\n",
    "    decision_tree = DecisionTree(config,data_2)\n",
    "    decision_tree.root = decision_tree.build_regression_tree(train_data, train_target)\n",
    "    predictions = decision_tree.predict(test_features)\n",
    "\n",
    "    # Calculate and store decision tree scores\n",
    "    scores = Evaluation.calculate_regression_scores(test_true_vals, predictions)\n",
    "    for key in dt_scores:\n",
    "        dt_scores[key].append(scores[key])\n",
    "\n",
    "    # Pruning the Decision Tree\n",
    "    decision_tree.prune(decision_tree.root, data_val)  # Ensure data_val is correctly defined as your validation set\n",
    "    pruned_predictions = decision_tree.predict(test_features)\n",
    "\n",
    "    # Calculate and store pruned decision tree scores\n",
    "    pruned_scores = Evaluation.calculate_regression_scores(test_true_vals, pruned_predictions)\n",
    "    for key in pruned_dt_scores:\n",
    "        pruned_dt_scores[key].append(pruned_scores[key])\n",
    "\n",
    "    # Null Model\n",
    "    null_model = NullModelRegression(config=config)\n",
    "    null_model_prediction = null_model.naive_regression(test_set)\n",
    "\n",
    "    # Calculate and store null model scores (excluding R2 and Pearson)\n",
    "    null_model_mse = Evaluation.mean_squared_error(test_true_vals, null_model_prediction)\n",
    "    null_model_mae = Evaluation.mean_absolute_error(test_true_vals, null_model_prediction)\n",
    "    null_model_scores['mse'].append(null_model_mse)\n",
    "    null_model_scores['mae'].append(null_model_mae)\n",
    "\n",
    "# Calculate average scores for each model\n",
    "average_dt_scores = {metric: np.mean(values) for metric, values in dt_scores.items()}\n",
    "average_pruned_dt_scores = {metric: np.mean(values) for metric, values in pruned_dt_scores.items()}\n",
    "average_null_model_scores = {metric: np.mean(values) for metric, values in null_model_scores.items()}\n",
    "\n",
    "# Print average scores\n",
    "print(\"Average Decision Tree Scores:\")\n",
    "for metric, avg_score in average_dt_scores.items():\n",
    "    print(f\"{metric}: {avg_score}\")\n",
    "\n",
    "print(\"\\nAverage Pruned Decision Tree Scores:\")\n",
    "for metric, avg_score in average_pruned_dt_scores.items():\n",
    "    print(f\"{metric}: {avg_score}\")\n",
    "\n",
    "print(\"\\nAverage Null Model Scores:\")\n",
    "for metric, avg_score in average_null_model_scores.items():\n",
    "    print(f\"{metric}: {avg_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
