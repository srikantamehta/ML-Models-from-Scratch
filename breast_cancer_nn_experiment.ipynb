{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_preprocessor import DataProcessor\n",
    "from data_configs.configs import *\n",
    "from models.neural_networks import *\n",
    "from src.cross_validation import CrossValidation\n",
    "import numpy as np\n",
    "\n",
    "config = breast_cancer_config\n",
    "data_processor = DataProcessor(config=config)\n",
    "cross_validator = CrossValidation(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = data_processor.load_data()\n",
    "data_1 = data_processor.impute_missing_values(raw_data)\n",
    "data_2 = data_1.drop(columns=['Sample code number'])\n",
    "data_3 = data_processor.encode_ordinal_features(data_2)\n",
    "data_4 = data_processor.standardize_data(data_3,data_3,features=['Clump Thickness', 'Uniformity of Cell Size',\n",
    "       'Uniformity of Cell Shape', 'Marginal Adhesion',\n",
    "       'Single Epithelial Cell Size', 'Bare Nuclei', 'Bland Chromatin',\n",
    "       'Normal Nucleoli', 'Mitoses'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clump Thickness</th>\n",
       "      <th>Uniformity of Cell Size</th>\n",
       "      <th>Uniformity of Cell Shape</th>\n",
       "      <th>Marginal Adhesion</th>\n",
       "      <th>Single Epithelial Cell Size</th>\n",
       "      <th>Bare Nuclei</th>\n",
       "      <th>Bland Chromatin</th>\n",
       "      <th>Normal Nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.206788</td>\n",
       "      <td>-0.699494</td>\n",
       "      <td>-0.742767</td>\n",
       "      <td>-0.632794</td>\n",
       "      <td>-0.549168</td>\n",
       "      <td>-0.706485</td>\n",
       "      <td>-0.179534</td>\n",
       "      <td>-0.611387</td>\n",
       "      <td>-0.343666</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.206788</td>\n",
       "      <td>0.283642</td>\n",
       "      <td>0.266684</td>\n",
       "      <td>0.768071</td>\n",
       "      <td>1.708882</td>\n",
       "      <td>1.792229</td>\n",
       "      <td>-0.179534</td>\n",
       "      <td>-0.283909</td>\n",
       "      <td>-0.343666</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.503505</td>\n",
       "      <td>-0.699494</td>\n",
       "      <td>-0.742767</td>\n",
       "      <td>-0.632794</td>\n",
       "      <td>-0.549168</td>\n",
       "      <td>-0.428851</td>\n",
       "      <td>-0.179534</td>\n",
       "      <td>-0.611387</td>\n",
       "      <td>-0.343666</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.561934</td>\n",
       "      <td>1.594490</td>\n",
       "      <td>1.612618</td>\n",
       "      <td>-0.632794</td>\n",
       "      <td>-0.097558</td>\n",
       "      <td>0.126419</td>\n",
       "      <td>-0.179534</td>\n",
       "      <td>1.353485</td>\n",
       "      <td>-0.343666</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.148359</td>\n",
       "      <td>-0.699494</td>\n",
       "      <td>-0.742767</td>\n",
       "      <td>0.067638</td>\n",
       "      <td>-0.549168</td>\n",
       "      <td>-0.706485</td>\n",
       "      <td>-0.179534</td>\n",
       "      <td>-0.611387</td>\n",
       "      <td>-0.343666</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>-0.503505</td>\n",
       "      <td>-0.699494</td>\n",
       "      <td>-0.742767</td>\n",
       "      <td>-0.632794</td>\n",
       "      <td>-0.097558</td>\n",
       "      <td>-0.428851</td>\n",
       "      <td>-0.999756</td>\n",
       "      <td>-0.611387</td>\n",
       "      <td>-0.343666</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>-0.858651</td>\n",
       "      <td>-0.699494</td>\n",
       "      <td>-0.742767</td>\n",
       "      <td>-0.632794</td>\n",
       "      <td>-0.549168</td>\n",
       "      <td>-0.706485</td>\n",
       "      <td>-0.999756</td>\n",
       "      <td>-0.611387</td>\n",
       "      <td>-0.343666</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>0.206788</td>\n",
       "      <td>2.249915</td>\n",
       "      <td>2.285586</td>\n",
       "      <td>0.067638</td>\n",
       "      <td>1.708882</td>\n",
       "      <td>-0.151216</td>\n",
       "      <td>1.871021</td>\n",
       "      <td>2.335921</td>\n",
       "      <td>0.239398</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>-0.148359</td>\n",
       "      <td>1.594490</td>\n",
       "      <td>0.939651</td>\n",
       "      <td>0.417854</td>\n",
       "      <td>-0.097558</td>\n",
       "      <td>0.126419</td>\n",
       "      <td>2.691243</td>\n",
       "      <td>1.026006</td>\n",
       "      <td>-0.343666</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>-0.148359</td>\n",
       "      <td>1.594490</td>\n",
       "      <td>1.612618</td>\n",
       "      <td>0.768071</td>\n",
       "      <td>0.354052</td>\n",
       "      <td>0.404054</td>\n",
       "      <td>2.691243</td>\n",
       "      <td>0.371049</td>\n",
       "      <td>-0.343666</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>699 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Clump Thickness  Uniformity of Cell Size  Uniformity of Cell Shape  \\\n",
       "0           0.206788                -0.699494                 -0.742767   \n",
       "1           0.206788                 0.283642                  0.266684   \n",
       "2          -0.503505                -0.699494                 -0.742767   \n",
       "3           0.561934                 1.594490                  1.612618   \n",
       "4          -0.148359                -0.699494                 -0.742767   \n",
       "..               ...                      ...                       ...   \n",
       "694        -0.503505                -0.699494                 -0.742767   \n",
       "695        -0.858651                -0.699494                 -0.742767   \n",
       "696         0.206788                 2.249915                  2.285586   \n",
       "697        -0.148359                 1.594490                  0.939651   \n",
       "698        -0.148359                 1.594490                  1.612618   \n",
       "\n",
       "     Marginal Adhesion  Single Epithelial Cell Size  Bare Nuclei  \\\n",
       "0            -0.632794                    -0.549168    -0.706485   \n",
       "1             0.768071                     1.708882     1.792229   \n",
       "2            -0.632794                    -0.549168    -0.428851   \n",
       "3            -0.632794                    -0.097558     0.126419   \n",
       "4             0.067638                    -0.549168    -0.706485   \n",
       "..                 ...                          ...          ...   \n",
       "694          -0.632794                    -0.097558    -0.428851   \n",
       "695          -0.632794                    -0.549168    -0.706485   \n",
       "696           0.067638                     1.708882    -0.151216   \n",
       "697           0.417854                    -0.097558     0.126419   \n",
       "698           0.768071                     0.354052     0.404054   \n",
       "\n",
       "     Bland Chromatin  Normal Nucleoli   Mitoses  Class  \n",
       "0          -0.179534        -0.611387 -0.343666      2  \n",
       "1          -0.179534        -0.283909 -0.343666      2  \n",
       "2          -0.179534        -0.611387 -0.343666      2  \n",
       "3          -0.179534         1.353485 -0.343666      2  \n",
       "4          -0.179534        -0.611387 -0.343666      2  \n",
       "..               ...              ...       ...    ...  \n",
       "694        -0.999756        -0.611387 -0.343666      2  \n",
       "695        -0.999756        -0.611387 -0.343666      2  \n",
       "696         1.871021         2.335921  0.239398      4  \n",
       "697         2.691243         1.026006 -0.343666      4  \n",
       "698         2.691243         0.371049 -0.343666      4  \n",
       "\n",
       "[699 rows x 10 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_val = cross_validator.random_partition(data_4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_val = data_processor.encode_nominal_features(data_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = data_val.to_numpy()\n",
    "X_val = data_test[:,:-2]\n",
    "y_val = data_test[:,-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested params: {'lr': 0.001, 'epochs': 3000}, Score: 0.09679556054785152\n",
      "Tested params: {'lr': 1e-06, 'epochs': 11000}, Score: 0.11760015907610939\n",
      "Tested params: {'lr': 0.0001, 'epochs': 19000}, Score: 0.08120419794483275\n",
      "Tested params: {'lr': 0.01, 'epochs': 18000}, Score: 0.11034167774443762\n",
      "Tested params: {'lr': 1e-05, 'epochs': 20000}, Score: 0.07915639845216639\n",
      "Tested params: {'lr': 0.0001, 'epochs': 8000}, Score: 0.08122361785860831\n",
      "Tested params: {'lr': 0.001, 'epochs': 11000}, Score: 0.09679498720293966\n",
      "Tested params: {'lr': 1e-06, 'epochs': 14000}, Score: 0.10771810473704266\n",
      "Tested params: {'lr': 0.01, 'epochs': 1000}, Score: 0.11034122412734101\n",
      "Tested params: {'lr': 1e-06, 'epochs': 9000}, Score: 0.12753615690063147\n",
      "Tested params: {'lr': 0.01, 'epochs': 11000}, Score: 0.11033965936946608\n",
      "Tested params: {'lr': 0.01, 'epochs': 11000}, Score: 0.1103397932298309\n",
      "Tested params: {'lr': 1e-06, 'epochs': 6000}, Score: 0.15365715739282887\n",
      "Tested params: {'lr': 0.01, 'epochs': 9000}, Score: 0.11034157832618186\n",
      "Tested params: {'lr': 0.0001, 'epochs': 14000}, Score: 0.08121374601641254\n",
      "Best parameters: {'lr': 1e-05, 'epochs': 20000}, Best score: 0.07915639845216639\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "iterations = 15\n",
    "\n",
    "param_space = {\n",
    "    'lr': [0.01,0.001,0.0001,0.00001,0.000001],\n",
    "    'epochs': np.linspace(1000, 20000, num=20).astype(int).tolist()\n",
    "}\n",
    "\n",
    "best_score = float('inf')\n",
    "best_params_linear = {}\n",
    "\n",
    "for _ in range(iterations):\n",
    "\n",
    "    # Randomly select parameters\n",
    "    params = {key: random.choice(value) for key, value in param_space.items()}\n",
    "    scores = []\n",
    "\n",
    "    for i, (train_set, _) in enumerate(cross_validator.cross_validation(data_train, n_splits=2, n_repeats=5, random_state=42, stratify=True)):\n",
    "    \n",
    "        train_set = data_processor.encode_nominal_features(train_set)\n",
    "\n",
    "        train_data = train_set.to_numpy()\n",
    "        X_train = train_data[:,:-2]\n",
    "        y_train = train_data[:,-2:]\n",
    "\n",
    "        linear = LinearNetwork(config)\n",
    "\n",
    "        _, val_losses = linear.logistic_regression(X_train,y_train,X_val,y_val,epochs=params['epochs'],lr=params['lr'],patience=500)\n",
    "\n",
    "        score = val_losses[-1]\n",
    "        scores.append(score)\n",
    "\n",
    "        # Skip to the next parameter set if score > 0.2\n",
    "        if score > 0.2:\n",
    "            print(f\"Skipping params: {params} due to high score: {score}\")\n",
    "            break  # Exit the current for-loop\n",
    "        \n",
    "    avg_score = np.mean(scores)\n",
    "\n",
    "    print(f\"Tested params: {params}, Score: {avg_score}\")\n",
    "    \n",
    "    if avg_score < best_score:\n",
    "        best_score = avg_score\n",
    "        best_params_linear = params\n",
    "        \n",
    "\n",
    "print(f\"Best parameters: {best_params_linear}, Best score: {best_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping params: {'lr': 1e-06, 'epochs': 7000, 'n_hidden': 39} due to high score: 0.6419493248450852\n",
      "Tested params: {'lr': 1e-06, 'epochs': 7000, 'n_hidden': 39}, Score: 0.6419493248450852\n",
      "Skipping params: {'lr': 1e-06, 'epochs': 9000, 'n_hidden': 27} due to high score: 0.6386984333448966\n",
      "Tested params: {'lr': 1e-06, 'epochs': 9000, 'n_hidden': 27}, Score: 0.6386984333448966\n",
      "Tested params: {'lr': 1e-05, 'epochs': 5000, 'n_hidden': 29}, Score: 0.08194692698383096\n",
      "Skipping params: {'lr': 1e-07, 'epochs': 5000, 'n_hidden': 31} due to high score: 0.6861643016724251\n",
      "Tested params: {'lr': 1e-07, 'epochs': 5000, 'n_hidden': 31}, Score: 0.6861643016724251\n",
      "Skipping params: {'lr': 1e-07, 'epochs': 5000, 'n_hidden': 41} due to high score: 0.6860510919757659\n",
      "Tested params: {'lr': 1e-07, 'epochs': 5000, 'n_hidden': 41}, Score: 0.6860510919757659\n",
      "Skipping params: {'lr': 1e-06, 'epochs': 3000, 'n_hidden': 39} due to high score: 0.6612321895052478\n",
      "Tested params: {'lr': 1e-06, 'epochs': 3000, 'n_hidden': 39}, Score: 0.6612321895052478\n",
      "Skipping params: {'lr': 1e-06, 'epochs': 19000, 'n_hidden': 33} due to high score: 0.6228671336325883\n",
      "Tested params: {'lr': 1e-06, 'epochs': 19000, 'n_hidden': 33}, Score: 0.6228671336325883\n",
      "Tested params: {'lr': 0.0001, 'epochs': 11000, 'n_hidden': 10}, Score: 0.08499300476924906\n",
      "Skipping params: {'lr': 1e-06, 'epochs': 19000, 'n_hidden': 37} due to high score: 0.6101167689168698\n",
      "Tested params: {'lr': 1e-06, 'epochs': 19000, 'n_hidden': 37}, Score: 0.6101167689168698\n",
      "Tested params: {'lr': 0.0001, 'epochs': 15000, 'n_hidden': 41}, Score: 0.08410621252482683\n",
      "Skipping params: {'lr': 1e-06, 'epochs': 19000, 'n_hidden': 27} due to high score: 0.6275697978146395\n",
      "Tested params: {'lr': 1e-06, 'epochs': 19000, 'n_hidden': 27}, Score: 0.6275697978146395\n",
      "Skipping params: {'lr': 1e-06, 'epochs': 15000, 'n_hidden': 26} due to high score: 0.631591527118057\n",
      "Tested params: {'lr': 1e-06, 'epochs': 15000, 'n_hidden': 26}, Score: 0.631591527118057\n",
      "Skipping params: {'lr': 1e-07, 'epochs': 15000, 'n_hidden': 14} due to high score: 0.6746285628858112\n",
      "Tested params: {'lr': 1e-07, 'epochs': 15000, 'n_hidden': 14}, Score: 0.6746285628858112\n",
      "Skipping params: {'lr': 1e-06, 'epochs': 11000, 'n_hidden': 9} due to high score: 0.6365308269138578\n",
      "Tested params: {'lr': 1e-06, 'epochs': 11000, 'n_hidden': 9}, Score: 0.6365308269138578\n",
      "Tested params: {'lr': 1e-05, 'epochs': 9000, 'n_hidden': 16}, Score: 0.07815229620481166\n",
      "Best parameters: {'lr': 1e-05, 'epochs': 9000, 'n_hidden': 16}, Best score: 0.07815229620481166\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "iterations = 15\n",
    "\n",
    "param_space = {\n",
    "    'lr': [0.0001,0.00001,0.000001,0.0000001],\n",
    "    'epochs': np.arange(1000, 20000, 2000).tolist(),\n",
    "    'n_hidden': np.linspace(X_val.shape[1],5*X_val.shape[1],num=20).astype(int).tolist()\n",
    "}\n",
    "\n",
    "best_score = float('inf')\n",
    "best_params_ffn = {}\n",
    "\n",
    "for _ in range(iterations):\n",
    "\n",
    "    # Randomly select parameters\n",
    "    params = {key: random.choice(value) for key, value in param_space.items()}\n",
    "    scores = []\n",
    "\n",
    "    for i, (train_set, _) in enumerate(cross_validator.cross_validation(data_train, n_splits=2, n_repeats=5, random_state=42, stratify=True)):\n",
    "    \n",
    "        train_set = data_processor.encode_nominal_features(train_set)\n",
    "\n",
    "        train_data = train_set.to_numpy()\n",
    "        X_train = train_data[:,:-2]\n",
    "        y_train = train_data[:,-2:]\n",
    "\n",
    "        ffn = FeedForwardNetwork(config,n_input=X_train.shape[1],n_hidden_1=params['n_hidden'],n_hidden_2=params['n_hidden'],n_output=y_train.shape[1])\n",
    "\n",
    "        _, val_losses, _ = ffn.train(X_train,y_train,X_val,y_val,epochs=params['epochs'],lr=params['lr'],patience=500)\n",
    "\n",
    "        score = val_losses[-1]\n",
    "        scores.append(score)\n",
    "\n",
    "        # Skip to the next parameter set if score > 0.2\n",
    "        if score > 0.2:\n",
    "            print(f\"Skipping params: {params} due to high score: {score}\")\n",
    "            break  # Exit the current for-loop\n",
    "\n",
    "    avg_score = np.mean(scores)\n",
    "\n",
    "    print(f\"Tested params: {params}, Score: {avg_score}\")\n",
    "    \n",
    "    if avg_score < best_score:\n",
    "        best_score = avg_score\n",
    "        best_params_ffn = params\n",
    "        \n",
    "\n",
    "print(f\"Best parameters: {best_params_ffn}, Best score: {best_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping params: {'lr': 1e-07, 'epochs': 17000, 'n_encoder': 7} due to high score: 1.0101647121849406\n",
      "Tested params: {'lr': 1e-07, 'epochs': 17000, 'n_encoder': 7}, Score: 1.0101647121849406\n",
      "Skipping params: {'lr': 1e-07, 'epochs': 9000, 'n_encoder': 7} due to high score: 1.0106960978590305\n",
      "Tested params: {'lr': 1e-07, 'epochs': 9000, 'n_encoder': 7}, Score: 1.0106960978590305\n",
      "Tested params: {'lr': 0.0001, 'epochs': 5000, 'n_encoder': 6}, Score: 0.09806402884934455\n",
      "Skipping params: {'lr': 0.0001, 'epochs': 9000, 'n_encoder': 3} due to high score: 0.20287381796934215\n",
      "Tested params: {'lr': 0.0001, 'epochs': 9000, 'n_encoder': 3}, Score: 0.20287381796934215\n",
      "Skipping params: {'lr': 1e-06, 'epochs': 1000, 'n_encoder': 4} due to high score: 1.010840020454489\n",
      "Tested params: {'lr': 1e-06, 'epochs': 1000, 'n_encoder': 4}, Score: 1.010840020454489\n",
      "Skipping params: {'lr': 1e-05, 'epochs': 7000, 'n_encoder': 4} due to high score: 0.3580866439154864\n",
      "Tested params: {'lr': 1e-05, 'epochs': 7000, 'n_encoder': 4}, Score: 0.3580866439154864\n",
      "Skipping params: {'lr': 1e-07, 'epochs': 1000, 'n_encoder': 4} due to high score: 1.0112847520983068\n",
      "Tested params: {'lr': 1e-07, 'epochs': 1000, 'n_encoder': 4}, Score: 1.0112847520983068\n",
      "Skipping params: {'lr': 1e-06, 'epochs': 7000, 'n_encoder': 2} due to high score: 0.987838362952835\n",
      "Tested params: {'lr': 1e-06, 'epochs': 7000, 'n_encoder': 2}, Score: 0.987838362952835\n",
      "Skipping params: {'lr': 1e-06, 'epochs': 5000, 'n_encoder': 2} due to high score: 1.0051854799458202\n",
      "Tested params: {'lr': 1e-06, 'epochs': 5000, 'n_encoder': 2}, Score: 1.0051854799458202\n",
      "Skipping params: {'lr': 1e-07, 'epochs': 5000, 'n_encoder': 2} due to high score: 1.0111876127995791\n",
      "Tested params: {'lr': 1e-07, 'epochs': 5000, 'n_encoder': 2}, Score: 1.0111876127995791\n",
      "Skipping params: {'lr': 1e-06, 'epochs': 5000, 'n_encoder': 2} due to high score: 1.0050112200411063\n",
      "Tested params: {'lr': 1e-06, 'epochs': 5000, 'n_encoder': 2}, Score: 1.0050112200411063\n",
      "Skipping params: {'lr': 1e-05, 'epochs': 13000, 'n_encoder': 4} due to high score: 0.34567657812116026\n",
      "Tested params: {'lr': 1e-05, 'epochs': 13000, 'n_encoder': 4}, Score: 0.34567657812116026\n",
      "Skipping params: {'lr': 1e-07, 'epochs': 19000, 'n_encoder': 3} due to high score: 1.0103515698394632\n",
      "Tested params: {'lr': 1e-07, 'epochs': 19000, 'n_encoder': 3}, Score: 1.0103515698394632\n",
      "Tested params: {'lr': 0.0001, 'epochs': 11000, 'n_encoder': 4}, Score: 0.1504590496595331\n",
      "Skipping params: {'lr': 1e-05, 'epochs': 3000, 'n_encoder': 6} due to high score: 0.3814764693058038\n",
      "Tested params: {'lr': 1e-05, 'epochs': 3000, 'n_encoder': 6}, Score: 0.3814764693058038\n",
      "Best parameters: {'lr': 0.0001, 'epochs': 5000, 'n_encoder': 6}, Best score: 0.09806402884934455\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "iterations = 15\n",
    "\n",
    "param_space = {\n",
    "    'lr': [0.0001,0.00001,0.000001,0.0000001],\n",
    "    'epochs': np.arange(1000, 20000, 2000).tolist(),\n",
    "    'n_encoder': np.arange(2,X_val.shape[1]-1,1).tolist()\n",
    "}\n",
    "\n",
    "best_score = float('inf')\n",
    "best_params_auto = {}\n",
    "\n",
    "for _ in range(iterations):\n",
    "\n",
    "    # Randomly select parameters\n",
    "    params = {key: random.choice(value) for key, value in param_space.items()}\n",
    "    scores = []\n",
    "\n",
    "    for i, (train_set, _) in enumerate(cross_validator.cross_validation(data_train, n_splits=2, n_repeats=5, random_state=42, stratify=True)):\n",
    "    \n",
    "        train_set = data_processor.encode_nominal_features(train_set)\n",
    "\n",
    "        train_data = train_set.to_numpy()\n",
    "        X_train = train_data[:,:-2]\n",
    "        y_train = train_data[:,-2:]\n",
    "\n",
    "        autoE = AutoEncoder(config,n_input=X_train.shape[1],n_encoder=params['n_encoder'])\n",
    "\n",
    "        losses = autoE.train(X_train, max_epochs=params['epochs'], lr=params['lr'])\n",
    "\n",
    "        score = losses[-1]\n",
    "        scores.append(score)\n",
    "\n",
    "        # Skip to the next parameter set if score > 0.2\n",
    "        if score > 0.2:\n",
    "            print(f\"Skipping params: {params} due to high score: {score}\")\n",
    "            break  # Exit the current for-loop\n",
    "\n",
    "    avg_score = np.mean(scores)\n",
    "\n",
    "    print(f\"Tested params: {params}, Score: {avg_score}\")\n",
    "    \n",
    "    if avg_score < best_score:\n",
    "        best_score = avg_score\n",
    "        best_params_auto = params\n",
    "        \n",
    "\n",
    "print(f\"Best parameters: {best_params_auto}, Best score: {best_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09248448445211395"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoE = AutoEncoder(config,n_input=X_train.shape[1],n_encoder=best_params_auto['n_encoder'])\n",
    "losses = autoE.train(X_train, max_epochs=best_params_auto['epochs'], lr=best_params_auto['lr'])\n",
    "losses[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested params: {'lr': 1e-05, 'epochs': 13000, 'n_hidden_2': 4}, Score: 0.09524552305479583\n",
      "Tested params: {'lr': 1e-05, 'epochs': 17000, 'n_hidden_2': 5}, Score: 0.08943902898977531\n",
      "Skipping params: {'lr': 1e-06, 'epochs': 13000, 'n_hidden_2': 5} due to high score: 0.6343483148762368\n",
      "Tested params: {'lr': 1e-06, 'epochs': 13000, 'n_hidden_2': 5}, Score: 0.6343483148762368\n",
      "Tested params: {'lr': 0.0001, 'epochs': 9000, 'n_hidden_2': 7}, Score: 0.09147129630081938\n",
      "Skipping params: {'lr': 1e-07, 'epochs': 15000, 'n_hidden_2': 5} due to high score: 0.6746543037651868\n",
      "Tested params: {'lr': 1e-07, 'epochs': 15000, 'n_hidden_2': 5}, Score: 0.6746543037651868\n",
      "Skipping params: {'lr': 1e-06, 'epochs': 17000, 'n_hidden_2': 7} due to high score: 0.6315978948827793\n",
      "Tested params: {'lr': 1e-06, 'epochs': 17000, 'n_hidden_2': 7}, Score: 0.6315978948827793\n",
      "Tested params: {'lr': 0.0001, 'epochs': 13000, 'n_hidden_2': 2}, Score: 0.0919710234722924\n",
      "Tested params: {'lr': 0.0001, 'epochs': 13000, 'n_hidden_2': 7}, Score: 0.09133847829208541\n",
      "Skipping params: {'lr': 1e-07, 'epochs': 13000, 'n_hidden_2': 7} due to high score: 0.6767238718835459\n",
      "Tested params: {'lr': 1e-07, 'epochs': 13000, 'n_hidden_2': 7}, Score: 0.6767238718835459\n",
      "Tested params: {'lr': 1e-05, 'epochs': 15000, 'n_hidden_2': 7}, Score: 0.09044502454052444\n",
      "Tested params: {'lr': 0.0001, 'epochs': 11000, 'n_hidden_2': 5}, Score: 0.09113056048572522\n",
      "Skipping params: {'lr': 1e-07, 'epochs': 19000, 'n_hidden_2': 6} due to high score: 0.6707887479319385\n",
      "Tested params: {'lr': 1e-07, 'epochs': 19000, 'n_hidden_2': 6}, Score: 0.6707887479319385\n",
      "Skipping params: {'lr': 1e-06, 'epochs': 5000, 'n_hidden_2': 6} due to high score: 0.6508014849583996\n",
      "Tested params: {'lr': 1e-06, 'epochs': 5000, 'n_hidden_2': 6}, Score: 0.6508014849583996\n",
      "Skipping params: {'lr': 1e-05, 'epochs': 3000, 'n_hidden_2': 6} due to high score: 0.6261229126490259\n",
      "Tested params: {'lr': 1e-05, 'epochs': 3000, 'n_hidden_2': 6}, Score: 0.6261229126490259\n",
      "Skipping params: {'lr': 1e-07, 'epochs': 3000, 'n_hidden_2': 3} due to high score: 0.6888643796385702\n",
      "Tested params: {'lr': 1e-07, 'epochs': 3000, 'n_hidden_2': 3}, Score: 0.6888643796385702\n",
      "Best parameters: {'lr': 1e-05, 'epochs': 17000, 'n_hidden_2': 5}, Best score: 0.08943902898977531\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "iterations = 15\n",
    "\n",
    "param_space = {\n",
    "    'lr': [0.0001,0.00001,0.000001,0.0000001],\n",
    "    'epochs': np.arange(1000, 20000, 2000).tolist(),\n",
    "    'n_hidden_2': np.arange(2,X_val.shape[1]-1,1).tolist()\n",
    "}\n",
    "\n",
    "best_score = float('inf')\n",
    "best_params_combined = {}\n",
    "\n",
    "for _ in range(iterations):\n",
    "\n",
    "    # Randomly select parameters\n",
    "    params = {key: random.choice(value) for key, value in param_space.items()}\n",
    "    scores = []\n",
    "\n",
    "    for i, (train_set, _) in enumerate(cross_validator.cross_validation(data_train, n_splits=2, n_repeats=5, random_state=42, stratify=True)):\n",
    "    \n",
    "        train_set = data_processor.encode_nominal_features(train_set)\n",
    "\n",
    "        train_data = train_set.to_numpy()\n",
    "        X_train = train_data[:,:-2]\n",
    "        y_train = train_data[:,-2:]\n",
    "\n",
    "        combined = CombinedModel(autoE,n_hidden_2=params['n_hidden_2'],n_output=y_val.shape[1])\n",
    "\n",
    "        _, val_losses, _ = combined.train(X_train,y_train,X_val,y_val,epochs=params['epochs'], lr=params['lr'],patience=500)\n",
    "\n",
    "\n",
    "        score = val_losses[-1]\n",
    "        scores.append(score)\n",
    "\n",
    "        # Skip to the next parameter set if score > 0.2\n",
    "        if score > 0.2:\n",
    "            print(f\"Skipping params: {params} due to high score: {score}\")\n",
    "            break  # Exit the current for-loop\n",
    "\n",
    "    avg_score = np.mean(scores)\n",
    "\n",
    "    print(f\"Tested params: {params}, Score: {avg_score}\")\n",
    "    \n",
    "    if avg_score < best_score:\n",
    "        best_score = avg_score\n",
    "        best_params_combined = params\n",
    "        \n",
    "\n",
    "print(f\"Best parameters: {best_params_combined}, Best score: {best_score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested params: {'lr': 1e-05, 'epochs': 20000}, Average Score: 0.09566483027171763\n",
      "Tested params: {'lr': 1e-05, 'epochs': 9000, 'n_hidden': 16}, Average Score: 0.09671512283573097\n",
      "Tested params: {'lr': 1e-05, 'epochs': 17000, 'n_hidden_2': 5}, Average Score: 0.10181484506005731\n"
     ]
    }
   ],
   "source": [
    "linear_scores = []\n",
    "ffn_scores = []\n",
    "combined_scores = []\n",
    "\n",
    "for i, (train_set, test_set) in enumerate(cross_validator.cross_validation(data_train, n_splits=2, n_repeats=5, random_state=42, stratify=True)):\n",
    "\n",
    "    train_set = data_processor.encode_nominal_features(train_set)\n",
    "    test_set = data_processor.encode_nominal_features(test_set)\n",
    "\n",
    "    train_data = train_set.to_numpy()\n",
    "    X_train = train_data[:,:-2]\n",
    "    y_train = train_data[:,-2:]\n",
    "\n",
    "    test_data = test_set.to_numpy()\n",
    "    X_test = test_data[:,:-2]\n",
    "    y_test = test_data[:,-2:]\n",
    "\n",
    "    linear = LinearNetwork(config)\n",
    "    _, linear_val_losses = linear.logistic_regression(X_train,y_train,X_test,y_test,epochs=best_params_linear['epochs'],lr=best_params_linear['lr'],patience=500)\n",
    "\n",
    "    ffn = FeedForwardNetwork(config,n_input=X_train.shape[1],n_hidden_1=best_params_ffn['n_hidden'],n_hidden_2=best_params_ffn['n_hidden'],n_output=y_train.shape[1])\n",
    "    _, ffn_val_losses, _ = ffn.train(X_train,y_train,X_test,y_test,epochs=best_params_ffn['epochs'],lr=best_params_ffn['lr'],patience=500)\n",
    "\n",
    "    autoE = AutoEncoder(config,n_input=X_train.shape[1],n_encoder=best_params_auto['n_encoder'])\n",
    "    losses = autoE.train(X_train, max_epochs=best_params_auto['epochs'], lr=best_params_auto['lr'])\n",
    "    combined = CombinedModel(autoE,n_hidden_2=best_params_combined['n_hidden_2'],n_output=y_test.shape[1])\n",
    "    _, combined_val_losses, _ = combined.train(X_train,y_train,X_test,y_test,epochs=best_params_combined['epochs'], lr=best_params_combined['lr'],patience=500)\n",
    "\n",
    "\n",
    "    linear_score = linear_val_losses[-1]\n",
    "    ffn_score = ffn_val_losses[-1]\n",
    "    combined_score = combined_val_losses[-1]\n",
    "    \n",
    "    linear_scores.append(linear_score)\n",
    "    ffn_scores.append(ffn_score)\n",
    "    combined_scores.append(combined_score)\n",
    "\n",
    "avg_score_linear = np.mean(linear_scores)\n",
    "avg_score_ffn = np.mean(ffn_scores)\n",
    "avg_score_combined = np.mean(combined_scores)\n",
    "\n",
    "print(f\"Linear Model Tested params: {best_params_linear}, Average Score: {avg_score_linear}\")\n",
    "print(f\"FFN Model Tested params: {best_params_ffn}, Average Score: {avg_score_ffn}\")\n",
    "print(f\"Combined Model Tested params: {best_params_combined}, Average Score: {avg_score_combined}\")\n",
    "\n",
    "print(f\"Linear Model Scores: {linear_scores}\")\n",
    "print(f\"FFN Model Scores: {ffn_scores}\")\n",
    "print(f\"Combined Model Scores: {combined_scores}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Model Tested params: {'lr': 1e-05, 'epochs': 20000}, Average Score: 0.09566483027171763\n",
      "FFN Model Tested params: {'lr': 1e-05, 'epochs': 9000, 'n_hidden': 16}, Average Score: 0.09671512283573097\n",
      "Combined Model Tested params: {'lr': 1e-05, 'epochs': 17000, 'n_hidden_2': 5}, Average Score: 0.10181484506005731\n",
      "Linear Model Scores: [0.11848689379877886, 0.06855733122936343, 0.0914292595740916, 0.08845363592663304, 0.08788965255481519, 0.10184645296921152, 0.10972672240754154, 0.09235595708561394, 0.10226829522597905, 0.09563410194514825]\n",
      "FFN Model Scores: [0.1214222374639577, 0.06857891292044042, 0.09670960713225625, 0.08908281584332961, 0.09379335933795958, 0.10085272479665836, 0.11127096356472, 0.08643346311188324, 0.10175157191111493, 0.09725557227498964]\n",
      "Combined Model Scores: [0.12466373478670287, 0.073320915089253, 0.10039047958257587, 0.09566831503995853, 0.09366246710267205, 0.11513349672814732, 0.11584861014671317, 0.09133245161222694, 0.10776527968709641, 0.10036270082522701]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Linear Model Tested params: {best_params_linear}, Average Score: {avg_score_linear}\")\n",
    "print(f\"FFN Model Tested params: {best_params_ffn}, Average Score: {avg_score_ffn}\")\n",
    "print(f\"Combined Model Tested params: {best_params_combined}, Average Score: {avg_score_combined}\")\n",
    "\n",
    "print(f\"Linear Model Scores: {linear_scores}\")\n",
    "print(f\"FFN Model Scores: {ffn_scores}\")\n",
    "print(f\"Combined Model Scores: {combined_scores}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Model vs. FFN Model: t-statistic = -0.1682820775506725, p-value = 0.8682378089240967\n",
      "Linear Model vs. Combined Model: t-statistic = -0.9672393254197901, p-value = 0.34624170755070816\n",
      "FFN Model vs. Combined Model: t-statistic = -0.7857394607428007, p-value = 0.44224118353419584\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "t_stat, p_val = stats.ttest_ind(linear_scores, ffn_scores)\n",
    "print(f\"Linear Model vs. FFN Model: t-statistic = {t_stat}, p-value = {p_val}\")\n",
    "\n",
    "# Comparing Linear Model vs. Combined Model\n",
    "t_stat, p_val = stats.ttest_ind(linear_scores, combined_scores)\n",
    "print(f\"Linear Model vs. Combined Model: t-statistic = {t_stat}, p-value = {p_val}\")\n",
    "\n",
    "# Comparing FFN Model vs. Combined Model\n",
    "t_stat, p_val = stats.ttest_ind(ffn_scores, combined_scores)\n",
    "print(f\"FFN Model vs. Combined Model: t-statistic = {t_stat}, p-value = {p_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARCHIVED ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = data_train.to_numpy()\n",
    "# X_train = data[:,:-2]\n",
    "# y_train = data[:,-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_test = data_val.to_numpy()\n",
    "# X_val = data_test[:,:-2]\n",
    "# y_val = data_test[:,-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoE = AutoEncoder(config,n_input=X_train.shape[1],n_encoder=5)\n",
    "\n",
    "# autoE.train(X_train, max_epochs=20000, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined = CombinedModel(autoE,n_hidden_2=50,n_output=y_val.shape[1])\n",
    "\n",
    "# loss, val_metrics, final_loss = combined.train(X_train,y_train,X_val,y_val,epochs=10000,lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.min(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.plot(loss)\n",
    "# plt.plot(val_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ffn = FeedForwardNetwork(config,n_input=X_train.shape[1],n_hidden_1=24,n_hidden_2=24,n_output=y_train.shape[1])\n",
    "\n",
    "# loss, val_metrics, final_mse = ffn.train(X_train,y_train,X_val,y_val,5000,0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(loss)\n",
    "# plt.plot(val_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear = LinearNetwork(config)\n",
    "\n",
    "# losses, val_losses = linear.logistic_regression(X_train,y_train,X_val,y_val,epochs=1000,lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(losses)\n",
    "# plt.plot(val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
