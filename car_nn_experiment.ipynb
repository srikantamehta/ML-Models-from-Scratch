{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_preprocessor import DataProcessor\n",
    "from data_configs.configs import *\n",
    "from models.neural_networks import *\n",
    "from src.cross_validation import CrossValidation\n",
    "import numpy as np\n",
    "\n",
    "config = car_config\n",
    "data_processor = DataProcessor(config=config)\n",
    "cross_validator = CrossValidation(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Srikanta\\Documents\\Intro to Machine Learning\\programming_assignment_1\\src\\data_preprocessor.py:47: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[column].fillna(data[column].mode()[0], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "raw_data = data_processor.load_data()\n",
    "data_1 = data_processor.impute_missing_values(raw_data)\n",
    "data_2 = data_processor.encode_ordinal_features(data_1)\n",
    "data_3 = data_processor.standardize_data(data_2,data_2,features=['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.341253</td>\n",
       "      <td>-1.341253</td>\n",
       "      <td>-1.341253</td>\n",
       "      <td>-1.22439</td>\n",
       "      <td>-1.22439</td>\n",
       "      <td>-1.22439</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.341253</td>\n",
       "      <td>-1.341253</td>\n",
       "      <td>-1.341253</td>\n",
       "      <td>-1.22439</td>\n",
       "      <td>-1.22439</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.341253</td>\n",
       "      <td>-1.341253</td>\n",
       "      <td>-1.341253</td>\n",
       "      <td>-1.22439</td>\n",
       "      <td>-1.22439</td>\n",
       "      <td>1.22439</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.341253</td>\n",
       "      <td>-1.341253</td>\n",
       "      <td>-1.341253</td>\n",
       "      <td>-1.22439</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-1.22439</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.341253</td>\n",
       "      <td>-1.341253</td>\n",
       "      <td>-1.341253</td>\n",
       "      <td>-1.22439</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1723</th>\n",
       "      <td>1.341253</td>\n",
       "      <td>1.341253</td>\n",
       "      <td>1.341253</td>\n",
       "      <td>1.22439</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1724</th>\n",
       "      <td>1.341253</td>\n",
       "      <td>1.341253</td>\n",
       "      <td>1.341253</td>\n",
       "      <td>1.22439</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.22439</td>\n",
       "      <td>vgood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1725</th>\n",
       "      <td>1.341253</td>\n",
       "      <td>1.341253</td>\n",
       "      <td>1.341253</td>\n",
       "      <td>1.22439</td>\n",
       "      <td>1.22439</td>\n",
       "      <td>-1.22439</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1726</th>\n",
       "      <td>1.341253</td>\n",
       "      <td>1.341253</td>\n",
       "      <td>1.341253</td>\n",
       "      <td>1.22439</td>\n",
       "      <td>1.22439</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1727</th>\n",
       "      <td>1.341253</td>\n",
       "      <td>1.341253</td>\n",
       "      <td>1.341253</td>\n",
       "      <td>1.22439</td>\n",
       "      <td>1.22439</td>\n",
       "      <td>1.22439</td>\n",
       "      <td>vgood</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1728 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        buying     maint     doors  persons  lug_boot   safety  Class\n",
       "0    -1.341253 -1.341253 -1.341253 -1.22439  -1.22439 -1.22439  unacc\n",
       "1    -1.341253 -1.341253 -1.341253 -1.22439  -1.22439  0.00000  unacc\n",
       "2    -1.341253 -1.341253 -1.341253 -1.22439  -1.22439  1.22439  unacc\n",
       "3    -1.341253 -1.341253 -1.341253 -1.22439   0.00000 -1.22439  unacc\n",
       "4    -1.341253 -1.341253 -1.341253 -1.22439   0.00000  0.00000  unacc\n",
       "...        ...       ...       ...      ...       ...      ...    ...\n",
       "1723  1.341253  1.341253  1.341253  1.22439   0.00000  0.00000   good\n",
       "1724  1.341253  1.341253  1.341253  1.22439   0.00000  1.22439  vgood\n",
       "1725  1.341253  1.341253  1.341253  1.22439   1.22439 -1.22439  unacc\n",
       "1726  1.341253  1.341253  1.341253  1.22439   1.22439  0.00000   good\n",
       "1727  1.341253  1.341253  1.341253  1.22439   1.22439  1.22439  vgood\n",
       "\n",
       "[1728 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_val = cross_validator.random_partition(data_3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_val = data_processor.encode_nominal_features(data_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>Class_acc</th>\n",
       "      <th>Class_good</th>\n",
       "      <th>Class_unacc</th>\n",
       "      <th>Class_vgood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>-0.447084</td>\n",
       "      <td>-0.447084</td>\n",
       "      <td>0.447084</td>\n",
       "      <td>-1.22439</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.22439</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1201</th>\n",
       "      <td>0.447084</td>\n",
       "      <td>1.341253</td>\n",
       "      <td>-1.341253</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>-0.447084</td>\n",
       "      <td>-0.447084</td>\n",
       "      <td>1.341253</td>\n",
       "      <td>-1.22439</td>\n",
       "      <td>1.22439</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>1.341253</td>\n",
       "      <td>-0.447084</td>\n",
       "      <td>1.341253</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>0.447084</td>\n",
       "      <td>1.341253</td>\n",
       "      <td>0.447084</td>\n",
       "      <td>1.22439</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-1.22439</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>-1.341253</td>\n",
       "      <td>-1.341253</td>\n",
       "      <td>1.341253</td>\n",
       "      <td>1.22439</td>\n",
       "      <td>-1.22439</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>-1.341253</td>\n",
       "      <td>0.447084</td>\n",
       "      <td>0.447084</td>\n",
       "      <td>-1.22439</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1206</th>\n",
       "      <td>0.447084</td>\n",
       "      <td>1.341253</td>\n",
       "      <td>-1.341253</td>\n",
       "      <td>1.22439</td>\n",
       "      <td>-1.22439</td>\n",
       "      <td>-1.22439</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>-1.341253</td>\n",
       "      <td>-1.341253</td>\n",
       "      <td>1.341253</td>\n",
       "      <td>1.22439</td>\n",
       "      <td>-1.22439</td>\n",
       "      <td>1.22439</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084</th>\n",
       "      <td>0.447084</td>\n",
       "      <td>0.447084</td>\n",
       "      <td>-1.341253</td>\n",
       "      <td>-1.22439</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>346 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        buying     maint     doors  persons  lug_boot   safety  Class_acc  \\\n",
       "599  -0.447084 -0.447084  0.447084 -1.22439   0.00000  1.22439          0   \n",
       "1201  0.447084  1.341253 -1.341253  0.00000   0.00000  0.00000          1   \n",
       "628  -0.447084 -0.447084  1.341253 -1.22439   1.22439  0.00000          0   \n",
       "1498  1.341253 -0.447084  1.341253  0.00000   0.00000  0.00000          1   \n",
       "1263  0.447084  1.341253  0.447084  1.22439   0.00000 -1.22439          0   \n",
       "...        ...       ...       ...      ...       ...      ...        ...   \n",
       "100  -1.341253 -1.341253  1.341253  1.22439  -1.22439  0.00000          0   \n",
       "274  -1.341253  0.447084  0.447084 -1.22439   0.00000  0.00000          0   \n",
       "1206  0.447084  1.341253 -1.341253  1.22439  -1.22439 -1.22439          0   \n",
       "101  -1.341253 -1.341253  1.341253  1.22439  -1.22439  1.22439          0   \n",
       "1084  0.447084  0.447084 -1.341253 -1.22439   0.00000  0.00000          0   \n",
       "\n",
       "      Class_good  Class_unacc  Class_vgood  \n",
       "599            0            1            0  \n",
       "1201           0            0            0  \n",
       "628            0            1            0  \n",
       "1498           0            0            0  \n",
       "1263           0            1            0  \n",
       "...          ...          ...          ...  \n",
       "100            0            1            0  \n",
       "274            0            1            0  \n",
       "1206           0            1            0  \n",
       "101            0            1            0  \n",
       "1084           0            1            0  \n",
       "\n",
       "[346 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = data_val.to_numpy()\n",
    "X_val = data_test[:,:-4]\n",
    "y_val = data_test[:,-4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>-1.341253</td>\n",
       "      <td>-1.341253</td>\n",
       "      <td>1.341253</td>\n",
       "      <td>1.22439</td>\n",
       "      <td>1.22439</td>\n",
       "      <td>1.22439</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>0.447084</td>\n",
       "      <td>-1.341253</td>\n",
       "      <td>-0.447084</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-1.22439</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1709</th>\n",
       "      <td>1.341253</td>\n",
       "      <td>1.341253</td>\n",
       "      <td>1.341253</td>\n",
       "      <td>-1.22439</td>\n",
       "      <td>1.22439</td>\n",
       "      <td>1.22439</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>-0.447084</td>\n",
       "      <td>0.447084</td>\n",
       "      <td>0.447084</td>\n",
       "      <td>-1.22439</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>-0.447084</td>\n",
       "      <td>0.447084</td>\n",
       "      <td>-0.447084</td>\n",
       "      <td>-1.22439</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-1.22439</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>0.447084</td>\n",
       "      <td>0.447084</td>\n",
       "      <td>-0.447084</td>\n",
       "      <td>1.22439</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.22439</td>\n",
       "      <td>vgood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>0.447084</td>\n",
       "      <td>1.341253</td>\n",
       "      <td>1.341253</td>\n",
       "      <td>1.22439</td>\n",
       "      <td>1.22439</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>-0.447084</td>\n",
       "      <td>1.341253</td>\n",
       "      <td>1.341253</td>\n",
       "      <td>1.22439</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.22439</td>\n",
       "      <td>acc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>1.341253</td>\n",
       "      <td>-0.447084</td>\n",
       "      <td>0.447084</td>\n",
       "      <td>-1.22439</td>\n",
       "      <td>-1.22439</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>0.447084</td>\n",
       "      <td>0.447084</td>\n",
       "      <td>-0.447084</td>\n",
       "      <td>1.22439</td>\n",
       "      <td>-1.22439</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>acc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1382 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        buying     maint     doors  persons  lug_boot   safety  Class\n",
       "107  -1.341253 -1.341253  1.341253  1.22439   1.22439  1.22439  unacc\n",
       "901   0.447084 -1.341253 -0.447084  0.00000  -1.22439  0.00000  unacc\n",
       "1709  1.341253  1.341253  1.341253 -1.22439   1.22439  1.22439  unacc\n",
       "706  -0.447084  0.447084  0.447084 -1.22439   0.00000  0.00000  unacc\n",
       "678  -0.447084  0.447084 -0.447084 -1.22439   0.00000 -1.22439  unacc\n",
       "...        ...       ...       ...      ...       ...      ...    ...\n",
       "1130  0.447084  0.447084 -0.447084  1.22439   0.00000  1.22439  vgood\n",
       "1294  0.447084  1.341253  1.341253  1.22439   1.22439  0.00000   good\n",
       "860  -0.447084  1.341253  1.341253  1.22439   0.00000  1.22439    acc\n",
       "1459  1.341253 -0.447084  0.447084 -1.22439  -1.22439  0.00000  unacc\n",
       "1126  0.447084  0.447084 -0.447084  1.22439  -1.22439  0.00000    acc\n",
       "\n",
       "[1382 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing params: {'lr': 0.0001, 'epochs': 15263}\n",
      "Skipping params: {'lr': 0.0001, 'epochs': 15263} due to high score.\n",
      "Tested params: {'lr': 0.0001, 'epochs': 15263}, Score: 0.41081176080693943\n",
      "Testing params: {'lr': 0.0001, 'epochs': 8947}\n",
      "Skipping params: {'lr': 0.0001, 'epochs': 8947} due to high score.\n",
      "Tested params: {'lr': 0.0001, 'epochs': 8947}, Score: 0.41770325635835276\n",
      "Testing params: {'lr': 0.001, 'epochs': 16842}\n",
      "Skipping params: {'lr': 0.001, 'epochs': 16842} due to high score.\n",
      "Tested params: {'lr': 0.001, 'epochs': 16842}, Score: 0.40158658154749993\n",
      "Testing params: {'lr': 0.001, 'epochs': 17631}\n",
      "Skipping params: {'lr': 0.001, 'epochs': 17631} due to high score.\n",
      "Tested params: {'lr': 0.001, 'epochs': 17631}, Score: 0.40154822284753333\n",
      "Testing params: {'lr': 1e-06, 'epochs': 11315}\n",
      "Skipping params: {'lr': 1e-06, 'epochs': 11315} due to high score.\n",
      "Tested params: {'lr': 1e-06, 'epochs': 11315}, Score: 0.6253265810638988\n",
      "Testing params: {'lr': 0.001, 'epochs': 8947}\n",
      "Skipping params: {'lr': 0.001, 'epochs': 8947} due to high score.\n",
      "Tested params: {'lr': 0.001, 'epochs': 8947}, Score: 0.40234645181159456\n",
      "Testing params: {'lr': 1e-07, 'epochs': 19210}\n",
      "Skipping params: {'lr': 1e-07, 'epochs': 19210} due to high score.\n",
      "Tested params: {'lr': 1e-07, 'epochs': 19210}, Score: 0.9829650164183109\n",
      "Testing params: {'lr': 0.0001, 'epochs': 12894}\n",
      "Skipping params: {'lr': 0.0001, 'epochs': 12894} due to high score.\n",
      "Tested params: {'lr': 0.0001, 'epochs': 12894}, Score: 0.4126737537058921\n",
      "Testing params: {'lr': 1e-05, 'epochs': 9736}\n",
      "Skipping params: {'lr': 1e-05, 'epochs': 9736} due to high score.\n",
      "Tested params: {'lr': 1e-05, 'epochs': 9736}, Score: 0.4872324610983023\n",
      "Testing params: {'lr': 1e-06, 'epochs': 13684}\n",
      "Skipping params: {'lr': 1e-06, 'epochs': 13684} due to high score.\n",
      "Tested params: {'lr': 1e-06, 'epochs': 13684}, Score: 0.6067590202320609\n",
      "Testing params: {'lr': 1e-07, 'epochs': 10526}\n",
      "Skipping params: {'lr': 1e-07, 'epochs': 10526} due to high score.\n",
      "Tested params: {'lr': 1e-07, 'epochs': 10526}, Score: 1.1272579666370333\n",
      "Testing params: {'lr': 0.001, 'epochs': 12894}\n",
      "Skipping params: {'lr': 0.001, 'epochs': 12894} due to high score.\n",
      "Tested params: {'lr': 0.001, 'epochs': 12894}, Score: 0.4018505797718201\n",
      "Testing params: {'lr': 1e-07, 'epochs': 14473}\n",
      "Skipping params: {'lr': 1e-07, 'epochs': 14473} due to high score.\n",
      "Tested params: {'lr': 1e-07, 'epochs': 14473}, Score: 1.0567500404247034\n",
      "Testing params: {'lr': 0.001, 'epochs': 9736}\n",
      "Skipping params: {'lr': 0.001, 'epochs': 9736} due to high score.\n",
      "Tested params: {'lr': 0.001, 'epochs': 9736}, Score: 0.40221550747909174\n",
      "Testing params: {'lr': 1e-06, 'epochs': 14473}\n",
      "Skipping params: {'lr': 1e-06, 'epochs': 14473} due to high score.\n",
      "Tested params: {'lr': 1e-06, 'epochs': 14473}, Score: 0.6017026091225701\n",
      "Best parameters: {'lr': 0.001, 'epochs': 17631}, Best score: 0.40154822284753333\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "iterations = 15\n",
    "\n",
    "param_space = {\n",
    "    'lr': [0.001,0.0001,0.00001,0.000001,0.0000001],\n",
    "    'epochs': np.linspace(5000, 20000, num=20).astype(int).tolist()\n",
    "}\n",
    "\n",
    "best_score = float('inf')\n",
    "best_params_linear = {}\n",
    "\n",
    "for _ in range(iterations):\n",
    "\n",
    "    # Randomly select parameters\n",
    "    params = {key: random.choice(value) for key, value in param_space.items()}\n",
    "    scores = []\n",
    "\n",
    "    print(f\"Testing params: {params}\")\n",
    "\n",
    "    for i, (train_set, _) in enumerate(cross_validator.cross_validation(data_train, n_splits=2, n_repeats=5, random_state=42, stratify=True)):\n",
    "    \n",
    "        train_set = data_processor.encode_nominal_features(train_set)\n",
    "\n",
    "        train_data = train_set.to_numpy()\n",
    "        X_train = train_data[:,:-4]\n",
    "        y_train = train_data[:,-4:]\n",
    "\n",
    "        linear = LinearNetwork(config)\n",
    "\n",
    "        _, val_losses = linear.logistic_regression(X_train,y_train,X_val,y_val,epochs=params['epochs'],lr=params['lr'],patience=np.inf)\n",
    "\n",
    "        score = val_losses[-1]\n",
    "        scores.append(score)\n",
    "\n",
    "        # Skip to the next parameter set if score > 0.2\n",
    "        if score > 0.2:\n",
    "            print(f\"Skipping params: {params} due to high score.\")\n",
    "            break  # Exit the current for-loop\n",
    "        \n",
    "    avg_score = np.mean(scores)\n",
    "\n",
    "    print(f\"Tested params: {params}, Score: {avg_score}\")\n",
    "    \n",
    "    if avg_score < best_score:\n",
    "        best_score = avg_score\n",
    "        best_params_linear = params\n",
    "        \n",
    "\n",
    "print(f\"Best parameters: {best_params_linear}, Best score: {best_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing params: {'lr': 1e-05, 'epochs': 9000, 'n_hidden': 6}\n",
      "Skipping params: {'lr': 1e-05, 'epochs': 9000, 'n_hidden': 6} due to high score.\n",
      "Tested params: {'lr': 1e-05, 'epochs': 9000, 'n_hidden': 6}, Score: 0.8678054958021445\n",
      "Testing params: {'lr': 1e-05, 'epochs': 15000, 'n_hidden': 51}\n",
      "Skipping params: {'lr': 1e-05, 'epochs': 15000, 'n_hidden': 51} due to high score.\n",
      "Tested params: {'lr': 1e-05, 'epochs': 15000, 'n_hidden': 51}, Score: 0.45562835589304573\n",
      "Testing params: {'lr': 0.0001, 'epochs': 15000, 'n_hidden': 51}\n",
      "Tested params: {'lr': 0.0001, 'epochs': 15000, 'n_hidden': 51}, Score: 0.09680569367472854\n",
      "Testing params: {'lr': 0.0001, 'epochs': 5000, 'n_hidden': 51}\n",
      "Skipping params: {'lr': 0.0001, 'epochs': 5000, 'n_hidden': 51} due to high score.\n",
      "Tested params: {'lr': 0.0001, 'epochs': 5000, 'n_hidden': 51}, Score: 0.232982181600254\n",
      "Testing params: {'lr': 1e-06, 'epochs': 9000, 'n_hidden': 51}\n",
      "Skipping params: {'lr': 1e-06, 'epochs': 9000, 'n_hidden': 51} due to high score.\n",
      "Tested params: {'lr': 1e-06, 'epochs': 9000, 'n_hidden': 51}, Score: 0.9074982027233979\n",
      "Testing params: {'lr': 1e-07, 'epochs': 5000, 'n_hidden': 36}\n",
      "Skipping params: {'lr': 1e-07, 'epochs': 5000, 'n_hidden': 36} due to high score.\n",
      "Tested params: {'lr': 1e-07, 'epochs': 5000, 'n_hidden': 36}, Score: 1.2965034670679596\n",
      "Testing params: {'lr': 1e-07, 'epochs': 7000, 'n_hidden': 51}\n",
      "Skipping params: {'lr': 1e-07, 'epochs': 7000, 'n_hidden': 51} due to high score.\n",
      "Tested params: {'lr': 1e-07, 'epochs': 7000, 'n_hidden': 51}, Score: 1.2650219761274304\n",
      "Testing params: {'lr': 0.0001, 'epochs': 11000, 'n_hidden': 21}\n",
      "Skipping params: {'lr': 0.0001, 'epochs': 11000, 'n_hidden': 21} due to high score.\n",
      "Tested params: {'lr': 0.0001, 'epochs': 11000, 'n_hidden': 21}, Score: 0.16296211988959672\n",
      "Testing params: {'lr': 1e-06, 'epochs': 19000, 'n_hidden': 36}\n",
      "Skipping params: {'lr': 1e-06, 'epochs': 19000, 'n_hidden': 36} due to high score.\n",
      "Tested params: {'lr': 1e-06, 'epochs': 19000, 'n_hidden': 36}, Score: 0.8775258075208221\n",
      "Testing params: {'lr': 0.0001, 'epochs': 13000, 'n_hidden': 21}\n",
      "Tested params: {'lr': 0.0001, 'epochs': 13000, 'n_hidden': 21}, Score: 0.108476128590865\n",
      "Testing params: {'lr': 0.0001, 'epochs': 11000, 'n_hidden': 51}\n",
      "Tested params: {'lr': 0.0001, 'epochs': 11000, 'n_hidden': 51}, Score: 0.0982083564991221\n",
      "Testing params: {'lr': 1e-06, 'epochs': 7000, 'n_hidden': 51}\n",
      "Skipping params: {'lr': 1e-06, 'epochs': 7000, 'n_hidden': 51} due to high score.\n",
      "Tested params: {'lr': 1e-06, 'epochs': 7000, 'n_hidden': 51}, Score: 0.9267235624471896\n",
      "Testing params: {'lr': 0.0001, 'epochs': 13000, 'n_hidden': 21}\n",
      "Tested params: {'lr': 0.0001, 'epochs': 13000, 'n_hidden': 21}, Score: 0.10865140052925884\n",
      "Testing params: {'lr': 1e-07, 'epochs': 13000, 'n_hidden': 51}\n",
      "Skipping params: {'lr': 1e-07, 'epochs': 13000, 'n_hidden': 51} due to high score.\n",
      "Tested params: {'lr': 1e-07, 'epochs': 13000, 'n_hidden': 51}, Score: 1.1843150443000494\n",
      "Testing params: {'lr': 0.0001, 'epochs': 17000, 'n_hidden': 36}\n",
      "Skipping params: {'lr': 0.0001, 'epochs': 17000, 'n_hidden': 36} due to high score.\n",
      "Tested params: {'lr': 0.0001, 'epochs': 17000, 'n_hidden': 36}, Score: 0.10426424450727811\n",
      "Best parameters: {'lr': 0.0001, 'epochs': 15000, 'n_hidden': 51}, Best score: 0.09680569367472854\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "iterations = 15\n",
    "\n",
    "param_space = {\n",
    "    'lr': [0.0001,0.00001,0.000001,0.0000001],\n",
    "    'epochs': np.arange(5000, 20000, 2000).tolist(),\n",
    "    'n_hidden': np.arange(X_val.shape[1], 60, 15)\n",
    "}\n",
    "\n",
    "best_score = float('inf')\n",
    "best_params_ffn = {}\n",
    "\n",
    "for _ in range(iterations):\n",
    "\n",
    "    # Randomly select parameters\n",
    "    params = {key: random.choice(value) for key, value in param_space.items()}\n",
    "    scores = []\n",
    "\n",
    "    print(f\"Testing params: {params}\")\n",
    "\n",
    "    for i, (train_set, _) in enumerate(cross_validator.cross_validation(data_train, n_splits=2, n_repeats=5, random_state=42, stratify=True)):\n",
    "    \n",
    "        train_set = data_processor.encode_nominal_features(train_set)\n",
    "\n",
    "        train_data = train_set.to_numpy()\n",
    "        X_train = train_data[:,:-4]\n",
    "        y_train = train_data[:,-4:]\n",
    "\n",
    "        ffn = FeedForwardNetwork(config,n_input=X_train.shape[1],n_hidden_1=params['n_hidden'],n_hidden_2=params['n_hidden'],n_output=y_train.shape[1])\n",
    "\n",
    "        _, val_losses, _ = ffn.train(X_train,y_train,X_val,y_val,epochs=params['epochs'],lr=params['lr'],patience=500)\n",
    "\n",
    "        score = val_losses[-1]\n",
    "        scores.append(score)\n",
    "\n",
    "        # Skip to the next parameter set if score > 0.2\n",
    "        if score > 0.2:\n",
    "            print(f\"Skipping params: {params} due to high score.\")\n",
    "            break  # Exit the current for-loop\n",
    "\n",
    "    avg_score = np.mean(scores)\n",
    "\n",
    "    print(f\"Tested params: {params}, Score: {avg_score}\")\n",
    "    \n",
    "    if avg_score < best_score:\n",
    "        best_score = avg_score\n",
    "        best_params_ffn = params\n",
    "        \n",
    "\n",
    "print(f\"Best parameters: {best_params_ffn}, Best score: {best_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping params: {'lr': 1e-07, 'epochs': 9000, 'n_encoder': 2} due to high score.\n",
      "Tested params: {'lr': 1e-07, 'epochs': 9000, 'n_encoder': 2}, Score: 0.9988959734291747\n",
      "Skipping params: {'lr': 1e-05, 'epochs': 11000, 'n_encoder': 2} due to high score.\n",
      "Tested params: {'lr': 1e-05, 'epochs': 11000, 'n_encoder': 2}, Score: 0.6683539166262461\n",
      "Skipping params: {'lr': 0.0001, 'epochs': 17000, 'n_encoder': 4} due to high score.\n",
      "Tested params: {'lr': 0.0001, 'epochs': 17000, 'n_encoder': 4}, Score: 0.318924853703842\n",
      "Skipping params: {'lr': 0.001, 'epochs': 5000, 'n_encoder': 4} due to high score.\n",
      "Tested params: {'lr': 0.001, 'epochs': 5000, 'n_encoder': 4}, Score: 0.3442933670017246\n",
      "Skipping params: {'lr': 0.0001, 'epochs': 9000, 'n_encoder': 2} due to high score.\n",
      "Tested params: {'lr': 0.0001, 'epochs': 9000, 'n_encoder': 2}, Score: 0.6461132372907222\n",
      "Skipping params: {'lr': 1e-06, 'epochs': 19000, 'n_encoder': 4} due to high score.\n",
      "Tested params: {'lr': 1e-06, 'epochs': 19000, 'n_encoder': 4}, Score: 0.9897185134891439\n",
      "Skipping params: {'lr': 0.001, 'epochs': 9000, 'n_encoder': 2} due to high score.\n",
      "Tested params: {'lr': 0.001, 'epochs': 9000, 'n_encoder': 2}, Score: 0.6430042561689064\n",
      "Skipping params: {'lr': 1e-05, 'epochs': 11000, 'n_encoder': 4} due to high score.\n",
      "Tested params: {'lr': 1e-05, 'epochs': 11000, 'n_encoder': 4}, Score: 0.3479742632574661\n",
      "Skipping params: {'lr': 0.001, 'epochs': 11000, 'n_encoder': 2} due to high score.\n",
      "Tested params: {'lr': 0.001, 'epochs': 11000, 'n_encoder': 2}, Score: 0.6488957189986041\n",
      "Skipping params: {'lr': 0.001, 'epochs': 19000, 'n_encoder': 2} due to high score.\n",
      "Tested params: {'lr': 0.001, 'epochs': 19000, 'n_encoder': 2}, Score: 0.6482147505350689\n",
      "Skipping params: {'lr': 0.0001, 'epochs': 15000, 'n_encoder': 4} due to high score.\n",
      "Tested params: {'lr': 0.0001, 'epochs': 15000, 'n_encoder': 4}, Score: 0.31136111910869524\n",
      "Skipping params: {'lr': 1e-06, 'epochs': 9000, 'n_encoder': 2} due to high score.\n",
      "Tested params: {'lr': 1e-06, 'epochs': 9000, 'n_encoder': 2}, Score: 0.9982711942104816\n",
      "Skipping params: {'lr': 1e-06, 'epochs': 7000, 'n_encoder': 4} due to high score.\n",
      "Tested params: {'lr': 1e-06, 'epochs': 7000, 'n_encoder': 4}, Score: 0.9984457379444223\n",
      "Skipping params: {'lr': 1e-05, 'epochs': 9000, 'n_encoder': 2} due to high score.\n",
      "Tested params: {'lr': 1e-05, 'epochs': 9000, 'n_encoder': 2}, Score: 0.6754819260690182\n",
      "Skipping params: {'lr': 0.001, 'epochs': 13000, 'n_encoder': 3} due to high score.\n",
      "Tested params: {'lr': 0.001, 'epochs': 13000, 'n_encoder': 3}, Score: 0.4813571042728304\n",
      "Best parameters: {'lr': 0.0001, 'epochs': 15000, 'n_encoder': 4}, Best score: 0.31136111910869524\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "iterations = 15\n",
    "\n",
    "param_space = {\n",
    "    'lr': [0.001,0.0001,0.00001,0.000001,0.0000001],\n",
    "    'epochs': np.arange(5000, 20000, 2000).tolist(),\n",
    "    'n_encoder': np.arange(2,X_val.shape[1]-1,1).tolist()\n",
    "}\n",
    "\n",
    "best_score = float('inf')\n",
    "best_params_auto = {}\n",
    "\n",
    "for _ in range(iterations):\n",
    "\n",
    "    # Randomly select parameters\n",
    "    params = {key: random.choice(value) for key, value in param_space.items()}\n",
    "    scores = []\n",
    "\n",
    "    for i, (train_set, _) in enumerate(cross_validator.cross_validation(data_train, n_splits=2, n_repeats=5, random_state=42, stratify=True)):\n",
    "    \n",
    "        train_set = data_processor.encode_nominal_features(train_set)\n",
    "\n",
    "        train_data = train_set.to_numpy()\n",
    "        X_train = train_data[:,:-4]\n",
    "        y_train = train_data[:,-4:]\n",
    "\n",
    "        autoE = AutoEncoder(config,n_input=X_train.shape[1],n_encoder=params['n_encoder'])\n",
    "\n",
    "        losses = autoE.train(X_train, max_epochs=params['epochs'], lr=params['lr'])\n",
    "\n",
    "        score = losses[-1]\n",
    "        scores.append(score)\n",
    "\n",
    "        # Skip to the next parameter set if score > 0.2\n",
    "        if score > 0.2:\n",
    "            print(f\"Skipping params: {params} due to high score.\")\n",
    "            break  # Exit the current for-loop\n",
    "\n",
    "    avg_score = np.mean(scores)\n",
    "\n",
    "    print(f\"Tested params: {params}, Score: {avg_score}\")\n",
    "    \n",
    "    if avg_score < best_score:\n",
    "        best_score = avg_score\n",
    "        best_params_auto = params\n",
    "        \n",
    "\n",
    "print(f\"Best parameters: {best_params_auto}, Best score: {best_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3111830550283207"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoE = AutoEncoder(config,n_input=X_train.shape[1],n_encoder=best_params_auto['n_encoder'])\n",
    "losses = autoE.train(X_train, max_epochs=best_params_auto['epochs'], lr=best_params_auto['lr'])\n",
    "losses[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing params: {'lr': 1e-07, 'epochs': 15000, 'n_hidden_2': 21}\n",
      "Skipping params: {'lr': 1e-07, 'epochs': 15000, 'n_hidden_2': 21} due to high score: 1.1610906645825398\n",
      "Tested params: {'lr': 1e-07, 'epochs': 15000, 'n_hidden_2': 21}, Score: 1.1610906645825398\n",
      "Testing params: {'lr': 1e-06, 'epochs': 17000, 'n_hidden_2': 6}\n",
      "Skipping params: {'lr': 1e-06, 'epochs': 17000, 'n_hidden_2': 6} due to high score: 0.8805642774982249\n",
      "Tested params: {'lr': 1e-06, 'epochs': 17000, 'n_hidden_2': 6}, Score: 0.8805642774982249\n",
      "Testing params: {'lr': 1e-06, 'epochs': 17000, 'n_hidden_2': 6}\n",
      "Skipping params: {'lr': 1e-06, 'epochs': 17000, 'n_hidden_2': 6} due to high score: 0.8804484655709752\n",
      "Tested params: {'lr': 1e-06, 'epochs': 17000, 'n_hidden_2': 6}, Score: 0.8804484655709752\n",
      "Testing params: {'lr': 1e-06, 'epochs': 17000, 'n_hidden_2': 21}\n",
      "Skipping params: {'lr': 1e-06, 'epochs': 17000, 'n_hidden_2': 21} due to high score: 0.8795834328435462\n",
      "Tested params: {'lr': 1e-06, 'epochs': 17000, 'n_hidden_2': 21}, Score: 0.8795834328435462\n",
      "Testing params: {'lr': 0.0001, 'epochs': 13000, 'n_hidden_2': 51}\n",
      "Skipping params: {'lr': 0.0001, 'epochs': 13000, 'n_hidden_2': 51} due to high score: 0.263124042440046\n",
      "Tested params: {'lr': 0.0001, 'epochs': 13000, 'n_hidden_2': 51}, Score: 0.1909840332430632\n",
      "Testing params: {'lr': 1e-07, 'epochs': 9000, 'n_hidden_2': 51}\n",
      "Skipping params: {'lr': 1e-07, 'epochs': 9000, 'n_hidden_2': 51} due to high score: 1.2353223129331958\n",
      "Tested params: {'lr': 1e-07, 'epochs': 9000, 'n_hidden_2': 51}, Score: 1.2353223129331958\n",
      "Testing params: {'lr': 1e-07, 'epochs': 5000, 'n_hidden_2': 21}\n",
      "Skipping params: {'lr': 1e-07, 'epochs': 5000, 'n_hidden_2': 21} due to high score: 1.2963494435650915\n",
      "Tested params: {'lr': 1e-07, 'epochs': 5000, 'n_hidden_2': 21}, Score: 1.2963494435650915\n",
      "Testing params: {'lr': 0.001, 'epochs': 7000, 'n_hidden_2': 36}\n",
      "Skipping params: {'lr': 0.001, 'epochs': 7000, 'n_hidden_2': 36} due to high score: 0.27752195676338853\n",
      "Tested params: {'lr': 0.001, 'epochs': 7000, 'n_hidden_2': 36}, Score: 0.1733876615239003\n",
      "Testing params: {'lr': 1e-05, 'epochs': 5000, 'n_hidden_2': 6}\n",
      "Skipping params: {'lr': 1e-05, 'epochs': 5000, 'n_hidden_2': 6} due to high score: 0.8680833410235886\n",
      "Tested params: {'lr': 1e-05, 'epochs': 5000, 'n_hidden_2': 6}, Score: 0.8680833410235886\n",
      "Testing params: {'lr': 1e-07, 'epochs': 7000, 'n_hidden_2': 51}\n",
      "Skipping params: {'lr': 1e-07, 'epochs': 7000, 'n_hidden_2': 51} due to high score: 1.264271292147553\n",
      "Tested params: {'lr': 1e-07, 'epochs': 7000, 'n_hidden_2': 51}, Score: 1.264271292147553\n",
      "Testing params: {'lr': 1e-06, 'epochs': 5000, 'n_hidden_2': 21}\n",
      "Skipping params: {'lr': 1e-06, 'epochs': 5000, 'n_hidden_2': 21} due to high score: 0.9615041757410573\n",
      "Tested params: {'lr': 1e-06, 'epochs': 5000, 'n_hidden_2': 21}, Score: 0.9615041757410573\n",
      "Testing params: {'lr': 1e-07, 'epochs': 5000, 'n_hidden_2': 51}\n",
      "Skipping params: {'lr': 1e-07, 'epochs': 5000, 'n_hidden_2': 51} due to high score: 1.296115114592537\n",
      "Tested params: {'lr': 1e-07, 'epochs': 5000, 'n_hidden_2': 51}, Score: 1.296115114592537\n",
      "Testing params: {'lr': 0.0001, 'epochs': 13000, 'n_hidden_2': 6}\n",
      "Skipping params: {'lr': 0.0001, 'epochs': 13000, 'n_hidden_2': 6} due to high score: 0.20215055642028557\n",
      "Tested params: {'lr': 0.0001, 'epochs': 13000, 'n_hidden_2': 6}, Score: 0.18139324665562295\n",
      "Testing params: {'lr': 1e-07, 'epochs': 17000, 'n_hidden_2': 6}\n",
      "Skipping params: {'lr': 1e-07, 'epochs': 17000, 'n_hidden_2': 6} due to high score: 1.1404477790236511\n",
      "Tested params: {'lr': 1e-07, 'epochs': 17000, 'n_hidden_2': 6}, Score: 1.1404477790236511\n",
      "Testing params: {'lr': 0.001, 'epochs': 19000, 'n_hidden_2': 36}\n",
      "Skipping params: {'lr': 0.001, 'epochs': 19000, 'n_hidden_2': 36} due to high score: 0.2861764796311203\n",
      "Tested params: {'lr': 0.001, 'epochs': 19000, 'n_hidden_2': 36}, Score: 0.15866382910228183\n",
      "Best parameters: {'lr': 0.001, 'epochs': 19000, 'n_hidden_2': 36}, Best score: 0.15866382910228183\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "iterations = 15\n",
    "\n",
    "param_space = {\n",
    "    'lr': [0.001,0.0001,0.00001,0.000001,0.0000001],\n",
    "    'epochs': np.arange(5000, 20000, 2000).tolist(),\n",
    "    'n_hidden_2': np.arange(X_val.shape[1], 60, 15)\n",
    "}\n",
    "\n",
    "best_score = float('inf')\n",
    "best_params_combined = {}\n",
    "\n",
    "for _ in range(iterations):\n",
    "\n",
    "    # Randomly select parameters\n",
    "    params = {key: random.choice(value) for key, value in param_space.items()}\n",
    "    scores = []\n",
    "    print(f\"Testing params: {params}\")\n",
    "\n",
    "    for i, (train_set, _) in enumerate(cross_validator.cross_validation(data_train, n_splits=2, n_repeats=5, random_state=42, stratify=True)):\n",
    "    \n",
    "        train_set = data_processor.encode_nominal_features(train_set)\n",
    "\n",
    "        train_data = train_set.to_numpy()\n",
    "        X_train = train_data[:,:-4]\n",
    "        y_train = train_data[:,-4:]\n",
    "\n",
    "        combined = CombinedModel(autoE,n_hidden_2=params['n_hidden_2'],n_output=y_val.shape[1])\n",
    "\n",
    "        _, val_losses, _ = combined.train(X_train,y_train,X_val,y_val,epochs=params['epochs'], lr=params['lr'],patience=500)\n",
    "\n",
    "\n",
    "        score = val_losses[-1]\n",
    "        scores.append(score)\n",
    "\n",
    "        # Skip to the next parameter set if score > 0.2\n",
    "        if score > 0.2:\n",
    "            print(f\"Skipping params: {params} due to high score: {score}\")\n",
    "            break  # Exit the current for-loop\n",
    "\n",
    "    avg_score = np.mean(scores)\n",
    "\n",
    "    print(f\"Tested params: {params}, Score: {avg_score}\")\n",
    "    \n",
    "    if avg_score < best_score:\n",
    "        best_score = avg_score\n",
    "        best_params_combined = params\n",
    "        \n",
    "\n",
    "print(f\"Best parameters: {best_params_combined}, Best score: {best_score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Model Tested params: {'lr': 0.001, 'epochs': 17631}, Average Score: 0.3973078572142352\n",
      "FFN Model Tested params: {'lr': 0.0001, 'epochs': 15000, 'n_hidden': 51}, Average Score: 0.07246082076067989\n",
      "Combined Model Tested params: {'lr': 0.001, 'epochs': 19000, 'n_hidden_2': 36}, Average Score: 0.10001335266412095\n",
      "Linear Model Scores: [0.3986343388674607, 0.4041138755568258, 0.3848313992905454, 0.4167407095898887, 0.3802121430335066, 0.40762362921082995, 0.40725013280011935, 0.37885617086436985, 0.4025237252336589, 0.39229244769514704]\n",
      "FFN Model Scores: [0.07682131200474152, 0.07063944627187413, 0.08969222970421535, 0.07518292713970606, 0.05707371343739654, 0.07887621356307986, 0.056863501508397654, 0.0831171840295786, 0.055184485504538236, 0.08115719444327095]\n",
      "Combined Model Scores: [0.0955876646569639, 0.12608108467117493, 0.13471493406796306, 0.06294310293858896, 0.06872114685291315, 0.09097500268679101, 0.09417760912482494, 0.10049405767327041, 0.08863619864823079, 0.13780272532048823]\n"
     ]
    }
   ],
   "source": [
    "linear_scores = []\n",
    "ffn_scores = []\n",
    "combined_scores = []\n",
    "\n",
    "for i, (train_set, test_set) in enumerate(cross_validator.cross_validation(data_train, n_splits=2, n_repeats=5, random_state=42, stratify=True)):\n",
    "\n",
    "    train_set = data_processor.encode_nominal_features(train_set)\n",
    "    test_set = data_processor.encode_nominal_features(test_set)\n",
    "\n",
    "    train_data = train_set.to_numpy()\n",
    "    X_train = train_data[:,:-4]\n",
    "    y_train = train_data[:,-4:]\n",
    "\n",
    "    test_data = test_set.to_numpy()\n",
    "    X_test = test_data[:,:-4]\n",
    "    y_test = test_data[:,-4:]\n",
    "\n",
    "    linear = LinearNetwork(config)\n",
    "    _, linear_val_losses = linear.logistic_regression(X_train,y_train,X_test,y_test,epochs=best_params_linear['epochs'],lr=best_params_linear['lr'],patience=np.inf)\n",
    "\n",
    "    ffn = FeedForwardNetwork(config,n_input=X_train.shape[1],n_hidden_1=best_params_ffn['n_hidden'],n_hidden_2=best_params_ffn['n_hidden'],n_output=y_train.shape[1])\n",
    "    _, ffn_val_losses, _ = ffn.train(X_train,y_train,X_test,y_test,epochs=best_params_ffn['epochs'],lr=best_params_ffn['lr'],patience=np.inf)\n",
    "\n",
    "    autoE = AutoEncoder(config,n_input=X_train.shape[1],n_encoder=best_params_auto['n_encoder'])\n",
    "    losses = autoE.train(X_train, max_epochs=best_params_auto['epochs'], lr=best_params_auto['lr'])\n",
    "    combined = CombinedModel(autoE,n_hidden_2=best_params_combined['n_hidden_2'],n_output=y_test.shape[1])\n",
    "    _, combined_val_losses, _ = combined.train(X_train,y_train,X_test,y_test,epochs=best_params_combined['epochs'], lr=best_params_combined['lr'],patience=np.inf)\n",
    "\n",
    "\n",
    "    linear_score = np.min(linear_val_losses)\n",
    "    ffn_score = np.min(ffn_val_losses)\n",
    "    combined_score = np.min(combined_val_losses)\n",
    "    \n",
    "    linear_scores.append(linear_score)\n",
    "    ffn_scores.append(ffn_score)\n",
    "    combined_scores.append(combined_score)\n",
    "\n",
    "avg_score_linear = np.mean(linear_scores)\n",
    "avg_score_ffn = np.mean(ffn_scores)\n",
    "avg_score_combined = np.mean(combined_scores)\n",
    "\n",
    "print(f\"Linear Model Tested params: {best_params_linear}, Average Score: {avg_score_linear}\")\n",
    "print(f\"FFN Model Tested params: {best_params_ffn}, Average Score: {avg_score_ffn}\")\n",
    "print(f\"Combined Model Tested params: {best_params_combined}, Average Score: {avg_score_combined}\")\n",
    "\n",
    "print(f\"Linear Model Scores: {linear_scores}\")\n",
    "print(f\"FFN Model Scores: {ffn_scores}\")\n",
    "print(f\"Combined Model Scores: {combined_scores}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Model vs. FFN Model: t-statistic = 58.16474758665112, p-value = 6.05544773243553e-22\n",
      "Linear Model vs. Combined Model: t-statistic = 32.78207132920138, p-value = 1.669517911184232e-17\n",
      "FFN Model vs. Combined Model: t-statistic = -3.0665096959370204, p-value = 0.006648539731434936\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "t_stat, p_val = stats.ttest_ind(linear_scores, ffn_scores)\n",
    "print(f\"Linear Model vs. FFN Model: t-statistic = {t_stat}, p-value = {p_val}\")\n",
    "\n",
    "# Comparing Linear Model vs. Combined Model\n",
    "t_stat, p_val = stats.ttest_ind(linear_scores, combined_scores)\n",
    "print(f\"Linear Model vs. Combined Model: t-statistic = {t_stat}, p-value = {p_val}\")\n",
    "\n",
    "# Comparing FFN Model vs. Combined Model\n",
    "t_stat, p_val = stats.ttest_ind(ffn_scores, combined_scores)\n",
    "print(f\"FFN Model vs. Combined Model: t-statistic = {t_stat}, p-value = {p_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANOVA result: F-statistic = 1002.5949860886334, p-value = 4.633324440573921e-26\n",
      " Multiple Comparison of Means - Tukey HSD, FWER=0.05  \n",
      "======================================================\n",
      " group1  group2 meandiff p-adj   lower   upper  reject\n",
      "------------------------------------------------------\n",
      "Combined    FFN  -0.0276 0.0054 -0.0475 -0.0076   True\n",
      "Combined Linear   0.2973    0.0  0.2773  0.3172   True\n",
      "     FFN Linear   0.3248    0.0  0.3049  0.3448   True\n",
      "------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Combine all scores into a single array, and create an array of labels\n",
    "scores = np.concatenate([linear_scores, ffn_scores, combined_scores])\n",
    "labels = ['Linear'] * len(linear_scores) + ['FFN'] * len(ffn_scores) + ['Combined'] * len(combined_scores)\n",
    "\n",
    "# Conduct ANOVA\n",
    "anova_result = stats.f_oneway(linear_scores, ffn_scores, combined_scores)\n",
    "print(f\"ANOVA result: F-statistic = {anova_result.statistic}, p-value = {anova_result.pvalue}\")\n",
    "\n",
    "# If ANOVA shows significant differences, conduct post-hoc testing with Tukey's HSD\n",
    "if anova_result.pvalue < 0.05:\n",
    "    tukey = pairwise_tukeyhsd(endog=scores, groups=labels, alpha=0.05)\n",
    "    print(tukey)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Archive ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_train = data_processor.encode_nominal_features(data_train)\n",
    "# # data_val = data_processor.encode_nominal_features(data_val)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = data_train.to_numpy()\n",
    "# X_train = data[:,:-4]\n",
    "# y_train = data[:,-4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_test = data_val.to_numpy()\n",
    "# X_val = data_test[:,:-4]\n",
    "# y_val = data_test[:,-4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoE = AutoEncoder(config,n_input=X_train.shape[1],n_encoder=4)\n",
    "\n",
    "# autoE.train(X_train, max_epochs=20000, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined = CombinedModel(autoE,n_hidden_2=20,n_output=y_val.shape[1])\n",
    "\n",
    "# loss, val_metrics, final_loss = combined.train(X_train,y_train,X_val,y_val,epochs=15000,lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.plot(loss)\n",
    "# plt.plot(val_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ffn = FeedForwardNetwork(config,n_input=X_train.shape[1],n_hidden_1=20,n_hidden_2=20,n_output=y_train.shape[1])\n",
    "\n",
    "# loss, val_metrics, final_mse = ffn.train(X_train,y_train,X_val,y_val,10000,0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(loss)\n",
    "# plt.plot(val_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear = LinearNetwork(config)\n",
    "\n",
    "# losses, val_losses = linear.logistic_regression(X_train,y_train,X_val,y_val,epochs=20000,lr=0.0001)\n",
    "# val_losses[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# plt.plot(losses)\n",
    "# plt.plot(val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
